{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad18dd8-67ef-4c3d-b6c1-44f16541e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6aff81-7f87-4a99-8db6-93f6b2224ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Downloads\\emotion_det\\emotion\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115c8f66-81d1-4e3b-a671-c09a843adf30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ad409b4-08ea-489d-a047-293eb582a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0ed405-d958-4100-8296-5bd2416dc053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3854d5-5cb7-466b-9e53-44871ca4f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9daead-abc7-4acd-85ca-dca2a8053fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install soundfile numpy scikit-learn pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42aebf18-ff6b-4413-88cd-b6c2b389e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install resampy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa67fff-3dd8-4b95-b62e-4b164b24804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac188d0-89db-4c06-9d9e-9c0de4ee841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
    "    stft = np.abs(librosa.stft(X)) if chroma or mel else None  # Compute STFT once if needed\n",
    "    result = np.array([])\n",
    "    \n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "        \n",
    "    if chroma:\n",
    "        chroma_feat = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, chroma_feat))\n",
    "        \n",
    "    if mel:\n",
    "        # Fixed: Added y= parameter for melspectrogram\n",
    "        mel_feat = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, mel_feat))\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b92166-e62a-40f5-a1f1-2d1ede3a9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotions={\n",
    "#   '01':'neutral',\n",
    "#   '02':'calm',\n",
    "#   '03':'happy',\n",
    "#   '04':'sad',\n",
    "#   '05':'angry',\n",
    "#   '06':'fearful',\n",
    "#   '07':'disgust',\n",
    "#   '08':'surprised'\n",
    "# }\n",
    "# # Emotions to observe\n",
    "# observed_emotions=['neutral','calm','happy','sad','angry','fearful', 'disgust','surprised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdf3fd0c-c41c-4348-ac66-eeba5b8b1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Automatically derive observed emotions from the dictionary\n",
    "observed_emotions = list(emotions.values())  # Now includes all emotions\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    x, y = [], []\n",
    "    # Process both speech and song files\n",
    "    for pattern in ['speech', 'song']:\n",
    "        for file in glob.glob(f'C:/Users/Dell/Downloads/emotion_det/{pattern}/Actor_*/*.wav'):\n",
    "            file_name = os.path.basename(file)\n",
    "            emotion_code = file_name.split(\"-\")[2]\n",
    "            \n",
    "            # Safely get emotion, skip if code is invalid\n",
    "            emotion = emotions.get(emotion_code)\n",
    "            if emotion not in observed_emotions:\n",
    "                continue\n",
    "            \n",
    "            # Feature extraction\n",
    "            feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "            x.append(feature)\n",
    "            y.append(emotion)\n",
    "    \n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bdfca-ac06-4a07-89e7-41ade0a72b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04cea39c-1aab-4f0e-97f4-37f7461ffb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee027203-efe8-4cc3-b6f4-d369cd502893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96f84415-aaef-431f-bcbb-8088ef3b6924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1839, 613)\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f5fe0f-c15b-4516-b1f8-7f05d2f5fae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1961, 180)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "495b8b5b-c8af-4361-9d8e-349b7083730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e1fc88d-3cec-4d5e-8a9a-3615dec4d706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Downloads\\emotion_det\\emotion\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.1789 - loss: 2.0512 - val_accuracy: 0.2444 - val_loss: 1.9782\n",
      "Epoch 2/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2466 - loss: 1.9396 - val_accuracy: 0.2383 - val_loss: 1.8577\n",
      "Epoch 3/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3160 - loss: 1.7991 - val_accuracy: 0.2912 - val_loss: 1.7553\n",
      "Epoch 4/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3123 - loss: 1.7449 - val_accuracy: 0.3605 - val_loss: 1.6343\n",
      "Epoch 5/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3831 - loss: 1.6100 - val_accuracy: 0.3849 - val_loss: 1.5355\n",
      "Epoch 6/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4143 - loss: 1.5273 - val_accuracy: 0.4420 - val_loss: 1.4629\n",
      "Epoch 7/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4454 - loss: 1.4458 - val_accuracy: 0.4644 - val_loss: 1.3922\n",
      "Epoch 8/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4299 - loss: 1.4747 - val_accuracy: 0.4705 - val_loss: 1.3806\n",
      "Epoch 9/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4574 - loss: 1.3962 - val_accuracy: 0.4807 - val_loss: 1.3406\n",
      "Epoch 10/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4677 - loss: 1.4044 - val_accuracy: 0.4929 - val_loss: 1.3086\n",
      "Epoch 11/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4755 - loss: 1.3677 - val_accuracy: 0.4929 - val_loss: 1.2895\n",
      "Epoch 12/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4941 - loss: 1.3057 - val_accuracy: 0.5092 - val_loss: 1.2680\n",
      "Epoch 13/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5153 - loss: 1.2809 - val_accuracy: 0.4908 - val_loss: 1.2763\n",
      "Epoch 14/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5195 - loss: 1.2494 - val_accuracy: 0.5356 - val_loss: 1.2258\n",
      "Epoch 15/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5240 - loss: 1.2433 - val_accuracy: 0.5071 - val_loss: 1.2519\n",
      "Epoch 16/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5193 - loss: 1.2352 - val_accuracy: 0.5397 - val_loss: 1.2164\n",
      "Epoch 17/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5380 - loss: 1.2577 - val_accuracy: 0.5458 - val_loss: 1.1840\n",
      "Epoch 18/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5431 - loss: 1.2027 - val_accuracy: 0.5377 - val_loss: 1.1725\n",
      "Epoch 19/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5574 - loss: 1.2017 - val_accuracy: 0.5112 - val_loss: 1.2249\n",
      "Epoch 20/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5574 - loss: 1.1756 - val_accuracy: 0.5479 - val_loss: 1.1538\n",
      "Epoch 21/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5475 - loss: 1.1738 - val_accuracy: 0.5804 - val_loss: 1.1251\n",
      "Epoch 22/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5673 - loss: 1.1499 - val_accuracy: 0.5356 - val_loss: 1.1602\n",
      "Epoch 23/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5732 - loss: 1.1560 - val_accuracy: 0.5418 - val_loss: 1.1482\n",
      "Epoch 24/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5752 - loss: 1.1422 - val_accuracy: 0.5845 - val_loss: 1.1086\n",
      "Epoch 25/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5771 - loss: 1.1364 - val_accuracy: 0.5743 - val_loss: 1.1195\n",
      "Epoch 26/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5794 - loss: 1.1256 - val_accuracy: 0.5845 - val_loss: 1.1012\n",
      "Epoch 27/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5755 - loss: 1.1085 - val_accuracy: 0.5703 - val_loss: 1.0910\n",
      "Epoch 28/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5898 - loss: 1.1074 - val_accuracy: 0.5886 - val_loss: 1.0937\n",
      "Epoch 29/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5989 - loss: 1.0605 - val_accuracy: 0.5499 - val_loss: 1.1187\n",
      "Epoch 30/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5892 - loss: 1.0870 - val_accuracy: 0.6130 - val_loss: 1.0727\n",
      "Epoch 31/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6169 - loss: 1.0262 - val_accuracy: 0.5743 - val_loss: 1.0999\n",
      "Epoch 32/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6128 - loss: 1.0164 - val_accuracy: 0.5845 - val_loss: 1.0649\n",
      "Epoch 33/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6235 - loss: 1.0151 - val_accuracy: 0.5825 - val_loss: 1.0779\n",
      "Epoch 34/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6101 - loss: 1.0254 - val_accuracy: 0.5988 - val_loss: 1.0697\n",
      "Epoch 35/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6161 - loss: 0.9955 - val_accuracy: 0.5723 - val_loss: 1.0994\n",
      "Epoch 36/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6164 - loss: 1.0276 - val_accuracy: 0.5886 - val_loss: 1.0670\n",
      "Epoch 37/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6000 - loss: 1.0656 - val_accuracy: 0.5947 - val_loss: 1.0664\n",
      "Epoch 38/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6368 - loss: 0.9742 - val_accuracy: 0.6090 - val_loss: 1.0462\n",
      "Epoch 39/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6294 - loss: 0.9964 - val_accuracy: 0.6069 - val_loss: 1.0674\n",
      "Epoch 40/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6179 - loss: 0.9984 - val_accuracy: 0.5927 - val_loss: 1.0418\n",
      "Epoch 41/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6476 - loss: 0.9997 - val_accuracy: 0.6008 - val_loss: 1.0656\n",
      "Epoch 42/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6415 - loss: 0.9631 - val_accuracy: 0.5927 - val_loss: 1.0537\n",
      "Epoch 43/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6473 - loss: 0.9683 - val_accuracy: 0.6232 - val_loss: 1.0348\n",
      "Epoch 44/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6438 - loss: 0.9586 - val_accuracy: 0.6029 - val_loss: 1.0467\n",
      "Epoch 45/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6415 - loss: 0.9583 - val_accuracy: 0.6008 - val_loss: 1.0426\n",
      "Epoch 46/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6427 - loss: 0.9684 - val_accuracy: 0.5967 - val_loss: 1.0470\n",
      "Epoch 47/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6470 - loss: 0.9729 - val_accuracy: 0.6253 - val_loss: 1.0366\n",
      "Epoch 48/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6629 - loss: 0.9126 - val_accuracy: 0.5947 - val_loss: 1.0316\n",
      "Epoch 49/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6439 - loss: 0.9181 - val_accuracy: 0.6293 - val_loss: 0.9979\n",
      "Epoch 50/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6609 - loss: 0.9054 - val_accuracy: 0.6171 - val_loss: 1.0118\n",
      "Epoch 51/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6376 - loss: 0.9720 - val_accuracy: 0.6008 - val_loss: 1.0317\n",
      "Epoch 52/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6490 - loss: 0.9382 - val_accuracy: 0.5947 - val_loss: 1.0783\n",
      "Epoch 53/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6523 - loss: 0.9397 - val_accuracy: 0.6049 - val_loss: 1.0194\n",
      "Epoch 54/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6510 - loss: 0.9353 - val_accuracy: 0.6110 - val_loss: 1.0654\n",
      "Epoch 55/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6699 - loss: 0.9254 - val_accuracy: 0.6151 - val_loss: 0.9984\n",
      "Epoch 56/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6774 - loss: 0.9171 - val_accuracy: 0.6130 - val_loss: 1.0237\n",
      "Epoch 57/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6608 - loss: 0.9114 - val_accuracy: 0.5621 - val_loss: 1.1015\n",
      "Epoch 58/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6729 - loss: 0.8950 - val_accuracy: 0.6090 - val_loss: 1.0254\n",
      "Epoch 59/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6722 - loss: 0.8817 - val_accuracy: 0.5988 - val_loss: 1.0174\n",
      "Epoch 60/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6826 - loss: 0.8634 - val_accuracy: 0.6029 - val_loss: 0.9953\n",
      "Epoch 61/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6813 - loss: 0.8464 - val_accuracy: 0.6090 - val_loss: 0.9955\n",
      "Epoch 62/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6932 - loss: 0.8455 - val_accuracy: 0.6171 - val_loss: 0.9801\n",
      "Epoch 63/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6781 - loss: 0.8487 - val_accuracy: 0.6151 - val_loss: 1.0192\n",
      "Epoch 64/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6742 - loss: 0.8569 - val_accuracy: 0.6293 - val_loss: 0.9866\n",
      "Epoch 65/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6907 - loss: 0.8349 - val_accuracy: 0.6232 - val_loss: 0.9603\n",
      "Epoch 66/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6767 - loss: 0.8369 - val_accuracy: 0.6191 - val_loss: 0.9994\n",
      "Epoch 67/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6729 - loss: 0.8822 - val_accuracy: 0.6151 - val_loss: 0.9700\n",
      "Epoch 68/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7036 - loss: 0.8119 - val_accuracy: 0.5988 - val_loss: 0.9928\n",
      "Epoch 69/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6877 - loss: 0.8141 - val_accuracy: 0.6232 - val_loss: 0.9820\n",
      "Epoch 70/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6883 - loss: 0.8602 - val_accuracy: 0.6130 - val_loss: 0.9962\n",
      "Epoch 71/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6758 - loss: 0.8762 - val_accuracy: 0.6171 - val_loss: 0.9811\n",
      "Epoch 72/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6665 - loss: 0.8532 - val_accuracy: 0.6171 - val_loss: 0.9917\n",
      "Epoch 73/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6911 - loss: 0.8316 - val_accuracy: 0.6191 - val_loss: 0.9851\n",
      "Epoch 74/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6798 - loss: 0.8409 - val_accuracy: 0.5967 - val_loss: 1.0187\n",
      "Epoch 75/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6820 - loss: 0.8539 - val_accuracy: 0.6212 - val_loss: 0.9968\n",
      "Epoch 76/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6801 - loss: 0.8545 - val_accuracy: 0.6293 - val_loss: 0.9738\n",
      "Epoch 77/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6809 - loss: 0.8733 - val_accuracy: 0.6212 - val_loss: 0.9635\n",
      "Epoch 78/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6744 - loss: 0.8681 - val_accuracy: 0.6090 - val_loss: 1.0026\n",
      "Epoch 79/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7196 - loss: 0.7747 - val_accuracy: 0.6029 - val_loss: 1.0356\n",
      "Epoch 80/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6756 - loss: 0.8317 - val_accuracy: 0.6293 - val_loss: 0.9751\n",
      "Epoch 81/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6889 - loss: 0.7948 - val_accuracy: 0.6253 - val_loss: 0.9660\n",
      "Epoch 82/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7000 - loss: 0.7808 - val_accuracy: 0.6130 - val_loss: 0.9790\n",
      "Epoch 83/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6924 - loss: 0.8209 - val_accuracy: 0.6253 - val_loss: 0.9632\n",
      "Epoch 84/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7090 - loss: 0.7835 - val_accuracy: 0.6293 - val_loss: 0.9748\n",
      "Epoch 85/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7179 - loss: 0.7463 - val_accuracy: 0.6415 - val_loss: 0.9847\n",
      "Epoch 86/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7060 - loss: 0.8044 - val_accuracy: 0.6253 - val_loss: 0.9938\n",
      "Epoch 87/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7078 - loss: 0.7778 - val_accuracy: 0.6232 - val_loss: 1.0261\n",
      "Epoch 88/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7000 - loss: 0.8133 - val_accuracy: 0.6212 - val_loss: 0.9824\n",
      "Epoch 89/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6993 - loss: 0.7874 - val_accuracy: 0.6171 - val_loss: 1.0135\n",
      "Epoch 90/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6984 - loss: 0.7931 - val_accuracy: 0.6477 - val_loss: 0.9506\n",
      "Epoch 91/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7203 - loss: 0.7436 - val_accuracy: 0.6212 - val_loss: 0.9618\n",
      "Epoch 92/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7022 - loss: 0.7961 - val_accuracy: 0.6212 - val_loss: 1.0140\n",
      "Epoch 93/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7001 - loss: 0.7987 - val_accuracy: 0.6232 - val_loss: 0.9797\n",
      "Epoch 94/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7146 - loss: 0.7954 - val_accuracy: 0.6375 - val_loss: 1.0059\n",
      "Epoch 95/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7133 - loss: 0.7647 - val_accuracy: 0.6110 - val_loss: 1.0441\n",
      "Epoch 96/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7173 - loss: 0.7489 - val_accuracy: 0.6334 - val_loss: 0.9537\n",
      "Epoch 97/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7123 - loss: 0.7727 - val_accuracy: 0.6293 - val_loss: 0.9850\n",
      "Epoch 98/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7138 - loss: 0.7817 - val_accuracy: 0.6273 - val_loss: 0.9711\n",
      "Epoch 99/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6822 - loss: 0.8309 - val_accuracy: 0.6293 - val_loss: 0.9531\n",
      "Epoch 100/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7047 - loss: 0.7504 - val_accuracy: 0.6314 - val_loss: 0.9394\n",
      "Epoch 101/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7368 - loss: 0.7369 - val_accuracy: 0.6212 - val_loss: 0.9561\n",
      "Epoch 102/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7215 - loss: 0.7520 - val_accuracy: 0.6477 - val_loss: 0.9540\n",
      "Epoch 103/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6902 - loss: 0.7871 - val_accuracy: 0.6354 - val_loss: 0.9527\n",
      "Epoch 104/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6836 - loss: 0.8240 - val_accuracy: 0.6517 - val_loss: 0.9631\n",
      "Epoch 105/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7087 - loss: 0.7648 - val_accuracy: 0.6436 - val_loss: 0.9357\n",
      "Epoch 106/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7217 - loss: 0.7425 - val_accuracy: 0.6477 - val_loss: 0.9292\n",
      "Epoch 107/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7349 - loss: 0.7281 - val_accuracy: 0.6212 - val_loss: 0.9820\n",
      "Epoch 108/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7279 - loss: 0.7269 - val_accuracy: 0.6354 - val_loss: 0.9408\n",
      "Epoch 109/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7230 - loss: 0.7544 - val_accuracy: 0.6191 - val_loss: 0.9749\n",
      "Epoch 110/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7016 - loss: 0.7579 - val_accuracy: 0.6334 - val_loss: 0.9491\n",
      "Epoch 111/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7235 - loss: 0.7225 - val_accuracy: 0.6232 - val_loss: 0.9647\n",
      "Epoch 112/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6862 - loss: 0.7931 - val_accuracy: 0.6415 - val_loss: 0.9393\n",
      "Epoch 113/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7300 - loss: 0.7241 - val_accuracy: 0.6477 - val_loss: 0.9553\n",
      "Epoch 114/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6861 - loss: 0.8073 - val_accuracy: 0.6375 - val_loss: 0.9651\n",
      "Epoch 115/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7002 - loss: 0.8033 - val_accuracy: 0.6191 - val_loss: 0.9731\n",
      "Epoch 116/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7282 - loss: 0.7344 - val_accuracy: 0.6375 - val_loss: 0.9615\n",
      "Epoch 117/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7181 - loss: 0.7366 - val_accuracy: 0.6497 - val_loss: 0.9338\n",
      "Epoch 118/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7144 - loss: 0.7449 - val_accuracy: 0.6497 - val_loss: 0.9683\n",
      "Epoch 119/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7407 - loss: 0.6943 - val_accuracy: 0.6354 - val_loss: 0.9695\n",
      "Epoch 120/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7216 - loss: 0.7066 - val_accuracy: 0.6375 - val_loss: 0.9726\n",
      "Epoch 121/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7291 - loss: 0.7237 - val_accuracy: 0.6314 - val_loss: 1.0013\n",
      "Epoch 122/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7397 - loss: 0.6982 - val_accuracy: 0.6436 - val_loss: 0.9725\n",
      "Epoch 123/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7321 - loss: 0.7295 - val_accuracy: 0.6436 - val_loss: 0.9817\n",
      "Epoch 124/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7281 - loss: 0.6912 - val_accuracy: 0.6436 - val_loss: 0.9611\n",
      "Epoch 125/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7497 - loss: 0.6731 - val_accuracy: 0.6273 - val_loss: 0.9720\n",
      "Epoch 126/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7439 - loss: 0.7315 - val_accuracy: 0.6395 - val_loss: 0.9471\n",
      "Epoch 127/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7570 - loss: 0.6935 - val_accuracy: 0.6354 - val_loss: 0.9768\n",
      "Epoch 128/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7331 - loss: 0.6963 - val_accuracy: 0.6375 - val_loss: 0.9529\n",
      "Epoch 129/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7263 - loss: 0.7185 - val_accuracy: 0.6477 - val_loss: 0.9517\n",
      "Epoch 130/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7271 - loss: 0.6891 - val_accuracy: 0.6375 - val_loss: 0.9687\n",
      "Epoch 131/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7284 - loss: 0.6870 - val_accuracy: 0.6578 - val_loss: 0.9615\n",
      "Epoch 132/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7530 - loss: 0.6761 - val_accuracy: 0.6477 - val_loss: 0.9600\n",
      "Epoch 133/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7145 - loss: 0.7566 - val_accuracy: 0.6334 - val_loss: 0.9730\n",
      "Epoch 134/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7446 - loss: 0.6936 - val_accuracy: 0.6619 - val_loss: 0.9261\n",
      "Epoch 135/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7298 - loss: 0.7468 - val_accuracy: 0.6538 - val_loss: 0.9809\n",
      "Epoch 136/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7383 - loss: 0.6876 - val_accuracy: 0.6456 - val_loss: 0.9781\n",
      "Epoch 137/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7408 - loss: 0.6826 - val_accuracy: 0.6415 - val_loss: 0.9839\n",
      "Epoch 138/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7465 - loss: 0.6975 - val_accuracy: 0.6415 - val_loss: 0.9697\n",
      "Epoch 139/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7556 - loss: 0.6608 - val_accuracy: 0.6456 - val_loss: 0.9700\n",
      "Epoch 140/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7591 - loss: 0.6604 - val_accuracy: 0.6660 - val_loss: 0.9436\n",
      "Epoch 141/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7606 - loss: 0.6273 - val_accuracy: 0.6517 - val_loss: 0.9791\n",
      "Epoch 142/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7466 - loss: 0.6689 - val_accuracy: 0.6436 - val_loss: 0.9456\n",
      "Epoch 143/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7416 - loss: 0.6868 - val_accuracy: 0.6415 - val_loss: 0.9676\n",
      "Epoch 144/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7151 - loss: 0.7403 - val_accuracy: 0.6477 - val_loss: 0.9482\n",
      "Epoch 145/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7470 - loss: 0.6782 - val_accuracy: 0.6456 - val_loss: 0.9491\n",
      "Epoch 146/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7321 - loss: 0.6953 - val_accuracy: 0.6558 - val_loss: 0.9343\n",
      "Epoch 147/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7344 - loss: 0.6978 - val_accuracy: 0.6517 - val_loss: 0.9593\n",
      "Epoch 148/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7548 - loss: 0.6740 - val_accuracy: 0.6578 - val_loss: 0.9671\n",
      "Epoch 149/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7326 - loss: 0.6956 - val_accuracy: 0.6456 - val_loss: 1.0029\n",
      "Epoch 150/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7434 - loss: 0.6913 - val_accuracy: 0.6395 - val_loss: 0.9381\n",
      "Epoch 151/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7422 - loss: 0.7050 - val_accuracy: 0.6415 - val_loss: 0.9500\n",
      "Epoch 152/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7453 - loss: 0.6579 - val_accuracy: 0.6273 - val_loss: 1.0106\n",
      "Epoch 153/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7398 - loss: 0.6898 - val_accuracy: 0.6578 - val_loss: 0.9662\n",
      "Epoch 154/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7145 - loss: 0.7184 - val_accuracy: 0.6395 - val_loss: 0.9895\n",
      "Epoch 155/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7497 - loss: 0.6584 - val_accuracy: 0.6456 - val_loss: 0.9762\n",
      "Epoch 156/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7587 - loss: 0.6413 - val_accuracy: 0.6314 - val_loss: 0.9612\n",
      "Epoch 157/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7668 - loss: 0.6251 - val_accuracy: 0.6517 - val_loss: 0.9507\n",
      "Epoch 158/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7635 - loss: 0.6269 - val_accuracy: 0.6599 - val_loss: 0.9585\n",
      "Epoch 159/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7599 - loss: 0.6358 - val_accuracy: 0.6640 - val_loss: 0.9300\n",
      "Epoch 160/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7771 - loss: 0.6084 - val_accuracy: 0.6375 - val_loss: 0.9420\n",
      "Epoch 161/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7543 - loss: 0.6443 - val_accuracy: 0.6477 - val_loss: 0.9588\n",
      "Epoch 162/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7514 - loss: 0.6532 - val_accuracy: 0.6415 - val_loss: 0.9749\n",
      "Epoch 163/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7552 - loss: 0.6218 - val_accuracy: 0.6314 - val_loss: 1.0199\n",
      "Epoch 164/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7397 - loss: 0.6926 - val_accuracy: 0.6477 - val_loss: 0.9890\n",
      "Epoch 165/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7561 - loss: 0.6735 - val_accuracy: 0.6334 - val_loss: 0.9717\n",
      "Epoch 166/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7447 - loss: 0.6806 - val_accuracy: 0.6497 - val_loss: 0.9546\n",
      "Epoch 167/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7550 - loss: 0.6373 - val_accuracy: 0.6354 - val_loss: 0.9906\n",
      "Epoch 168/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7775 - loss: 0.6126 - val_accuracy: 0.6456 - val_loss: 0.9958\n",
      "Epoch 169/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7375 - loss: 0.6859 - val_accuracy: 0.6538 - val_loss: 0.9548\n",
      "Epoch 170/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7652 - loss: 0.6307 - val_accuracy: 0.6578 - val_loss: 0.9150\n",
      "Epoch 171/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7522 - loss: 0.6233 - val_accuracy: 0.6497 - val_loss: 1.0375\n",
      "Epoch 172/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7423 - loss: 0.6572 - val_accuracy: 0.6375 - val_loss: 1.0426\n",
      "Epoch 173/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7506 - loss: 0.6588 - val_accuracy: 0.6497 - val_loss: 1.0004\n",
      "Epoch 174/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7629 - loss: 0.6273 - val_accuracy: 0.6456 - val_loss: 0.9723\n",
      "Epoch 175/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7797 - loss: 0.6049 - val_accuracy: 0.6578 - val_loss: 0.9612\n",
      "Epoch 176/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7645 - loss: 0.6202 - val_accuracy: 0.6640 - val_loss: 0.9487\n",
      "Epoch 177/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7789 - loss: 0.5852 - val_accuracy: 0.6456 - val_loss: 0.9538\n",
      "Epoch 178/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7800 - loss: 0.5965 - val_accuracy: 0.6619 - val_loss: 0.9553\n",
      "Epoch 179/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7568 - loss: 0.6452 - val_accuracy: 0.6640 - val_loss: 0.9876\n",
      "Epoch 180/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7781 - loss: 0.5931 - val_accuracy: 0.6599 - val_loss: 0.9915\n",
      "Epoch 181/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7520 - loss: 0.6650 - val_accuracy: 0.6456 - val_loss: 0.9884\n",
      "Epoch 182/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7632 - loss: 0.6054 - val_accuracy: 0.6436 - val_loss: 1.0026\n",
      "Epoch 183/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7592 - loss: 0.6232 - val_accuracy: 0.6558 - val_loss: 0.9480\n",
      "Epoch 184/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7665 - loss: 0.6320 - val_accuracy: 0.6477 - val_loss: 0.9626\n",
      "Epoch 185/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7560 - loss: 0.6393 - val_accuracy: 0.6436 - val_loss: 0.9475\n",
      "Epoch 186/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7678 - loss: 0.6235 - val_accuracy: 0.6212 - val_loss: 1.0280\n",
      "Epoch 187/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7712 - loss: 0.6299 - val_accuracy: 0.6314 - val_loss: 0.9814\n",
      "Epoch 188/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7702 - loss: 0.6236 - val_accuracy: 0.6456 - val_loss: 0.9631\n",
      "Epoch 189/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7786 - loss: 0.5932 - val_accuracy: 0.6640 - val_loss: 0.9410\n",
      "Epoch 190/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7726 - loss: 0.6104 - val_accuracy: 0.6640 - val_loss: 0.9779\n",
      "Epoch 191/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7451 - loss: 0.6658 - val_accuracy: 0.6660 - val_loss: 0.9268\n",
      "Epoch 192/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7870 - loss: 0.5709 - val_accuracy: 0.6497 - val_loss: 0.9472\n",
      "Epoch 193/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7694 - loss: 0.5985 - val_accuracy: 0.6517 - val_loss: 0.9865\n",
      "Epoch 194/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7719 - loss: 0.5997 - val_accuracy: 0.6436 - val_loss: 1.0217\n",
      "Epoch 195/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7713 - loss: 0.6094 - val_accuracy: 0.6619 - val_loss: 0.9609\n",
      "Epoch 196/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7668 - loss: 0.6060 - val_accuracy: 0.6640 - val_loss: 0.9891\n",
      "Epoch 197/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7810 - loss: 0.5864 - val_accuracy: 0.6497 - val_loss: 0.9718\n",
      "Epoch 198/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7853 - loss: 0.5666 - val_accuracy: 0.6538 - val_loss: 1.0211\n",
      "Epoch 199/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7889 - loss: 0.5731 - val_accuracy: 0.6354 - val_loss: 0.9594\n",
      "Epoch 200/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7728 - loss: 0.6195 - val_accuracy: 0.6477 - val_loss: 1.0279\n",
      "Epoch 201/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7762 - loss: 0.5982 - val_accuracy: 0.6558 - val_loss: 1.0553\n",
      "Epoch 202/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7709 - loss: 0.5998 - val_accuracy: 0.6517 - val_loss: 1.0794\n",
      "Epoch 203/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7565 - loss: 0.6521 - val_accuracy: 0.6538 - val_loss: 0.9704\n",
      "Epoch 204/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7444 - loss: 0.6379 - val_accuracy: 0.6477 - val_loss: 0.9880\n",
      "Epoch 205/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7831 - loss: 0.6020 - val_accuracy: 0.6456 - val_loss: 0.9900\n",
      "Epoch 206/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7835 - loss: 0.5822 - val_accuracy: 0.6517 - val_loss: 1.0100\n",
      "Epoch 207/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7659 - loss: 0.6121 - val_accuracy: 0.6456 - val_loss: 1.0205\n",
      "Epoch 208/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7900 - loss: 0.5895 - val_accuracy: 0.6497 - val_loss: 0.9544\n",
      "Epoch 209/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7866 - loss: 0.5688 - val_accuracy: 0.6334 - val_loss: 0.9835\n",
      "Epoch 210/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7837 - loss: 0.5601 - val_accuracy: 0.6578 - val_loss: 1.0045\n",
      "Epoch 211/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7798 - loss: 0.5930 - val_accuracy: 0.6538 - val_loss: 0.9961\n",
      "Epoch 212/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7952 - loss: 0.5626 - val_accuracy: 0.6517 - val_loss: 1.0129\n",
      "Epoch 213/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7716 - loss: 0.6136 - val_accuracy: 0.6456 - val_loss: 0.9590\n",
      "Epoch 214/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7556 - loss: 0.6496 - val_accuracy: 0.6538 - val_loss: 0.9895\n",
      "Epoch 215/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7606 - loss: 0.6128 - val_accuracy: 0.6517 - val_loss: 0.9652\n",
      "Epoch 216/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7632 - loss: 0.6400 - val_accuracy: 0.6354 - val_loss: 0.9805\n",
      "Epoch 217/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7746 - loss: 0.6069 - val_accuracy: 0.6517 - val_loss: 0.9769\n",
      "Epoch 218/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7883 - loss: 0.5515 - val_accuracy: 0.6599 - val_loss: 0.9378\n",
      "Epoch 219/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7945 - loss: 0.5663 - val_accuracy: 0.6558 - val_loss: 1.0386\n",
      "Epoch 220/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.5795 - val_accuracy: 0.6497 - val_loss: 0.9844\n",
      "Epoch 221/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7828 - loss: 0.5773 - val_accuracy: 0.6558 - val_loss: 0.9375\n",
      "Epoch 222/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7724 - loss: 0.6103 - val_accuracy: 0.6558 - val_loss: 0.9890\n",
      "Epoch 223/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7746 - loss: 0.5945 - val_accuracy: 0.6578 - val_loss: 0.9310\n",
      "Epoch 224/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7805 - loss: 0.5744 - val_accuracy: 0.6558 - val_loss: 0.9836\n",
      "Epoch 225/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7870 - loss: 0.5215 - val_accuracy: 0.6721 - val_loss: 0.9925\n",
      "Epoch 226/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7836 - loss: 0.5723 - val_accuracy: 0.6660 - val_loss: 0.9786\n",
      "Epoch 227/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7676 - loss: 0.6113 - val_accuracy: 0.6456 - val_loss: 0.9650\n",
      "Epoch 228/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7778 - loss: 0.5540 - val_accuracy: 0.6701 - val_loss: 0.9814\n",
      "Epoch 229/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7911 - loss: 0.5428 - val_accuracy: 0.6477 - val_loss: 1.0253\n",
      "Epoch 230/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7937 - loss: 0.5891 - val_accuracy: 0.6578 - val_loss: 0.9667\n",
      "Epoch 231/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7983 - loss: 0.5479 - val_accuracy: 0.6701 - val_loss: 0.9735\n",
      "Epoch 232/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7809 - loss: 0.5797 - val_accuracy: 0.6517 - val_loss: 0.9903\n",
      "Epoch 233/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7816 - loss: 0.6139 - val_accuracy: 0.6375 - val_loss: 0.9988\n",
      "Epoch 234/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7754 - loss: 0.5728 - val_accuracy: 0.6599 - val_loss: 0.9495\n",
      "Epoch 235/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7882 - loss: 0.5800 - val_accuracy: 0.6578 - val_loss: 1.0063\n",
      "Epoch 236/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7653 - loss: 0.6438 - val_accuracy: 0.6497 - val_loss: 0.9886\n",
      "Epoch 237/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7717 - loss: 0.5644 - val_accuracy: 0.6680 - val_loss: 1.0229\n",
      "Epoch 238/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7948 - loss: 0.5654 - val_accuracy: 0.6619 - val_loss: 0.9443\n",
      "Epoch 239/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8014 - loss: 0.5389 - val_accuracy: 0.6619 - val_loss: 0.9759\n",
      "Epoch 240/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7869 - loss: 0.5847 - val_accuracy: 0.6680 - val_loss: 0.9480\n",
      "Epoch 241/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7842 - loss: 0.5568 - val_accuracy: 0.6578 - val_loss: 0.9688\n",
      "Epoch 242/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8083 - loss: 0.5198 - val_accuracy: 0.6619 - val_loss: 0.9866\n",
      "Epoch 243/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8044 - loss: 0.5295 - val_accuracy: 0.6762 - val_loss: 0.9209\n",
      "Epoch 244/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7840 - loss: 0.5531 - val_accuracy: 0.6802 - val_loss: 0.9954\n",
      "Epoch 245/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7888 - loss: 0.5524 - val_accuracy: 0.6660 - val_loss: 0.9957\n",
      "Epoch 246/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8014 - loss: 0.5442 - val_accuracy: 0.6558 - val_loss: 0.9936\n",
      "Epoch 247/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7892 - loss: 0.5640 - val_accuracy: 0.6701 - val_loss: 0.9990\n",
      "Epoch 248/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7900 - loss: 0.5698 - val_accuracy: 0.6619 - val_loss: 1.0119\n",
      "Epoch 249/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7811 - loss: 0.5768 - val_accuracy: 0.6823 - val_loss: 0.9556\n",
      "Epoch 250/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7984 - loss: 0.5331 - val_accuracy: 0.6782 - val_loss: 0.9924\n",
      "Epoch 251/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8007 - loss: 0.5445 - val_accuracy: 0.6782 - val_loss: 0.9488\n",
      "Epoch 252/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7797 - loss: 0.5851 - val_accuracy: 0.6558 - val_loss: 1.0014\n",
      "Epoch 253/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7809 - loss: 0.5899 - val_accuracy: 0.6762 - val_loss: 0.9315\n",
      "Epoch 254/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8042 - loss: 0.5354 - val_accuracy: 0.6456 - val_loss: 0.9964\n",
      "Epoch 255/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7897 - loss: 0.5421 - val_accuracy: 0.6721 - val_loss: 1.0065\n",
      "Epoch 256/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7736 - loss: 0.5767 - val_accuracy: 0.6762 - val_loss: 0.9691\n",
      "Epoch 257/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8030 - loss: 0.5232 - val_accuracy: 0.6538 - val_loss: 1.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.5252 - val_accuracy: 0.6314 - val_loss: 1.0385\n",
      "Epoch 259/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8066 - loss: 0.5198 - val_accuracy: 0.6823 - val_loss: 0.9993\n",
      "Epoch 260/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7836 - loss: 0.5667 - val_accuracy: 0.6640 - val_loss: 0.9658\n",
      "Epoch 261/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7970 - loss: 0.5369 - val_accuracy: 0.6497 - val_loss: 1.0040\n",
      "Epoch 262/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8069 - loss: 0.5428 - val_accuracy: 0.6558 - val_loss: 1.0183\n",
      "Epoch 263/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8064 - loss: 0.5483 - val_accuracy: 0.6640 - val_loss: 0.9742\n",
      "Epoch 264/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8005 - loss: 0.5504 - val_accuracy: 0.6843 - val_loss: 0.9760\n",
      "Epoch 265/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8211 - loss: 0.5186 - val_accuracy: 0.6864 - val_loss: 1.0231\n",
      "Epoch 266/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8152 - loss: 0.4999 - val_accuracy: 0.6517 - val_loss: 1.0182\n",
      "Epoch 267/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7791 - loss: 0.5555 - val_accuracy: 0.6741 - val_loss: 1.0051\n",
      "Epoch 268/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8204 - loss: 0.5112 - val_accuracy: 0.6782 - val_loss: 1.0245\n",
      "Epoch 269/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7920 - loss: 0.5122 - val_accuracy: 0.6782 - val_loss: 0.9652\n",
      "Epoch 270/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7782 - loss: 0.5993 - val_accuracy: 0.6578 - val_loss: 0.9364\n",
      "Epoch 271/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7934 - loss: 0.5462 - val_accuracy: 0.6701 - val_loss: 0.9734\n",
      "Epoch 272/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8053 - loss: 0.5229 - val_accuracy: 0.6538 - val_loss: 1.0080\n",
      "Epoch 273/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 0.5079 - val_accuracy: 0.6599 - val_loss: 1.0325\n",
      "Epoch 274/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7916 - loss: 0.5363 - val_accuracy: 0.6680 - val_loss: 1.0191\n",
      "Epoch 275/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8188 - loss: 0.5083 - val_accuracy: 0.6741 - val_loss: 1.0797\n",
      "Epoch 276/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8006 - loss: 0.5139 - val_accuracy: 0.6843 - val_loss: 0.9997\n",
      "Epoch 277/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7666 - loss: 0.5871 - val_accuracy: 0.6619 - val_loss: 0.9666\n",
      "Epoch 278/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7750 - loss: 0.6136 - val_accuracy: 0.6741 - val_loss: 0.9895\n",
      "Epoch 279/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7871 - loss: 0.5727 - val_accuracy: 0.6741 - val_loss: 0.9729\n",
      "Epoch 280/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8167 - loss: 0.4916 - val_accuracy: 0.6843 - val_loss: 0.9693\n",
      "Epoch 281/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8049 - loss: 0.5425 - val_accuracy: 0.6640 - val_loss: 1.0202\n",
      "Epoch 282/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8038 - loss: 0.5310 - val_accuracy: 0.6660 - val_loss: 1.0207\n",
      "Epoch 283/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7963 - loss: 0.5157 - val_accuracy: 0.6517 - val_loss: 1.0362\n",
      "Epoch 284/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8163 - loss: 0.4870 - val_accuracy: 0.6558 - val_loss: 1.0398\n",
      "Epoch 285/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7961 - loss: 0.5589 - val_accuracy: 0.6293 - val_loss: 1.0364\n",
      "Epoch 286/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 0.5250 - val_accuracy: 0.6517 - val_loss: 1.0646\n",
      "Epoch 287/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7926 - loss: 0.5244 - val_accuracy: 0.6538 - val_loss: 1.0257\n",
      "Epoch 288/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.5160 - val_accuracy: 0.6517 - val_loss: 1.0614\n",
      "Epoch 289/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8219 - loss: 0.5151 - val_accuracy: 0.6640 - val_loss: 1.0036\n",
      "Epoch 290/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7818 - loss: 0.5638 - val_accuracy: 0.6640 - val_loss: 1.0239\n",
      "Epoch 291/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7938 - loss: 0.5487 - val_accuracy: 0.6538 - val_loss: 0.9888\n",
      "Epoch 292/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8042 - loss: 0.5524 - val_accuracy: 0.6660 - val_loss: 1.0222\n",
      "Epoch 293/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7960 - loss: 0.5781 - val_accuracy: 0.6578 - val_loss: 1.0077\n",
      "Epoch 294/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8131 - loss: 0.4947 - val_accuracy: 0.6762 - val_loss: 0.9961\n",
      "Epoch 295/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7981 - loss: 0.5408 - val_accuracy: 0.6701 - val_loss: 1.0189\n",
      "Epoch 296/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7887 - loss: 0.5612 - val_accuracy: 0.6599 - val_loss: 1.0052\n",
      "Epoch 297/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7827 - loss: 0.5437 - val_accuracy: 0.6741 - val_loss: 0.9792\n",
      "Epoch 298/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8055 - loss: 0.5309 - val_accuracy: 0.6721 - val_loss: 0.9667\n",
      "Epoch 299/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.5275 - val_accuracy: 0.6680 - val_loss: 1.0239\n",
      "Epoch 300/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8199 - loss: 0.5070 - val_accuracy: 0.6660 - val_loss: 1.0371\n",
      "Epoch 301/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7816 - loss: 0.5887 - val_accuracy: 0.6640 - val_loss: 0.9945\n",
      "Epoch 302/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7609 - loss: 0.6213 - val_accuracy: 0.6660 - val_loss: 0.9786\n",
      "Epoch 303/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 0.4997 - val_accuracy: 0.6680 - val_loss: 1.0104\n",
      "Epoch 304/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8094 - loss: 0.5208 - val_accuracy: 0.6660 - val_loss: 0.9854\n",
      "Epoch 305/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8248 - loss: 0.5096 - val_accuracy: 0.6640 - val_loss: 1.0724\n",
      "Epoch 306/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8101 - loss: 0.5138 - val_accuracy: 0.6762 - val_loss: 1.0074\n",
      "Epoch 307/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8143 - loss: 0.5152 - val_accuracy: 0.6660 - val_loss: 1.0387\n",
      "Epoch 308/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8117 - loss: 0.5038 - val_accuracy: 0.6802 - val_loss: 0.9956\n",
      "Epoch 309/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7894 - loss: 0.5643 - val_accuracy: 0.6619 - val_loss: 1.0818\n",
      "Epoch 310/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7759 - loss: 0.5528 - val_accuracy: 0.6599 - val_loss: 1.0906\n",
      "Epoch 311/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.5267 - val_accuracy: 0.6782 - val_loss: 1.0341\n",
      "Epoch 312/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8104 - loss: 0.5387 - val_accuracy: 0.6701 - val_loss: 1.0155\n",
      "Epoch 313/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 0.4895 - val_accuracy: 0.6599 - val_loss: 1.0255\n",
      "Epoch 314/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.4951 - val_accuracy: 0.6497 - val_loss: 1.0791\n",
      "Epoch 315/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8155 - loss: 0.5104 - val_accuracy: 0.6843 - val_loss: 1.0537\n",
      "Epoch 316/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.4909 - val_accuracy: 0.6599 - val_loss: 1.0619\n",
      "Epoch 317/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8199 - loss: 0.4641 - val_accuracy: 0.6497 - val_loss: 1.0899\n",
      "Epoch 318/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7924 - loss: 0.5454 - val_accuracy: 0.6701 - val_loss: 1.0711\n",
      "Epoch 319/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8224 - loss: 0.4828 - val_accuracy: 0.6578 - val_loss: 1.0909\n",
      "Epoch 320/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7922 - loss: 0.5340 - val_accuracy: 0.6762 - val_loss: 1.0002\n",
      "Epoch 321/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8072 - loss: 0.5032 - val_accuracy: 0.6721 - val_loss: 0.9938\n",
      "Epoch 322/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7997 - loss: 0.5456 - val_accuracy: 0.6640 - val_loss: 1.0215\n",
      "Epoch 323/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8184 - loss: 0.4763 - val_accuracy: 0.6456 - val_loss: 1.1049\n",
      "Epoch 324/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7966 - loss: 0.5346 - val_accuracy: 0.6986 - val_loss: 1.0159\n",
      "Epoch 325/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8229 - loss: 0.4928 - val_accuracy: 0.6782 - val_loss: 1.0365\n",
      "Epoch 326/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7885 - loss: 0.5374 - val_accuracy: 0.6497 - val_loss: 1.0263\n",
      "Epoch 327/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7984 - loss: 0.5242 - val_accuracy: 0.6680 - val_loss: 1.0384\n",
      "Epoch 328/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8260 - loss: 0.4834 - val_accuracy: 0.6802 - val_loss: 0.9974\n",
      "Epoch 329/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8231 - loss: 0.4713 - val_accuracy: 0.6823 - val_loss: 1.0039\n",
      "Epoch 330/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8138 - loss: 0.5092 - val_accuracy: 0.6864 - val_loss: 0.9846\n",
      "Epoch 331/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8206 - loss: 0.5011 - val_accuracy: 0.6864 - val_loss: 1.0297\n",
      "Epoch 332/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8247 - loss: 0.4916 - val_accuracy: 0.6721 - val_loss: 1.0058\n",
      "Epoch 333/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8239 - loss: 0.4653 - val_accuracy: 0.6802 - val_loss: 0.9747\n",
      "Epoch 334/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8100 - loss: 0.5146 - val_accuracy: 0.6680 - val_loss: 1.0756\n",
      "Epoch 335/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7896 - loss: 0.5539 - val_accuracy: 0.6599 - val_loss: 1.0514\n",
      "Epoch 336/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7905 - loss: 0.5329 - val_accuracy: 0.6762 - val_loss: 1.0357\n",
      "Epoch 337/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 0.5155 - val_accuracy: 0.6762 - val_loss: 1.0546\n",
      "Epoch 338/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8234 - loss: 0.4755 - val_accuracy: 0.6619 - val_loss: 0.9867\n",
      "Epoch 339/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 0.4927 - val_accuracy: 0.6904 - val_loss: 0.9930\n",
      "Epoch 340/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.5114 - val_accuracy: 0.6640 - val_loss: 1.0035\n",
      "Epoch 341/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8156 - loss: 0.4972 - val_accuracy: 0.6680 - val_loss: 1.0344\n",
      "Epoch 342/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8041 - loss: 0.5043 - val_accuracy: 0.6680 - val_loss: 1.0580\n",
      "Epoch 343/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8033 - loss: 0.5170 - val_accuracy: 0.6660 - val_loss: 1.0504\n",
      "Epoch 344/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8547 - loss: 0.4186 - val_accuracy: 0.6619 - val_loss: 1.0263\n",
      "Epoch 345/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8223 - loss: 0.4761 - val_accuracy: 0.6660 - val_loss: 1.0278\n",
      "Epoch 346/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7959 - loss: 0.5259 - val_accuracy: 0.6619 - val_loss: 1.0348\n",
      "Epoch 347/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7932 - loss: 0.5445 - val_accuracy: 0.6640 - val_loss: 1.0159\n",
      "Epoch 348/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7969 - loss: 0.5297 - val_accuracy: 0.6436 - val_loss: 1.0724\n",
      "Epoch 349/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7951 - loss: 0.5013 - val_accuracy: 0.6762 - val_loss: 1.0190\n",
      "Epoch 350/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8033 - loss: 0.5093 - val_accuracy: 0.6599 - val_loss: 1.0520\n",
      "Epoch 351/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8138 - loss: 0.5239 - val_accuracy: 0.6721 - val_loss: 1.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8442 - loss: 0.4390 - val_accuracy: 0.6456 - val_loss: 1.1209\n",
      "Epoch 353/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8192 - loss: 0.4955 - val_accuracy: 0.6741 - val_loss: 0.9951\n",
      "Epoch 354/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8226 - loss: 0.4960 - val_accuracy: 0.6619 - val_loss: 1.0460\n",
      "Epoch 355/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8150 - loss: 0.4978 - val_accuracy: 0.6925 - val_loss: 0.9886\n",
      "Epoch 356/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8175 - loss: 0.4960 - val_accuracy: 0.6741 - val_loss: 0.9677\n",
      "Epoch 357/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8151 - loss: 0.4808 - val_accuracy: 0.6782 - val_loss: 0.9971\n",
      "Epoch 358/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8256 - loss: 0.4854 - val_accuracy: 0.6884 - val_loss: 1.0305\n",
      "Epoch 359/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8405 - loss: 0.4488 - val_accuracy: 0.6782 - val_loss: 1.0089\n",
      "Epoch 360/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8261 - loss: 0.4647 - val_accuracy: 0.6721 - val_loss: 1.0473\n",
      "Epoch 361/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8177 - loss: 0.4757 - val_accuracy: 0.6741 - val_loss: 1.0194\n",
      "Epoch 362/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8100 - loss: 0.4846 - val_accuracy: 0.6721 - val_loss: 1.0471\n",
      "Epoch 363/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8500 - loss: 0.4334 - val_accuracy: 0.6782 - val_loss: 0.9938\n",
      "Epoch 364/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8102 - loss: 0.4985 - val_accuracy: 0.6640 - val_loss: 1.0549\n",
      "Epoch 365/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8024 - loss: 0.5243 - val_accuracy: 0.6741 - val_loss: 1.0293\n",
      "Epoch 366/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7925 - loss: 0.5689 - val_accuracy: 0.6558 - val_loss: 1.0490\n",
      "Epoch 367/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8195 - loss: 0.4579 - val_accuracy: 0.6660 - val_loss: 1.0686\n",
      "Epoch 368/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8144 - loss: 0.4990 - val_accuracy: 0.6741 - val_loss: 1.0284\n",
      "Epoch 369/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8224 - loss: 0.4988 - val_accuracy: 0.6762 - val_loss: 0.9882\n",
      "Epoch 370/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7923 - loss: 0.5151 - val_accuracy: 0.6802 - val_loss: 0.9919\n",
      "Epoch 371/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8382 - loss: 0.4560 - val_accuracy: 0.6599 - val_loss: 1.1158\n",
      "Epoch 372/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8101 - loss: 0.5080 - val_accuracy: 0.6538 - val_loss: 0.9966\n",
      "Epoch 373/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8160 - loss: 0.4837 - val_accuracy: 0.6721 - val_loss: 1.0648\n",
      "Epoch 374/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8288 - loss: 0.4735 - val_accuracy: 0.6701 - val_loss: 1.0758\n",
      "Epoch 375/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8274 - loss: 0.4585 - val_accuracy: 0.6782 - val_loss: 1.0255\n",
      "Epoch 376/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8406 - loss: 0.4388 - val_accuracy: 0.6721 - val_loss: 1.0750\n",
      "Epoch 377/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8182 - loss: 0.4940 - val_accuracy: 0.6802 - val_loss: 0.9998\n",
      "Epoch 378/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7963 - loss: 0.5377 - val_accuracy: 0.6660 - val_loss: 1.0148\n",
      "Epoch 379/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8030 - loss: 0.5169 - val_accuracy: 0.6680 - val_loss: 0.9856\n",
      "Epoch 380/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8025 - loss: 0.5332 - val_accuracy: 0.6640 - val_loss: 0.9666\n",
      "Epoch 381/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8072 - loss: 0.4942 - val_accuracy: 0.6701 - val_loss: 1.0085\n",
      "Epoch 382/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8032 - loss: 0.5408 - val_accuracy: 0.6741 - val_loss: 1.0272\n",
      "Epoch 383/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8225 - loss: 0.4621 - val_accuracy: 0.6619 - val_loss: 1.0453\n",
      "Epoch 384/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8029 - loss: 0.5126 - val_accuracy: 0.6823 - val_loss: 0.9612\n",
      "Epoch 385/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8182 - loss: 0.4879 - val_accuracy: 0.6619 - val_loss: 1.0628\n",
      "Epoch 386/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8354 - loss: 0.4284 - val_accuracy: 0.6701 - val_loss: 1.0567\n",
      "Epoch 387/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8398 - loss: 0.4406 - val_accuracy: 0.6660 - val_loss: 1.0280\n",
      "Epoch 388/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 0.4581 - val_accuracy: 0.6619 - val_loss: 1.0910\n",
      "Epoch 389/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8091 - loss: 0.4914 - val_accuracy: 0.6782 - val_loss: 1.0162\n",
      "Epoch 390/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8294 - loss: 0.4777 - val_accuracy: 0.6721 - val_loss: 1.0123\n",
      "Epoch 391/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8249 - loss: 0.4538 - val_accuracy: 0.6701 - val_loss: 1.0297\n",
      "Epoch 392/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8332 - loss: 0.4519 - val_accuracy: 0.6497 - val_loss: 1.1476\n",
      "Epoch 393/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 0.5230 - val_accuracy: 0.6680 - val_loss: 1.0731\n",
      "Epoch 394/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8248 - loss: 0.4688 - val_accuracy: 0.6884 - val_loss: 1.0702\n",
      "Epoch 395/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8189 - loss: 0.4862 - val_accuracy: 0.6741 - val_loss: 1.0487\n",
      "Epoch 396/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7978 - loss: 0.5301 - val_accuracy: 0.6660 - val_loss: 0.9903\n",
      "Epoch 397/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8052 - loss: 0.5389 - val_accuracy: 0.6721 - val_loss: 1.0404\n",
      "Epoch 398/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8438 - loss: 0.4403 - val_accuracy: 0.6497 - val_loss: 1.0822\n",
      "Epoch 399/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8067 - loss: 0.5241 - val_accuracy: 0.6741 - val_loss: 0.9980\n",
      "Epoch 400/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8115 - loss: 0.5106 - val_accuracy: 0.6660 - val_loss: 1.0263\n",
      "Epoch 401/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8398 - loss: 0.4531 - val_accuracy: 0.6965 - val_loss: 0.9467\n",
      "Epoch 402/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8271 - loss: 0.4777 - val_accuracy: 0.6741 - val_loss: 1.1022\n",
      "Epoch 403/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8227 - loss: 0.5058 - val_accuracy: 0.6965 - val_loss: 1.0248\n",
      "Epoch 404/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8375 - loss: 0.4250 - val_accuracy: 0.6680 - val_loss: 1.0771\n",
      "Epoch 405/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8447 - loss: 0.4473 - val_accuracy: 0.6701 - val_loss: 1.0566\n",
      "Epoch 406/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8305 - loss: 0.4525 - val_accuracy: 0.6904 - val_loss: 0.9834\n",
      "Epoch 407/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8371 - loss: 0.4124 - val_accuracy: 0.6762 - val_loss: 1.1242\n",
      "Epoch 408/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8238 - loss: 0.4610 - val_accuracy: 0.6904 - val_loss: 1.0424\n",
      "Epoch 409/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8337 - loss: 0.4450 - val_accuracy: 0.6864 - val_loss: 1.0295\n",
      "Epoch 410/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8298 - loss: 0.4466 - val_accuracy: 0.6823 - val_loss: 1.0021\n",
      "Epoch 411/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7984 - loss: 0.5155 - val_accuracy: 0.6741 - val_loss: 1.0933\n",
      "Epoch 412/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8265 - loss: 0.4497 - val_accuracy: 0.6823 - val_loss: 1.0590\n",
      "Epoch 413/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8147 - loss: 0.4626 - val_accuracy: 0.6802 - val_loss: 1.0674\n",
      "Epoch 414/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8403 - loss: 0.4454 - val_accuracy: 0.6640 - val_loss: 1.0535\n",
      "Epoch 415/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8286 - loss: 0.4422 - val_accuracy: 0.6904 - val_loss: 1.0434\n",
      "Epoch 416/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8220 - loss: 0.4724 - val_accuracy: 0.6762 - val_loss: 1.0394\n",
      "Epoch 417/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8282 - loss: 0.4469 - val_accuracy: 0.6741 - val_loss: 1.0332\n",
      "Epoch 418/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8050 - loss: 0.5123 - val_accuracy: 0.6843 - val_loss: 1.0145\n",
      "Epoch 419/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8442 - loss: 0.4327 - val_accuracy: 0.6762 - val_loss: 1.0572\n",
      "Epoch 420/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8376 - loss: 0.4480 - val_accuracy: 0.6721 - val_loss: 1.0966\n",
      "Epoch 421/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8060 - loss: 0.4625 - val_accuracy: 0.6721 - val_loss: 1.0488\n",
      "Epoch 422/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8348 - loss: 0.4542 - val_accuracy: 0.6864 - val_loss: 1.0215\n",
      "Epoch 423/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8601 - loss: 0.4014 - val_accuracy: 0.6864 - val_loss: 1.0532\n",
      "Epoch 424/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8531 - loss: 0.4125 - val_accuracy: 0.6619 - val_loss: 1.0563\n",
      "Epoch 425/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8455 - loss: 0.4157 - val_accuracy: 0.6701 - val_loss: 1.0431\n",
      "Epoch 426/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8427 - loss: 0.4605 - val_accuracy: 0.6680 - val_loss: 1.0285\n",
      "Epoch 427/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8353 - loss: 0.4410 - val_accuracy: 0.6741 - val_loss: 1.0374\n",
      "Epoch 428/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8228 - loss: 0.4686 - val_accuracy: 0.6721 - val_loss: 1.0903\n",
      "Epoch 429/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8304 - loss: 0.4625 - val_accuracy: 0.6701 - val_loss: 1.0617\n",
      "Epoch 430/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7959 - loss: 0.5504 - val_accuracy: 0.6721 - val_loss: 1.0679\n",
      "Epoch 431/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8410 - loss: 0.4239 - val_accuracy: 0.6802 - val_loss: 1.0754\n",
      "Epoch 432/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8416 - loss: 0.4114 - val_accuracy: 0.6741 - val_loss: 1.0852\n",
      "Epoch 433/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8370 - loss: 0.4588 - val_accuracy: 0.6721 - val_loss: 1.0267\n",
      "Epoch 434/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8372 - loss: 0.4241 - val_accuracy: 0.6721 - val_loss: 1.0196\n",
      "Epoch 435/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8282 - loss: 0.4885 - val_accuracy: 0.6884 - val_loss: 1.0306\n",
      "Epoch 436/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8297 - loss: 0.4707 - val_accuracy: 0.6619 - val_loss: 1.1169\n",
      "Epoch 437/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8210 - loss: 0.4687 - val_accuracy: 0.6701 - val_loss: 1.1034\n",
      "Epoch 438/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8536 - loss: 0.4025 - val_accuracy: 0.6741 - val_loss: 1.0348\n",
      "Epoch 439/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8368 - loss: 0.4499 - val_accuracy: 0.6680 - val_loss: 1.0906\n",
      "Epoch 440/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8382 - loss: 0.4708 - val_accuracy: 0.6802 - val_loss: 1.0126\n",
      "Epoch 441/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8450 - loss: 0.4383 - val_accuracy: 0.6884 - val_loss: 1.0449\n",
      "Epoch 442/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8449 - loss: 0.4188 - val_accuracy: 0.6884 - val_loss: 1.0627\n",
      "Epoch 443/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8381 - loss: 0.4384 - val_accuracy: 0.6986 - val_loss: 1.0102\n",
      "Epoch 444/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8071 - loss: 0.4972 - val_accuracy: 0.6599 - val_loss: 1.0473\n",
      "Epoch 445/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8282 - loss: 0.4463 - val_accuracy: 0.6721 - val_loss: 1.1130\n",
      "Epoch 446/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8173 - loss: 0.4805 - val_accuracy: 0.6925 - val_loss: 1.0744\n",
      "Epoch 447/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8218 - loss: 0.4677 - val_accuracy: 0.6599 - val_loss: 1.0918\n",
      "Epoch 448/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8298 - loss: 0.4699 - val_accuracy: 0.6802 - val_loss: 1.0550\n",
      "Epoch 449/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8272 - loss: 0.4700 - val_accuracy: 0.6640 - val_loss: 1.0916\n",
      "Epoch 450/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8197 - loss: 0.4762 - val_accuracy: 0.6904 - val_loss: 1.0009\n",
      "Epoch 451/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8477 - loss: 0.4379 - val_accuracy: 0.6925 - val_loss: 1.0069\n",
      "Epoch 452/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8326 - loss: 0.4682 - val_accuracy: 0.6599 - val_loss: 1.1094\n",
      "Epoch 453/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8168 - loss: 0.4924 - val_accuracy: 0.6823 - val_loss: 1.0486\n",
      "Epoch 454/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8450 - loss: 0.4165 - val_accuracy: 0.6823 - val_loss: 1.0895\n",
      "Epoch 455/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8254 - loss: 0.4647 - val_accuracy: 0.6864 - val_loss: 1.0239\n",
      "Epoch 456/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8295 - loss: 0.4560 - val_accuracy: 0.6782 - val_loss: 1.0488\n",
      "Epoch 457/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8201 - loss: 0.4725 - val_accuracy: 0.6864 - val_loss: 1.0070\n",
      "Epoch 458/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8543 - loss: 0.4066 - val_accuracy: 0.6599 - val_loss: 1.0583\n",
      "Epoch 459/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8234 - loss: 0.4626 - val_accuracy: 0.6802 - val_loss: 1.1131\n",
      "Epoch 460/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8303 - loss: 0.4658 - val_accuracy: 0.7006 - val_loss: 1.0497\n",
      "Epoch 461/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8102 - loss: 0.4790 - val_accuracy: 0.6782 - val_loss: 1.0902\n",
      "Epoch 462/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8328 - loss: 0.4334 - val_accuracy: 0.6701 - val_loss: 1.1045\n",
      "Epoch 463/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.4978 - val_accuracy: 0.6904 - val_loss: 1.0148\n",
      "Epoch 464/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8404 - loss: 0.4489 - val_accuracy: 0.6945 - val_loss: 1.0194\n",
      "Epoch 465/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8341 - loss: 0.4286 - val_accuracy: 0.6741 - val_loss: 1.1201\n",
      "Epoch 466/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8485 - loss: 0.4134 - val_accuracy: 0.6864 - val_loss: 1.0784\n",
      "Epoch 467/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8201 - loss: 0.4899 - val_accuracy: 0.6843 - val_loss: 1.0581\n",
      "Epoch 468/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8327 - loss: 0.4442 - val_accuracy: 0.6741 - val_loss: 1.0572\n",
      "Epoch 469/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8403 - loss: 0.4228 - val_accuracy: 0.6925 - val_loss: 1.0161\n",
      "Epoch 470/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8378 - loss: 0.4436 - val_accuracy: 0.6599 - val_loss: 1.0601\n",
      "Epoch 471/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8307 - loss: 0.4627 - val_accuracy: 0.6599 - val_loss: 1.1125\n",
      "Epoch 472/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8352 - loss: 0.4661 - val_accuracy: 0.6864 - val_loss: 1.1733\n",
      "Epoch 473/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8242 - loss: 0.4806 - val_accuracy: 0.6864 - val_loss: 1.1141\n",
      "Epoch 474/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8392 - loss: 0.4378 - val_accuracy: 0.6721 - val_loss: 1.0840\n",
      "Epoch 475/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8335 - loss: 0.4342 - val_accuracy: 0.6721 - val_loss: 1.1160\n",
      "Epoch 476/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8369 - loss: 0.4593 - val_accuracy: 0.6762 - val_loss: 1.0646\n",
      "Epoch 477/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8198 - loss: 0.4631 - val_accuracy: 0.6741 - val_loss: 1.1017\n",
      "Epoch 478/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8375 - loss: 0.4618 - val_accuracy: 0.6782 - val_loss: 1.1268\n",
      "Epoch 479/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8396 - loss: 0.4096 - val_accuracy: 0.6864 - val_loss: 1.0898\n",
      "Epoch 480/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8223 - loss: 0.4588 - val_accuracy: 0.6884 - val_loss: 1.0906\n",
      "Epoch 481/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8179 - loss: 0.4668 - val_accuracy: 0.6741 - val_loss: 1.0647\n",
      "Epoch 482/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8535 - loss: 0.4083 - val_accuracy: 0.6599 - val_loss: 1.1217\n",
      "Epoch 483/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8413 - loss: 0.4303 - val_accuracy: 0.6741 - val_loss: 1.0633\n",
      "Epoch 484/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8547 - loss: 0.4251 - val_accuracy: 0.6762 - val_loss: 1.1264\n",
      "Epoch 485/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8372 - loss: 0.4229 - val_accuracy: 0.6802 - val_loss: 1.1097\n",
      "Epoch 486/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8341 - loss: 0.4674 - val_accuracy: 0.6680 - val_loss: 1.1267\n",
      "Epoch 487/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8384 - loss: 0.4358 - val_accuracy: 0.6538 - val_loss: 1.1385\n",
      "Epoch 488/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8468 - loss: 0.4172 - val_accuracy: 0.6823 - val_loss: 1.0599\n",
      "Epoch 489/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8256 - loss: 0.4532 - val_accuracy: 0.6864 - val_loss: 1.0645\n",
      "Epoch 490/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8470 - loss: 0.4254 - val_accuracy: 0.6680 - val_loss: 1.0629\n",
      "Epoch 491/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8360 - loss: 0.4431 - val_accuracy: 0.6782 - val_loss: 1.1314\n",
      "Epoch 492/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8396 - loss: 0.4436 - val_accuracy: 0.6680 - val_loss: 1.1118\n",
      "Epoch 493/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8308 - loss: 0.4697 - val_accuracy: 0.6538 - val_loss: 1.1420\n",
      "Epoch 494/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8492 - loss: 0.4481 - val_accuracy: 0.6721 - val_loss: 1.0660\n",
      "Epoch 495/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8280 - loss: 0.4538 - val_accuracy: 0.6578 - val_loss: 1.0821\n",
      "Epoch 496/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8339 - loss: 0.4624 - val_accuracy: 0.6599 - val_loss: 1.0852\n",
      "Epoch 497/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8390 - loss: 0.4482 - val_accuracy: 0.6701 - val_loss: 1.1807\n",
      "Epoch 498/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 0.4337 - val_accuracy: 0.6741 - val_loss: 1.1197\n",
      "Epoch 499/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8696 - loss: 0.3703 - val_accuracy: 0.6762 - val_loss: 1.1087\n",
      "Epoch 500/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8690 - loss: 0.3963 - val_accuracy: 0.6802 - val_loss: 1.1312\n",
      "Epoch 501/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8461 - loss: 0.4034 - val_accuracy: 0.6843 - val_loss: 1.1406\n",
      "Epoch 502/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8260 - loss: 0.4681 - val_accuracy: 0.6619 - val_loss: 1.1535\n",
      "Epoch 503/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8514 - loss: 0.4077 - val_accuracy: 0.6640 - val_loss: 1.1181\n",
      "Epoch 504/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8396 - loss: 0.4319 - val_accuracy: 0.6843 - val_loss: 1.0998\n",
      "Epoch 505/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8177 - loss: 0.4380 - val_accuracy: 0.6884 - val_loss: 1.0955\n",
      "Epoch 506/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8353 - loss: 0.4354 - val_accuracy: 0.6762 - val_loss: 1.0895\n",
      "Epoch 507/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8559 - loss: 0.4037 - val_accuracy: 0.6782 - val_loss: 1.1070\n",
      "Epoch 508/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8349 - loss: 0.4289 - val_accuracy: 0.6925 - val_loss: 1.0962\n",
      "Epoch 509/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8335 - loss: 0.4617 - val_accuracy: 0.6864 - val_loss: 1.0515\n",
      "Epoch 510/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8396 - loss: 0.4326 - val_accuracy: 0.6823 - val_loss: 1.1356\n",
      "Epoch 511/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8269 - loss: 0.4671 - val_accuracy: 0.6864 - val_loss: 1.0949\n",
      "Epoch 512/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8463 - loss: 0.4195 - val_accuracy: 0.6904 - val_loss: 1.0958\n",
      "Epoch 513/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 0.4700 - val_accuracy: 0.6782 - val_loss: 1.0631\n",
      "Epoch 514/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8390 - loss: 0.4592 - val_accuracy: 0.6741 - val_loss: 1.0986\n",
      "Epoch 515/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8322 - loss: 0.4705 - val_accuracy: 0.6802 - val_loss: 1.1725\n",
      "Epoch 516/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8318 - loss: 0.4543 - val_accuracy: 0.6843 - val_loss: 1.0787\n",
      "Epoch 517/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8226 - loss: 0.4587 - val_accuracy: 0.6823 - val_loss: 1.1147\n",
      "Epoch 518/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8315 - loss: 0.4632 - val_accuracy: 0.6680 - val_loss: 1.1759\n",
      "Epoch 519/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8573 - loss: 0.4042 - val_accuracy: 0.6741 - val_loss: 1.1113\n",
      "Epoch 520/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8651 - loss: 0.3748 - val_accuracy: 0.6721 - val_loss: 1.1509\n",
      "Epoch 521/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8434 - loss: 0.4198 - val_accuracy: 0.6782 - val_loss: 1.0813\n",
      "Epoch 522/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8389 - loss: 0.4250 - val_accuracy: 0.6884 - val_loss: 1.0804\n",
      "Epoch 523/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8570 - loss: 0.4040 - val_accuracy: 0.6721 - val_loss: 1.1178\n",
      "Epoch 524/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8499 - loss: 0.4179 - val_accuracy: 0.6823 - val_loss: 1.1020\n",
      "Epoch 525/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8459 - loss: 0.4226 - val_accuracy: 0.6843 - val_loss: 1.0677\n",
      "Epoch 526/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8209 - loss: 0.4275 - val_accuracy: 0.6721 - val_loss: 1.0596\n",
      "Epoch 527/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8397 - loss: 0.4381 - val_accuracy: 0.6680 - val_loss: 1.1792\n",
      "Epoch 528/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8488 - loss: 0.4527 - val_accuracy: 0.6762 - val_loss: 1.1039\n",
      "Epoch 529/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8287 - loss: 0.4555 - val_accuracy: 0.6741 - val_loss: 1.0959\n",
      "Epoch 530/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8520 - loss: 0.4158 - val_accuracy: 0.6762 - val_loss: 1.0888\n",
      "Epoch 531/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8497 - loss: 0.4392 - val_accuracy: 0.6823 - val_loss: 1.1615\n",
      "Epoch 532/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8475 - loss: 0.4291 - val_accuracy: 0.6741 - val_loss: 1.1024\n",
      "Epoch 533/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8529 - loss: 0.4083 - val_accuracy: 0.6762 - val_loss: 1.1311\n",
      "Epoch 534/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8384 - loss: 0.4514 - val_accuracy: 0.6884 - val_loss: 1.0748\n",
      "Epoch 535/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8314 - loss: 0.4341 - val_accuracy: 0.6660 - val_loss: 1.0993\n",
      "Epoch 536/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8393 - loss: 0.4605 - val_accuracy: 0.6741 - val_loss: 1.1095\n",
      "Epoch 537/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8484 - loss: 0.3771 - val_accuracy: 0.6660 - val_loss: 1.1144\n",
      "Epoch 538/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8595 - loss: 0.3946 - val_accuracy: 0.6823 - val_loss: 1.1608\n",
      "Epoch 539/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8364 - loss: 0.4234 - val_accuracy: 0.6762 - val_loss: 1.0876\n",
      "Epoch 540/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8337 - loss: 0.4234 - val_accuracy: 0.6701 - val_loss: 1.0659\n",
      "Epoch 541/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8416 - loss: 0.4468 - val_accuracy: 0.7026 - val_loss: 1.1115\n",
      "Epoch 542/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8258 - loss: 0.4723 - val_accuracy: 0.6864 - val_loss: 1.1722\n",
      "Epoch 543/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8201 - loss: 0.5024 - val_accuracy: 0.6986 - val_loss: 1.1138\n",
      "Epoch 544/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8258 - loss: 0.4507 - val_accuracy: 0.6864 - val_loss: 1.0752\n",
      "Epoch 545/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8523 - loss: 0.3874 - val_accuracy: 0.6640 - val_loss: 1.1162\n",
      "Epoch 546/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8585 - loss: 0.4007 - val_accuracy: 0.6843 - val_loss: 1.1334\n",
      "Epoch 547/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8382 - loss: 0.4411 - val_accuracy: 0.6823 - val_loss: 1.1544\n",
      "Epoch 548/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8498 - loss: 0.4300 - val_accuracy: 0.7006 - val_loss: 1.0488\n",
      "Epoch 549/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8436 - loss: 0.4357 - val_accuracy: 0.6782 - val_loss: 1.0802\n",
      "Epoch 550/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8412 - loss: 0.4342 - val_accuracy: 0.6843 - val_loss: 1.0654\n",
      "Epoch 551/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8149 - loss: 0.5045 - val_accuracy: 0.6701 - val_loss: 1.0849\n",
      "Epoch 552/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8344 - loss: 0.4657 - val_accuracy: 0.6762 - val_loss: 1.1010\n",
      "Epoch 553/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8401 - loss: 0.4520 - val_accuracy: 0.6762 - val_loss: 1.1003\n",
      "Epoch 554/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8310 - loss: 0.4755 - val_accuracy: 0.6741 - val_loss: 1.1484\n",
      "Epoch 555/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8450 - loss: 0.4327 - val_accuracy: 0.6762 - val_loss: 1.1004\n",
      "Epoch 556/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8684 - loss: 0.3772 - val_accuracy: 0.6965 - val_loss: 1.1016\n",
      "Epoch 557/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8485 - loss: 0.4150 - val_accuracy: 0.6721 - val_loss: 1.0953\n",
      "Epoch 558/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8616 - loss: 0.3841 - val_accuracy: 0.6721 - val_loss: 1.1168\n",
      "Epoch 559/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8566 - loss: 0.4018 - val_accuracy: 0.6741 - val_loss: 1.1490\n",
      "Epoch 560/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8311 - loss: 0.4514 - val_accuracy: 0.6762 - val_loss: 1.1388\n",
      "Epoch 561/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8597 - loss: 0.4149 - val_accuracy: 0.6497 - val_loss: 1.2053\n",
      "Epoch 562/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8372 - loss: 0.4380 - val_accuracy: 0.6701 - val_loss: 1.1408\n",
      "Epoch 563/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8314 - loss: 0.4297 - val_accuracy: 0.6802 - val_loss: 1.1243\n",
      "Epoch 564/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8556 - loss: 0.3993 - val_accuracy: 0.6782 - val_loss: 1.1306\n",
      "Epoch 565/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8593 - loss: 0.3857 - val_accuracy: 0.6741 - val_loss: 1.1682\n",
      "Epoch 566/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 0.4523 - val_accuracy: 0.6884 - val_loss: 1.0737\n",
      "Epoch 567/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8366 - loss: 0.4610 - val_accuracy: 0.6741 - val_loss: 1.1090\n",
      "Epoch 568/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8292 - loss: 0.4775 - val_accuracy: 0.6782 - val_loss: 1.0688\n",
      "Epoch 569/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8573 - loss: 0.4133 - val_accuracy: 0.6823 - val_loss: 1.1173\n",
      "Epoch 570/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8412 - loss: 0.4289 - val_accuracy: 0.6802 - val_loss: 1.1521\n",
      "Epoch 571/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8643 - loss: 0.3660 - val_accuracy: 0.6843 - val_loss: 1.1708\n",
      "Epoch 572/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8370 - loss: 0.4195 - val_accuracy: 0.6904 - val_loss: 1.1294\n",
      "Epoch 573/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8416 - loss: 0.4001 - val_accuracy: 0.6701 - val_loss: 1.0875\n",
      "Epoch 574/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8507 - loss: 0.4342 - val_accuracy: 0.6721 - val_loss: 1.1236\n",
      "Epoch 575/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8420 - loss: 0.4117 - val_accuracy: 0.6701 - val_loss: 1.1571\n",
      "Epoch 576/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8553 - loss: 0.4038 - val_accuracy: 0.6782 - val_loss: 1.0611\n",
      "Epoch 577/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8451 - loss: 0.4205 - val_accuracy: 0.6864 - val_loss: 1.0933\n",
      "Epoch 578/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8554 - loss: 0.4049 - val_accuracy: 0.6864 - val_loss: 1.0859\n",
      "Epoch 579/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8507 - loss: 0.4033 - val_accuracy: 0.6823 - val_loss: 1.0785\n",
      "Epoch 580/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8584 - loss: 0.3690 - val_accuracy: 0.6782 - val_loss: 1.1965\n",
      "Epoch 581/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8442 - loss: 0.4252 - val_accuracy: 0.6741 - val_loss: 1.0704\n",
      "Epoch 582/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8213 - loss: 0.4394 - val_accuracy: 0.6782 - val_loss: 1.1084\n",
      "Epoch 583/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8323 - loss: 0.4593 - val_accuracy: 0.6741 - val_loss: 1.1100\n",
      "Epoch 584/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8546 - loss: 0.4089 - val_accuracy: 0.6660 - val_loss: 1.1120\n",
      "Epoch 585/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8485 - loss: 0.4248 - val_accuracy: 0.6660 - val_loss: 1.1744\n",
      "Epoch 586/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8580 - loss: 0.3962 - val_accuracy: 0.6660 - val_loss: 1.1662\n",
      "Epoch 587/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8376 - loss: 0.4236 - val_accuracy: 0.6721 - val_loss: 1.1454\n",
      "Epoch 588/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8377 - loss: 0.4453 - val_accuracy: 0.6660 - val_loss: 1.1730\n",
      "Epoch 589/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8426 - loss: 0.4177 - val_accuracy: 0.6802 - val_loss: 1.0988\n",
      "Epoch 590/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8501 - loss: 0.3968 - val_accuracy: 0.6986 - val_loss: 1.1191\n",
      "Epoch 591/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8326 - loss: 0.4497 - val_accuracy: 0.7026 - val_loss: 1.0909\n",
      "Epoch 592/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8620 - loss: 0.3818 - val_accuracy: 0.6884 - val_loss: 1.0727\n",
      "Epoch 593/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8359 - loss: 0.3971 - val_accuracy: 0.6721 - val_loss: 1.0606\n",
      "Epoch 594/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8437 - loss: 0.4119 - val_accuracy: 0.6680 - val_loss: 1.1296\n",
      "Epoch 595/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8541 - loss: 0.4244 - val_accuracy: 0.6538 - val_loss: 1.1539\n",
      "Epoch 596/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8518 - loss: 0.4032 - val_accuracy: 0.6660 - val_loss: 1.1287\n",
      "Epoch 597/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8443 - loss: 0.4112 - val_accuracy: 0.6802 - val_loss: 1.0999\n",
      "Epoch 598/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8628 - loss: 0.4076 - val_accuracy: 0.6660 - val_loss: 1.1806\n",
      "Epoch 599/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8460 - loss: 0.4049 - val_accuracy: 0.6782 - val_loss: 1.1023\n",
      "Epoch 600/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8531 - loss: 0.3962 - val_accuracy: 0.6538 - val_loss: 1.1774\n",
      "Epoch 601/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8590 - loss: 0.3760 - val_accuracy: 0.6640 - val_loss: 1.1355\n",
      "Epoch 602/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8577 - loss: 0.3935 - val_accuracy: 0.6741 - val_loss: 1.1877\n",
      "Epoch 603/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8462 - loss: 0.4301 - val_accuracy: 0.6802 - val_loss: 1.1254\n",
      "Epoch 604/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8555 - loss: 0.3887 - val_accuracy: 0.6701 - val_loss: 1.1036\n",
      "Epoch 605/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8364 - loss: 0.4311 - val_accuracy: 0.6538 - val_loss: 1.1365\n",
      "Epoch 606/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8278 - loss: 0.4495 - val_accuracy: 0.6701 - val_loss: 1.1803\n",
      "Epoch 607/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8534 - loss: 0.4257 - val_accuracy: 0.6884 - val_loss: 1.0672\n",
      "Epoch 608/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8481 - loss: 0.4110 - val_accuracy: 0.6558 - val_loss: 1.1769\n",
      "Epoch 609/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8525 - loss: 0.4011 - val_accuracy: 0.6721 - val_loss: 1.1364\n",
      "Epoch 610/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8511 - loss: 0.3936 - val_accuracy: 0.6640 - val_loss: 1.1697\n",
      "Epoch 611/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8286 - loss: 0.4800 - val_accuracy: 0.6762 - val_loss: 1.0786\n",
      "Epoch 612/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8522 - loss: 0.3946 - val_accuracy: 0.6843 - val_loss: 1.1405\n",
      "Epoch 613/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8702 - loss: 0.3526 - val_accuracy: 0.6640 - val_loss: 1.2667\n",
      "Epoch 614/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8322 - loss: 0.4295 - val_accuracy: 0.6701 - val_loss: 1.1345\n",
      "Epoch 615/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8513 - loss: 0.3961 - val_accuracy: 0.6823 - val_loss: 1.1465\n",
      "Epoch 616/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8613 - loss: 0.4011 - val_accuracy: 0.6884 - val_loss: 1.1110\n",
      "Epoch 617/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8551 - loss: 0.4095 - val_accuracy: 0.6884 - val_loss: 1.1358\n",
      "Epoch 618/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8538 - loss: 0.3918 - val_accuracy: 0.6945 - val_loss: 1.0860\n",
      "Epoch 619/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8599 - loss: 0.3965 - val_accuracy: 0.6802 - val_loss: 1.1131\n",
      "Epoch 620/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8503 - loss: 0.4161 - val_accuracy: 0.6762 - val_loss: 1.1027\n",
      "Epoch 621/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8566 - loss: 0.4154 - val_accuracy: 0.6680 - val_loss: 1.1319\n",
      "Epoch 622/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8500 - loss: 0.3908 - val_accuracy: 0.6660 - val_loss: 1.1486\n",
      "Epoch 623/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8530 - loss: 0.4010 - val_accuracy: 0.6823 - val_loss: 1.2083\n",
      "Epoch 624/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8368 - loss: 0.4348 - val_accuracy: 0.6843 - val_loss: 1.1359\n",
      "Epoch 625/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8635 - loss: 0.3860 - val_accuracy: 0.6701 - val_loss: 1.1573\n",
      "Epoch 626/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8421 - loss: 0.4307 - val_accuracy: 0.6823 - val_loss: 1.1378\n",
      "Epoch 627/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8493 - loss: 0.3987 - val_accuracy: 0.6680 - val_loss: 1.1481\n",
      "Epoch 628/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8430 - loss: 0.4027 - val_accuracy: 0.6701 - val_loss: 1.1005\n",
      "Epoch 629/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8835 - loss: 0.3489 - val_accuracy: 0.6599 - val_loss: 1.2178\n",
      "Epoch 630/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8486 - loss: 0.3942 - val_accuracy: 0.6843 - val_loss: 1.1058\n",
      "Epoch 631/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8641 - loss: 0.3801 - val_accuracy: 0.6884 - val_loss: 1.1632\n",
      "Epoch 632/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8563 - loss: 0.4027 - val_accuracy: 0.6640 - val_loss: 1.1687\n",
      "Epoch 633/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8419 - loss: 0.4118 - val_accuracy: 0.6721 - val_loss: 1.1677\n",
      "Epoch 634/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8451 - loss: 0.4132 - val_accuracy: 0.6660 - val_loss: 1.1526\n",
      "Epoch 635/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8601 - loss: 0.4336 - val_accuracy: 0.6558 - val_loss: 1.1578\n",
      "Epoch 636/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8348 - loss: 0.4155 - val_accuracy: 0.6721 - val_loss: 1.1901\n",
      "Epoch 637/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8470 - loss: 0.3961 - val_accuracy: 0.6762 - val_loss: 1.1628\n",
      "Epoch 638/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8425 - loss: 0.4257 - val_accuracy: 0.6864 - val_loss: 1.1397\n",
      "Epoch 639/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8405 - loss: 0.4340 - val_accuracy: 0.6701 - val_loss: 1.1506\n",
      "Epoch 640/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8579 - loss: 0.3940 - val_accuracy: 0.6660 - val_loss: 1.1356\n",
      "Epoch 641/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8555 - loss: 0.4254 - val_accuracy: 0.6986 - val_loss: 1.0875\n",
      "Epoch 642/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8692 - loss: 0.3601 - val_accuracy: 0.6762 - val_loss: 1.1077\n",
      "Epoch 643/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8615 - loss: 0.3830 - val_accuracy: 0.6660 - val_loss: 1.1513\n",
      "Epoch 644/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8582 - loss: 0.4090 - val_accuracy: 0.6965 - val_loss: 1.1082\n",
      "Epoch 645/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8554 - loss: 0.4259 - val_accuracy: 0.6884 - val_loss: 1.0578\n",
      "Epoch 646/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8519 - loss: 0.4118 - val_accuracy: 0.6721 - val_loss: 1.1149\n",
      "Epoch 647/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8628 - loss: 0.3638 - val_accuracy: 0.6925 - val_loss: 1.0549\n",
      "Epoch 648/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8430 - loss: 0.4056 - val_accuracy: 0.6884 - val_loss: 1.1173\n",
      "Epoch 649/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8574 - loss: 0.3850 - val_accuracy: 0.6782 - val_loss: 1.0772\n",
      "Epoch 650/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8512 - loss: 0.4006 - val_accuracy: 0.6823 - val_loss: 1.1055\n",
      "Epoch 651/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8608 - loss: 0.3836 - val_accuracy: 0.6640 - val_loss: 1.1453\n",
      "Epoch 652/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8667 - loss: 0.3716 - val_accuracy: 0.6741 - val_loss: 1.1484\n",
      "Epoch 653/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8439 - loss: 0.4260 - val_accuracy: 0.6721 - val_loss: 1.0986\n",
      "Epoch 654/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8514 - loss: 0.4050 - val_accuracy: 0.6802 - val_loss: 1.1155\n",
      "Epoch 655/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8491 - loss: 0.3869 - val_accuracy: 0.6823 - val_loss: 1.1115\n",
      "Epoch 656/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8526 - loss: 0.3901 - val_accuracy: 0.6843 - val_loss: 1.0841\n",
      "Epoch 657/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8655 - loss: 0.3917 - val_accuracy: 0.6619 - val_loss: 1.2277\n",
      "Epoch 658/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8489 - loss: 0.4148 - val_accuracy: 0.6864 - val_loss: 1.1951\n",
      "Epoch 659/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8446 - loss: 0.4194 - val_accuracy: 0.6864 - val_loss: 1.1109\n",
      "Epoch 660/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8538 - loss: 0.3983 - val_accuracy: 0.6762 - val_loss: 1.1447\n",
      "Epoch 661/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8560 - loss: 0.4007 - val_accuracy: 0.6680 - val_loss: 1.1624\n",
      "Epoch 662/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8713 - loss: 0.3616 - val_accuracy: 0.6802 - val_loss: 1.1521\n",
      "Epoch 663/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8315 - loss: 0.4521 - val_accuracy: 0.6558 - val_loss: 1.2583\n",
      "Epoch 664/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8438 - loss: 0.4120 - val_accuracy: 0.6701 - val_loss: 1.1495\n",
      "Epoch 665/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8494 - loss: 0.4282 - val_accuracy: 0.6599 - val_loss: 1.1896\n",
      "Epoch 666/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8499 - loss: 0.3831 - val_accuracy: 0.6721 - val_loss: 1.0727\n",
      "Epoch 667/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8566 - loss: 0.3696 - val_accuracy: 0.6864 - val_loss: 1.1545\n",
      "Epoch 668/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8235 - loss: 0.4816 - val_accuracy: 0.6701 - val_loss: 1.1593\n",
      "Epoch 669/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8661 - loss: 0.3590 - val_accuracy: 0.6640 - val_loss: 1.1863\n",
      "Epoch 670/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8608 - loss: 0.3799 - val_accuracy: 0.6640 - val_loss: 1.1497\n",
      "Epoch 671/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8589 - loss: 0.3748 - val_accuracy: 0.6802 - val_loss: 1.1600\n",
      "Epoch 672/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8484 - loss: 0.3856 - val_accuracy: 0.6741 - val_loss: 1.2020\n",
      "Epoch 673/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8546 - loss: 0.3944 - val_accuracy: 0.6741 - val_loss: 1.1371\n",
      "Epoch 674/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8402 - loss: 0.4301 - val_accuracy: 0.6741 - val_loss: 1.1339\n",
      "Epoch 675/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.4598 - val_accuracy: 0.6802 - val_loss: 1.1207\n",
      "Epoch 676/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8349 - loss: 0.4386 - val_accuracy: 0.6741 - val_loss: 1.1102\n",
      "Epoch 677/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8597 - loss: 0.3756 - val_accuracy: 0.6782 - val_loss: 1.1754\n",
      "Epoch 678/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8237 - loss: 0.4740 - val_accuracy: 0.6701 - val_loss: 1.1583\n",
      "Epoch 679/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8634 - loss: 0.3804 - val_accuracy: 0.6680 - val_loss: 1.1621\n",
      "Epoch 680/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8599 - loss: 0.3698 - val_accuracy: 0.6517 - val_loss: 1.1877\n",
      "Epoch 681/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8452 - loss: 0.3955 - val_accuracy: 0.6802 - val_loss: 1.1080\n",
      "Epoch 682/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8728 - loss: 0.3529 - val_accuracy: 0.6904 - val_loss: 1.1488\n",
      "Epoch 683/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8550 - loss: 0.3871 - val_accuracy: 0.6762 - val_loss: 1.2254\n",
      "Epoch 684/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8517 - loss: 0.4311 - val_accuracy: 0.6558 - val_loss: 1.1579\n",
      "Epoch 685/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8484 - loss: 0.4292 - val_accuracy: 0.6864 - val_loss: 1.1047\n",
      "Epoch 686/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8637 - loss: 0.3788 - val_accuracy: 0.6619 - val_loss: 1.1682\n",
      "Epoch 687/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8564 - loss: 0.3900 - val_accuracy: 0.6904 - val_loss: 1.1271\n",
      "Epoch 688/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8562 - loss: 0.3865 - val_accuracy: 0.6741 - val_loss: 1.1207\n",
      "Epoch 689/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8462 - loss: 0.4006 - val_accuracy: 0.6640 - val_loss: 1.1865\n",
      "Epoch 690/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8752 - loss: 0.3706 - val_accuracy: 0.6741 - val_loss: 1.1424\n",
      "Epoch 691/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8572 - loss: 0.3773 - val_accuracy: 0.7006 - val_loss: 1.0474\n",
      "Epoch 692/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8571 - loss: 0.3984 - val_accuracy: 0.6843 - val_loss: 1.1344\n",
      "Epoch 693/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8584 - loss: 0.3869 - val_accuracy: 0.7006 - val_loss: 1.1026\n",
      "Epoch 694/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8584 - loss: 0.3959 - val_accuracy: 0.6802 - val_loss: 1.1706\n",
      "Epoch 695/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8427 - loss: 0.4013 - val_accuracy: 0.6680 - val_loss: 1.1551\n",
      "Epoch 696/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8711 - loss: 0.3833 - val_accuracy: 0.6884 - val_loss: 1.1388\n",
      "Epoch 697/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8719 - loss: 0.3495 - val_accuracy: 0.6904 - val_loss: 1.1425\n",
      "Epoch 698/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8638 - loss: 0.3890 - val_accuracy: 0.6680 - val_loss: 1.1674\n",
      "Epoch 699/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8753 - loss: 0.3712 - val_accuracy: 0.6741 - val_loss: 1.1776\n",
      "Epoch 700/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8715 - loss: 0.3938 - val_accuracy: 0.6823 - val_loss: 1.1825\n",
      "Epoch 701/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8656 - loss: 0.3550 - val_accuracy: 0.6802 - val_loss: 1.1609\n",
      "Epoch 702/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8801 - loss: 0.3426 - val_accuracy: 0.6986 - val_loss: 1.1725\n",
      "Epoch 703/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8413 - loss: 0.3841 - val_accuracy: 0.6640 - val_loss: 1.1462\n",
      "Epoch 704/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8610 - loss: 0.3831 - val_accuracy: 0.6782 - val_loss: 1.2049\n",
      "Epoch 705/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8334 - loss: 0.4253 - val_accuracy: 0.6965 - val_loss: 1.1231\n",
      "Epoch 706/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8465 - loss: 0.3994 - val_accuracy: 0.6517 - val_loss: 1.2483\n",
      "Epoch 707/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8550 - loss: 0.4164 - val_accuracy: 0.6762 - val_loss: 1.1262\n",
      "Epoch 708/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8567 - loss: 0.3960 - val_accuracy: 0.6884 - val_loss: 1.1562\n",
      "Epoch 709/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8683 - loss: 0.3803 - val_accuracy: 0.6823 - val_loss: 1.1604\n",
      "Epoch 710/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8604 - loss: 0.3873 - val_accuracy: 0.6823 - val_loss: 1.1173\n",
      "Epoch 711/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8556 - loss: 0.3923 - val_accuracy: 0.6802 - val_loss: 1.1731\n",
      "Epoch 712/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8597 - loss: 0.3869 - val_accuracy: 0.6741 - val_loss: 1.2213\n",
      "Epoch 713/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8557 - loss: 0.3820 - val_accuracy: 0.6864 - val_loss: 1.1717\n",
      "Epoch 714/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8597 - loss: 0.3950 - val_accuracy: 0.6680 - val_loss: 1.1716\n",
      "Epoch 715/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8460 - loss: 0.3921 - val_accuracy: 0.6823 - val_loss: 1.1159\n",
      "Epoch 716/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.3643 - val_accuracy: 0.7026 - val_loss: 1.1217\n",
      "Epoch 717/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8555 - loss: 0.3845 - val_accuracy: 0.6721 - val_loss: 1.2214\n",
      "Epoch 718/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8801 - loss: 0.3460 - val_accuracy: 0.6701 - val_loss: 1.1966\n",
      "Epoch 719/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8716 - loss: 0.3694 - val_accuracy: 0.6660 - val_loss: 1.1457\n",
      "Epoch 720/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8466 - loss: 0.4200 - val_accuracy: 0.6741 - val_loss: 1.1920\n",
      "Epoch 721/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8445 - loss: 0.3929 - val_accuracy: 0.6599 - val_loss: 1.2051\n",
      "Epoch 722/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8410 - loss: 0.4133 - val_accuracy: 0.6762 - val_loss: 1.2157\n",
      "Epoch 723/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8471 - loss: 0.3912 - val_accuracy: 0.6701 - val_loss: 1.1729\n",
      "Epoch 724/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8595 - loss: 0.3906 - val_accuracy: 0.6864 - val_loss: 1.1333\n",
      "Epoch 725/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8503 - loss: 0.4256 - val_accuracy: 0.6802 - val_loss: 1.1978\n",
      "Epoch 726/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8597 - loss: 0.3968 - val_accuracy: 0.6904 - val_loss: 1.1827\n",
      "Epoch 727/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8619 - loss: 0.3981 - val_accuracy: 0.6843 - val_loss: 1.1380\n",
      "Epoch 728/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8523 - loss: 0.3887 - val_accuracy: 0.6660 - val_loss: 1.1869\n",
      "Epoch 729/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8476 - loss: 0.4152 - val_accuracy: 0.6680 - val_loss: 1.1765\n",
      "Epoch 730/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8452 - loss: 0.4126 - val_accuracy: 0.6721 - val_loss: 1.1278\n",
      "Epoch 731/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8657 - loss: 0.3825 - val_accuracy: 0.6782 - val_loss: 1.1576\n",
      "Epoch 732/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8635 - loss: 0.3885 - val_accuracy: 0.6599 - val_loss: 1.2338\n",
      "Epoch 733/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8549 - loss: 0.3960 - val_accuracy: 0.6619 - val_loss: 1.1490\n",
      "Epoch 734/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8706 - loss: 0.3625 - val_accuracy: 0.6843 - val_loss: 1.1510\n",
      "Epoch 735/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8728 - loss: 0.3673 - val_accuracy: 0.6782 - val_loss: 1.0936\n",
      "Epoch 736/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8712 - loss: 0.3574 - val_accuracy: 0.6864 - val_loss: 1.1385\n",
      "Epoch 737/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8544 - loss: 0.3839 - val_accuracy: 0.6925 - val_loss: 1.1085\n",
      "Epoch 738/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8708 - loss: 0.3546 - val_accuracy: 0.6741 - val_loss: 1.1649\n",
      "Epoch 739/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8690 - loss: 0.3789 - val_accuracy: 0.6680 - val_loss: 1.1380\n",
      "Epoch 740/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8693 - loss: 0.3538 - val_accuracy: 0.6802 - val_loss: 1.1462\n",
      "Epoch 741/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8799 - loss: 0.3485 - val_accuracy: 0.6680 - val_loss: 1.2246\n",
      "Epoch 742/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8578 - loss: 0.3656 - val_accuracy: 0.6925 - val_loss: 1.0754\n",
      "Epoch 743/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8592 - loss: 0.3832 - val_accuracy: 0.6864 - val_loss: 1.1068\n",
      "Epoch 744/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8486 - loss: 0.4017 - val_accuracy: 0.6477 - val_loss: 1.2351\n",
      "Epoch 745/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8366 - loss: 0.4346 - val_accuracy: 0.6782 - val_loss: 1.1089\n",
      "Epoch 746/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8742 - loss: 0.3624 - val_accuracy: 0.6843 - val_loss: 1.1709\n",
      "Epoch 747/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8537 - loss: 0.3748 - val_accuracy: 0.6925 - val_loss: 1.1837\n",
      "Epoch 748/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8500 - loss: 0.4351 - val_accuracy: 0.6762 - val_loss: 1.1728\n",
      "Epoch 749/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8551 - loss: 0.4010 - val_accuracy: 0.6701 - val_loss: 1.1767\n",
      "Epoch 750/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8562 - loss: 0.3879 - val_accuracy: 0.6660 - val_loss: 1.1910\n",
      "Epoch 751/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8435 - loss: 0.4226 - val_accuracy: 0.6762 - val_loss: 1.1598\n",
      "Epoch 752/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8551 - loss: 0.4094 - val_accuracy: 0.6802 - val_loss: 1.1566\n",
      "Epoch 753/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8677 - loss: 0.3525 - val_accuracy: 0.6843 - val_loss: 1.1426\n",
      "Epoch 754/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8529 - loss: 0.3880 - val_accuracy: 0.6741 - val_loss: 1.1820\n",
      "Epoch 755/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8681 - loss: 0.3656 - val_accuracy: 0.6802 - val_loss: 1.1540\n",
      "Epoch 756/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8836 - loss: 0.3387 - val_accuracy: 0.6660 - val_loss: 1.2403\n",
      "Epoch 757/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8364 - loss: 0.4548 - val_accuracy: 0.6660 - val_loss: 1.2318\n",
      "Epoch 758/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8704 - loss: 0.3554 - val_accuracy: 0.6986 - val_loss: 1.1571\n",
      "Epoch 759/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8781 - loss: 0.3218 - val_accuracy: 0.6802 - val_loss: 1.2226\n",
      "Epoch 760/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8533 - loss: 0.3851 - val_accuracy: 0.6640 - val_loss: 1.2052\n",
      "Epoch 761/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8505 - loss: 0.3733 - val_accuracy: 0.6945 - val_loss: 1.1370\n",
      "Epoch 762/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8701 - loss: 0.3682 - val_accuracy: 0.6802 - val_loss: 1.1989\n",
      "Epoch 763/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8650 - loss: 0.3674 - val_accuracy: 0.6925 - val_loss: 1.1987\n",
      "Epoch 764/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8644 - loss: 0.3509 - val_accuracy: 0.6782 - val_loss: 1.1833\n",
      "Epoch 765/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8614 - loss: 0.3764 - val_accuracy: 0.6823 - val_loss: 1.2113\n",
      "Epoch 766/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8471 - loss: 0.4021 - val_accuracy: 0.6782 - val_loss: 1.1556\n",
      "Epoch 767/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8670 - loss: 0.3911 - val_accuracy: 0.6864 - val_loss: 1.1689\n",
      "Epoch 768/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8631 - loss: 0.3416 - val_accuracy: 0.6701 - val_loss: 1.2410\n",
      "Epoch 769/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8623 - loss: 0.3714 - val_accuracy: 0.6884 - val_loss: 1.1821\n",
      "Epoch 770/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8375 - loss: 0.4304 - val_accuracy: 0.6599 - val_loss: 1.2737\n",
      "Epoch 771/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8576 - loss: 0.3792 - val_accuracy: 0.6925 - val_loss: 1.1467\n",
      "Epoch 772/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8617 - loss: 0.3853 - val_accuracy: 0.6782 - val_loss: 1.2643\n",
      "Epoch 773/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8525 - loss: 0.4024 - val_accuracy: 0.6904 - val_loss: 1.1470\n",
      "Epoch 774/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8620 - loss: 0.4018 - val_accuracy: 0.6619 - val_loss: 1.2432\n",
      "Epoch 775/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8682 - loss: 0.3837 - val_accuracy: 0.6965 - val_loss: 1.1584\n",
      "Epoch 776/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8741 - loss: 0.3553 - val_accuracy: 0.6721 - val_loss: 1.2075\n",
      "Epoch 777/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8654 - loss: 0.3519 - val_accuracy: 0.6701 - val_loss: 1.2254\n",
      "Epoch 778/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8678 - loss: 0.3376 - val_accuracy: 0.6619 - val_loss: 1.2093\n",
      "Epoch 779/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8821 - loss: 0.3365 - val_accuracy: 0.6721 - val_loss: 1.1906\n",
      "Epoch 780/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8787 - loss: 0.3234 - val_accuracy: 0.6782 - val_loss: 1.1650\n",
      "Epoch 781/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8974 - loss: 0.3070 - val_accuracy: 0.6802 - val_loss: 1.1784\n",
      "Epoch 782/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8619 - loss: 0.3646 - val_accuracy: 0.6660 - val_loss: 1.1556\n",
      "Epoch 783/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8681 - loss: 0.3758 - val_accuracy: 0.6680 - val_loss: 1.2123\n",
      "Epoch 784/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8788 - loss: 0.3533 - val_accuracy: 0.6741 - val_loss: 1.2086\n",
      "Epoch 785/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8641 - loss: 0.3847 - val_accuracy: 0.6538 - val_loss: 1.1470\n",
      "Epoch 786/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8515 - loss: 0.3921 - val_accuracy: 0.6904 - val_loss: 1.0931\n",
      "Epoch 787/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8496 - loss: 0.4023 - val_accuracy: 0.6925 - val_loss: 1.1596\n",
      "Epoch 788/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8506 - loss: 0.4034 - val_accuracy: 0.6965 - val_loss: 1.0853\n",
      "Epoch 789/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8628 - loss: 0.3592 - val_accuracy: 0.6640 - val_loss: 1.2267\n",
      "Epoch 790/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8621 - loss: 0.3668 - val_accuracy: 0.6843 - val_loss: 1.1690\n",
      "Epoch 791/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8693 - loss: 0.3581 - val_accuracy: 0.6925 - val_loss: 1.1578\n",
      "Epoch 792/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8417 - loss: 0.4451 - val_accuracy: 0.6721 - val_loss: 1.1549\n",
      "Epoch 793/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8379 - loss: 0.3967 - val_accuracy: 0.6640 - val_loss: 1.1731\n",
      "Epoch 794/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8731 - loss: 0.3503 - val_accuracy: 0.6823 - val_loss: 1.1318\n",
      "Epoch 795/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8763 - loss: 0.3407 - val_accuracy: 0.6823 - val_loss: 1.1962\n",
      "Epoch 796/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8738 - loss: 0.3706 - val_accuracy: 0.6721 - val_loss: 1.1869\n",
      "Epoch 797/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8631 - loss: 0.3725 - val_accuracy: 0.6741 - val_loss: 1.1687\n",
      "Epoch 798/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8645 - loss: 0.3793 - val_accuracy: 0.6843 - val_loss: 1.1692\n",
      "Epoch 799/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8626 - loss: 0.3705 - val_accuracy: 0.6864 - val_loss: 1.2031\n",
      "Epoch 800/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8733 - loss: 0.3461 - val_accuracy: 0.6843 - val_loss: 1.1710\n",
      "Epoch 801/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8733 - loss: 0.3645 - val_accuracy: 0.6904 - val_loss: 1.1995\n",
      "Epoch 802/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8779 - loss: 0.3085 - val_accuracy: 0.6680 - val_loss: 1.2258\n",
      "Epoch 803/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8694 - loss: 0.3749 - val_accuracy: 0.6904 - val_loss: 1.1372\n",
      "Epoch 804/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8651 - loss: 0.3774 - val_accuracy: 0.6741 - val_loss: 1.2094\n",
      "Epoch 805/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8526 - loss: 0.3861 - val_accuracy: 0.6864 - val_loss: 1.2253\n",
      "Epoch 806/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8733 - loss: 0.3520 - val_accuracy: 0.6680 - val_loss: 1.1834\n",
      "Epoch 807/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8384 - loss: 0.4328 - val_accuracy: 0.6823 - val_loss: 1.1935\n",
      "Epoch 808/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8525 - loss: 0.4096 - val_accuracy: 0.6762 - val_loss: 1.1692\n",
      "Epoch 809/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8799 - loss: 0.3557 - val_accuracy: 0.6660 - val_loss: 1.1665\n",
      "Epoch 810/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8482 - loss: 0.4210 - val_accuracy: 0.6843 - val_loss: 1.1780\n",
      "Epoch 811/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8566 - loss: 0.4202 - val_accuracy: 0.6701 - val_loss: 1.1188\n",
      "Epoch 812/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8646 - loss: 0.3971 - val_accuracy: 0.6802 - val_loss: 1.1488\n",
      "Epoch 813/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8656 - loss: 0.3875 - val_accuracy: 0.6762 - val_loss: 1.1718\n",
      "Epoch 814/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8663 - loss: 0.3724 - val_accuracy: 0.6945 - val_loss: 1.2209\n",
      "Epoch 815/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8575 - loss: 0.3913 - val_accuracy: 0.6823 - val_loss: 1.2063\n",
      "Epoch 816/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8622 - loss: 0.3715 - val_accuracy: 0.6680 - val_loss: 1.1741\n",
      "Epoch 817/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8593 - loss: 0.3733 - val_accuracy: 0.6823 - val_loss: 1.1703\n",
      "Epoch 818/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8665 - loss: 0.3523 - val_accuracy: 0.6701 - val_loss: 1.2109\n",
      "Epoch 819/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8671 - loss: 0.3964 - val_accuracy: 0.6578 - val_loss: 1.1973\n",
      "Epoch 820/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8671 - loss: 0.3618 - val_accuracy: 0.6640 - val_loss: 1.1768\n",
      "Epoch 821/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8669 - loss: 0.3778 - val_accuracy: 0.6640 - val_loss: 1.2653\n",
      "Epoch 822/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8699 - loss: 0.3486 - val_accuracy: 0.6843 - val_loss: 1.1607\n",
      "Epoch 823/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8727 - loss: 0.3579 - val_accuracy: 0.6884 - val_loss: 1.1296\n",
      "Epoch 824/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8682 - loss: 0.3747 - val_accuracy: 0.6721 - val_loss: 1.1590\n",
      "Epoch 825/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8642 - loss: 0.3481 - val_accuracy: 0.6782 - val_loss: 1.2247\n",
      "Epoch 826/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8786 - loss: 0.3393 - val_accuracy: 0.6741 - val_loss: 1.1957\n",
      "Epoch 827/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8742 - loss: 0.3446 - val_accuracy: 0.6925 - val_loss: 1.1676\n",
      "Epoch 828/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8887 - loss: 0.3098 - val_accuracy: 0.6578 - val_loss: 1.2343\n",
      "Epoch 829/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8614 - loss: 0.3885 - val_accuracy: 0.6762 - val_loss: 1.1642\n",
      "Epoch 830/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8566 - loss: 0.3704 - val_accuracy: 0.6884 - val_loss: 1.1785\n",
      "Epoch 831/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8485 - loss: 0.3721 - val_accuracy: 0.6782 - val_loss: 1.1587\n",
      "Epoch 832/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8486 - loss: 0.4134 - val_accuracy: 0.6823 - val_loss: 1.1674\n",
      "Epoch 833/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8783 - loss: 0.3529 - val_accuracy: 0.6965 - val_loss: 1.1379\n",
      "Epoch 834/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8694 - loss: 0.3646 - val_accuracy: 0.6619 - val_loss: 1.2196\n",
      "Epoch 835/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8598 - loss: 0.3680 - val_accuracy: 0.6640 - val_loss: 1.1794\n",
      "Epoch 836/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8733 - loss: 0.3384 - val_accuracy: 0.6945 - val_loss: 1.1057\n",
      "Epoch 837/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8559 - loss: 0.3831 - val_accuracy: 0.6721 - val_loss: 1.1631\n",
      "Epoch 838/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8550 - loss: 0.4033 - val_accuracy: 0.6578 - val_loss: 1.2913\n",
      "Epoch 839/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.3453 - val_accuracy: 0.6864 - val_loss: 1.1600\n",
      "Epoch 840/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8615 - loss: 0.3869 - val_accuracy: 0.6904 - val_loss: 1.1698\n",
      "Epoch 841/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8452 - loss: 0.4096 - val_accuracy: 0.6864 - val_loss: 1.1945\n",
      "Epoch 842/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8626 - loss: 0.3962 - val_accuracy: 0.6864 - val_loss: 1.1949\n",
      "Epoch 843/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8762 - loss: 0.3415 - val_accuracy: 0.6721 - val_loss: 1.1691\n",
      "Epoch 844/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8723 - loss: 0.3529 - val_accuracy: 0.6680 - val_loss: 1.2361\n",
      "Epoch 845/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8635 - loss: 0.3416 - val_accuracy: 0.6578 - val_loss: 1.2076\n",
      "Epoch 846/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8816 - loss: 0.3188 - val_accuracy: 0.6599 - val_loss: 1.1873\n",
      "Epoch 847/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8808 - loss: 0.3306 - val_accuracy: 0.6517 - val_loss: 1.2810\n",
      "Epoch 848/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8720 - loss: 0.3303 - val_accuracy: 0.6660 - val_loss: 1.2187\n",
      "Epoch 849/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8554 - loss: 0.3794 - val_accuracy: 0.6558 - val_loss: 1.2436\n",
      "Epoch 850/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8453 - loss: 0.4177 - val_accuracy: 0.6701 - val_loss: 1.2002\n",
      "Epoch 851/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8537 - loss: 0.3927 - val_accuracy: 0.6741 - val_loss: 1.1661\n",
      "Epoch 852/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8457 - loss: 0.4294 - val_accuracy: 0.6599 - val_loss: 1.2043\n",
      "Epoch 853/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8544 - loss: 0.3879 - val_accuracy: 0.6578 - val_loss: 1.2235\n",
      "Epoch 854/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8730 - loss: 0.3704 - val_accuracy: 0.6660 - val_loss: 1.2444\n",
      "Epoch 855/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8601 - loss: 0.3844 - val_accuracy: 0.6721 - val_loss: 1.2271\n",
      "Epoch 856/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8433 - loss: 0.4102 - val_accuracy: 0.6660 - val_loss: 1.1757\n",
      "Epoch 857/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8586 - loss: 0.4017 - val_accuracy: 0.6619 - val_loss: 1.2253\n",
      "Epoch 858/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8505 - loss: 0.4221 - val_accuracy: 0.6680 - val_loss: 1.2280\n",
      "Epoch 859/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8523 - loss: 0.4053 - val_accuracy: 0.6701 - val_loss: 1.1947\n",
      "Epoch 860/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8643 - loss: 0.3670 - val_accuracy: 0.6802 - val_loss: 1.1894\n",
      "Epoch 861/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8711 - loss: 0.3510 - val_accuracy: 0.6640 - val_loss: 1.1940\n",
      "Epoch 862/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8837 - loss: 0.3158 - val_accuracy: 0.6721 - val_loss: 1.1893\n",
      "Epoch 863/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8688 - loss: 0.3459 - val_accuracy: 0.6864 - val_loss: 1.2742\n",
      "Epoch 864/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8702 - loss: 0.3654 - val_accuracy: 0.6782 - val_loss: 1.1661\n",
      "Epoch 865/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8611 - loss: 0.3779 - val_accuracy: 0.6680 - val_loss: 1.2441\n",
      "Epoch 866/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8848 - loss: 0.3046 - val_accuracy: 0.6904 - val_loss: 1.2173\n",
      "Epoch 867/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8747 - loss: 0.3399 - val_accuracy: 0.6884 - val_loss: 1.2352\n",
      "Epoch 868/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8743 - loss: 0.3689 - val_accuracy: 0.6680 - val_loss: 1.2278\n",
      "Epoch 869/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8755 - loss: 0.3550 - val_accuracy: 0.6843 - val_loss: 1.2070\n",
      "Epoch 870/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8546 - loss: 0.3886 - val_accuracy: 0.6640 - val_loss: 1.2259\n",
      "Epoch 871/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8747 - loss: 0.3486 - val_accuracy: 0.6680 - val_loss: 1.3093\n",
      "Epoch 872/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8739 - loss: 0.3574 - val_accuracy: 0.6701 - val_loss: 1.2683\n",
      "Epoch 873/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8705 - loss: 0.3681 - val_accuracy: 0.6864 - val_loss: 1.3119\n",
      "Epoch 874/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8705 - loss: 0.3521 - val_accuracy: 0.6701 - val_loss: 1.2971\n",
      "Epoch 875/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8756 - loss: 0.3204 - val_accuracy: 0.6843 - val_loss: 1.2991\n",
      "Epoch 876/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8567 - loss: 0.3812 - val_accuracy: 0.6680 - val_loss: 1.2432\n",
      "Epoch 877/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8580 - loss: 0.4042 - val_accuracy: 0.6762 - val_loss: 1.2138\n",
      "Epoch 878/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8707 - loss: 0.3541 - val_accuracy: 0.6843 - val_loss: 1.1438\n",
      "Epoch 879/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8828 - loss: 0.3430 - val_accuracy: 0.6884 - val_loss: 1.2160\n",
      "Epoch 880/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8754 - loss: 0.3479 - val_accuracy: 0.6782 - val_loss: 1.2118\n",
      "Epoch 881/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8610 - loss: 0.3713 - val_accuracy: 0.6680 - val_loss: 1.1242\n",
      "Epoch 882/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8802 - loss: 0.3337 - val_accuracy: 0.6782 - val_loss: 1.2034\n",
      "Epoch 883/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8711 - loss: 0.3533 - val_accuracy: 0.6782 - val_loss: 1.2408\n",
      "Epoch 884/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8884 - loss: 0.3220 - val_accuracy: 0.6823 - val_loss: 1.2392\n",
      "Epoch 885/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8778 - loss: 0.3466 - val_accuracy: 0.6762 - val_loss: 1.2008\n",
      "Epoch 886/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8821 - loss: 0.3116 - val_accuracy: 0.6680 - val_loss: 1.2389\n",
      "Epoch 887/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8691 - loss: 0.3578 - val_accuracy: 0.6802 - val_loss: 1.1648\n",
      "Epoch 888/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8534 - loss: 0.3846 - val_accuracy: 0.6782 - val_loss: 1.2256\n",
      "Epoch 889/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8458 - loss: 0.4009 - val_accuracy: 0.6701 - val_loss: 1.1832\n",
      "Epoch 890/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8646 - loss: 0.3617 - val_accuracy: 0.6619 - val_loss: 1.2849\n",
      "Epoch 891/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8696 - loss: 0.3645 - val_accuracy: 0.6782 - val_loss: 1.2030\n",
      "Epoch 892/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8665 - loss: 0.3526 - val_accuracy: 0.6701 - val_loss: 1.2310\n",
      "Epoch 893/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8669 - loss: 0.3495 - val_accuracy: 0.6680 - val_loss: 1.2278\n",
      "Epoch 894/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8632 - loss: 0.3841 - val_accuracy: 0.6660 - val_loss: 1.1775\n",
      "Epoch 895/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8673 - loss: 0.3367 - val_accuracy: 0.6762 - val_loss: 1.2067\n",
      "Epoch 896/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8757 - loss: 0.3543 - val_accuracy: 0.6701 - val_loss: 1.1768\n",
      "Epoch 897/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8695 - loss: 0.3424 - val_accuracy: 0.6762 - val_loss: 1.2503\n",
      "Epoch 898/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8642 - loss: 0.3614 - val_accuracy: 0.6782 - val_loss: 1.2397\n",
      "Epoch 899/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8865 - loss: 0.3120 - val_accuracy: 0.6802 - val_loss: 1.2500\n",
      "Epoch 900/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8762 - loss: 0.3341 - val_accuracy: 0.6701 - val_loss: 1.2722\n",
      "Epoch 901/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8932 - loss: 0.3000 - val_accuracy: 0.6660 - val_loss: 1.2807\n",
      "Epoch 902/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8551 - loss: 0.3684 - val_accuracy: 0.6945 - val_loss: 1.1393\n",
      "Epoch 903/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8673 - loss: 0.3734 - val_accuracy: 0.6741 - val_loss: 1.1782\n",
      "Epoch 904/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8578 - loss: 0.3775 - val_accuracy: 0.6660 - val_loss: 1.2178\n",
      "Epoch 905/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8911 - loss: 0.3227 - val_accuracy: 0.6864 - val_loss: 1.2026\n",
      "Epoch 906/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8696 - loss: 0.3479 - val_accuracy: 0.6721 - val_loss: 1.1963\n",
      "Epoch 907/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8649 - loss: 0.3658 - val_accuracy: 0.6619 - val_loss: 1.2235\n",
      "Epoch 908/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8839 - loss: 0.3271 - val_accuracy: 0.6660 - val_loss: 1.3304\n",
      "Epoch 909/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8694 - loss: 0.3581 - val_accuracy: 0.6802 - val_loss: 1.2002\n",
      "Epoch 910/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8763 - loss: 0.3454 - val_accuracy: 0.6721 - val_loss: 1.2496\n",
      "Epoch 911/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8744 - loss: 0.3076 - val_accuracy: 0.6762 - val_loss: 1.2228\n",
      "Epoch 912/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8736 - loss: 0.3430 - val_accuracy: 0.6741 - val_loss: 1.1981\n",
      "Epoch 913/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8668 - loss: 0.3607 - val_accuracy: 0.6823 - val_loss: 1.1587\n",
      "Epoch 914/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8942 - loss: 0.3237 - val_accuracy: 0.6680 - val_loss: 1.2148\n",
      "Epoch 915/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8735 - loss: 0.3531 - val_accuracy: 0.6578 - val_loss: 1.2419\n",
      "Epoch 916/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8796 - loss: 0.3385 - val_accuracy: 0.6578 - val_loss: 1.2966\n",
      "Epoch 917/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8630 - loss: 0.3875 - val_accuracy: 0.6741 - val_loss: 1.2007\n",
      "Epoch 918/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8725 - loss: 0.3581 - val_accuracy: 0.6904 - val_loss: 1.2052\n",
      "Epoch 919/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8569 - loss: 0.3682 - val_accuracy: 0.6558 - val_loss: 1.2363\n",
      "Epoch 920/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8722 - loss: 0.3510 - val_accuracy: 0.6599 - val_loss: 1.1601\n",
      "Epoch 921/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8827 - loss: 0.3168 - val_accuracy: 0.6619 - val_loss: 1.2384\n",
      "Epoch 922/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8681 - loss: 0.3818 - val_accuracy: 0.6558 - val_loss: 1.2759\n",
      "Epoch 923/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8512 - loss: 0.4203 - val_accuracy: 0.6640 - val_loss: 1.1969\n",
      "Epoch 924/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8715 - loss: 0.3612 - val_accuracy: 0.6782 - val_loss: 1.2266\n",
      "Epoch 925/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8460 - loss: 0.3989 - val_accuracy: 0.6741 - val_loss: 1.1406\n",
      "Epoch 926/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8799 - loss: 0.3589 - val_accuracy: 0.6578 - val_loss: 1.2345\n",
      "Epoch 927/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8813 - loss: 0.3405 - val_accuracy: 0.6701 - val_loss: 1.1867\n",
      "Epoch 928/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8955 - loss: 0.2948 - val_accuracy: 0.6782 - val_loss: 1.1506\n",
      "Epoch 929/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8961 - loss: 0.3022 - val_accuracy: 0.6599 - val_loss: 1.1755\n",
      "Epoch 930/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8914 - loss: 0.3042 - val_accuracy: 0.6904 - val_loss: 1.1809\n",
      "Epoch 931/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8753 - loss: 0.3382 - val_accuracy: 0.6721 - val_loss: 1.2143\n",
      "Epoch 932/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8585 - loss: 0.3545 - val_accuracy: 0.6721 - val_loss: 1.2023\n",
      "Epoch 933/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8548 - loss: 0.3813 - val_accuracy: 0.6904 - val_loss: 1.1532\n",
      "Epoch 934/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8899 - loss: 0.3165 - val_accuracy: 0.6619 - val_loss: 1.3126\n",
      "Epoch 935/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8625 - loss: 0.3629 - val_accuracy: 0.6782 - val_loss: 1.1986\n",
      "Epoch 936/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8390 - loss: 0.4271 - val_accuracy: 0.6517 - val_loss: 1.1883\n",
      "Epoch 937/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8641 - loss: 0.3566 - val_accuracy: 0.6660 - val_loss: 1.2111\n",
      "Epoch 938/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8775 - loss: 0.3546 - val_accuracy: 0.6640 - val_loss: 1.2360\n",
      "Epoch 939/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8630 - loss: 0.3542 - val_accuracy: 0.6721 - val_loss: 1.2250\n",
      "Epoch 940/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8857 - loss: 0.3202 - val_accuracy: 0.6762 - val_loss: 1.2254\n",
      "Epoch 941/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8883 - loss: 0.3161 - val_accuracy: 0.6843 - val_loss: 1.2088\n",
      "Epoch 942/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8753 - loss: 0.3532 - val_accuracy: 0.6823 - val_loss: 1.2196\n",
      "Epoch 943/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8717 - loss: 0.3634 - val_accuracy: 0.6721 - val_loss: 1.2071\n",
      "Epoch 944/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8663 - loss: 0.3319 - val_accuracy: 0.6965 - val_loss: 1.1357\n",
      "Epoch 945/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8766 - loss: 0.3376 - val_accuracy: 0.6680 - val_loss: 1.2744\n",
      "Epoch 946/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8566 - loss: 0.4077 - val_accuracy: 0.6660 - val_loss: 1.2625\n",
      "Epoch 947/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8935 - loss: 0.3107 - val_accuracy: 0.6823 - val_loss: 1.1698\n",
      "Epoch 948/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8764 - loss: 0.3488 - val_accuracy: 0.6721 - val_loss: 1.1701\n",
      "Epoch 949/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8980 - loss: 0.2924 - val_accuracy: 0.6640 - val_loss: 1.2488\n",
      "Epoch 950/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8826 - loss: 0.3142 - val_accuracy: 0.6701 - val_loss: 1.2047\n",
      "Epoch 951/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8727 - loss: 0.3396 - val_accuracy: 0.6884 - val_loss: 1.2378\n",
      "Epoch 952/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8825 - loss: 0.3446 - val_accuracy: 0.6741 - val_loss: 1.2568\n",
      "Epoch 953/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8782 - loss: 0.3598 - val_accuracy: 0.6802 - val_loss: 1.2489\n",
      "Epoch 954/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8714 - loss: 0.3546 - val_accuracy: 0.6721 - val_loss: 1.2220\n",
      "Epoch 955/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8793 - loss: 0.3317 - val_accuracy: 0.6558 - val_loss: 1.2495\n",
      "Epoch 956/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8586 - loss: 0.3626 - val_accuracy: 0.6721 - val_loss: 1.2045\n",
      "Epoch 957/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8732 - loss: 0.3436 - val_accuracy: 0.6884 - val_loss: 1.2055\n",
      "Epoch 958/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8739 - loss: 0.3290 - val_accuracy: 0.6599 - val_loss: 1.2713\n",
      "Epoch 959/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8779 - loss: 0.3194 - val_accuracy: 0.6762 - val_loss: 1.2063\n",
      "Epoch 960/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8838 - loss: 0.3156 - val_accuracy: 0.6640 - val_loss: 1.2966\n",
      "Epoch 961/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8731 - loss: 0.3287 - val_accuracy: 0.6925 - val_loss: 1.1669\n",
      "Epoch 962/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8883 - loss: 0.3154 - val_accuracy: 0.6578 - val_loss: 1.2689\n",
      "Epoch 963/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8557 - loss: 0.3801 - val_accuracy: 0.6599 - val_loss: 1.2304\n",
      "Epoch 964/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8720 - loss: 0.3416 - val_accuracy: 0.6640 - val_loss: 1.3007\n",
      "Epoch 965/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8612 - loss: 0.3476 - val_accuracy: 0.6640 - val_loss: 1.2784\n",
      "Epoch 966/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8909 - loss: 0.2830 - val_accuracy: 0.6721 - val_loss: 1.3434\n",
      "Epoch 967/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8647 - loss: 0.3687 - val_accuracy: 0.6538 - val_loss: 1.2914\n",
      "Epoch 968/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8668 - loss: 0.3557 - val_accuracy: 0.6517 - val_loss: 1.2584\n",
      "Epoch 969/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8782 - loss: 0.3372 - val_accuracy: 0.6701 - val_loss: 1.2331\n",
      "Epoch 970/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8588 - loss: 0.3782 - val_accuracy: 0.6721 - val_loss: 1.1783\n",
      "Epoch 971/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8774 - loss: 0.3290 - val_accuracy: 0.6721 - val_loss: 1.2082\n",
      "Epoch 972/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8641 - loss: 0.3479 - val_accuracy: 0.6680 - val_loss: 1.2840\n",
      "Epoch 973/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8662 - loss: 0.3842 - val_accuracy: 0.6660 - val_loss: 1.2636\n",
      "Epoch 974/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8712 - loss: 0.3426 - val_accuracy: 0.6680 - val_loss: 1.2695\n",
      "Epoch 975/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8786 - loss: 0.3311 - val_accuracy: 0.6823 - val_loss: 1.1847\n",
      "Epoch 976/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8830 - loss: 0.3338 - val_accuracy: 0.6762 - val_loss: 1.2137\n",
      "Epoch 977/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9021 - loss: 0.2915 - val_accuracy: 0.6782 - val_loss: 1.2421\n",
      "Epoch 978/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8924 - loss: 0.2903 - val_accuracy: 0.6802 - val_loss: 1.2042\n",
      "Epoch 979/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8925 - loss: 0.3048 - val_accuracy: 0.6843 - val_loss: 1.2252\n",
      "Epoch 980/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8960 - loss: 0.3069 - val_accuracy: 0.6680 - val_loss: 1.3231\n",
      "Epoch 981/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.3436 - val_accuracy: 0.6721 - val_loss: 1.2405\n",
      "Epoch 982/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8636 - loss: 0.3579 - val_accuracy: 0.6619 - val_loss: 1.2707\n",
      "Epoch 983/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8729 - loss: 0.3898 - val_accuracy: 0.6578 - val_loss: 1.2925\n",
      "Epoch 984/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8802 - loss: 0.3540 - val_accuracy: 0.6619 - val_loss: 1.2420\n",
      "Epoch 985/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8907 - loss: 0.2887 - val_accuracy: 0.6721 - val_loss: 1.2876\n",
      "Epoch 986/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8837 - loss: 0.3232 - val_accuracy: 0.6843 - val_loss: 1.2076\n",
      "Epoch 987/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8934 - loss: 0.3165 - val_accuracy: 0.6619 - val_loss: 1.2941\n",
      "Epoch 988/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8816 - loss: 0.3081 - val_accuracy: 0.6782 - val_loss: 1.3757\n",
      "Epoch 989/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8830 - loss: 0.3519 - val_accuracy: 0.6538 - val_loss: 1.3251\n",
      "Epoch 990/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8748 - loss: 0.3226 - val_accuracy: 0.6864 - val_loss: 1.2005\n",
      "Epoch 991/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8808 - loss: 0.3322 - val_accuracy: 0.6762 - val_loss: 1.1870\n",
      "Epoch 992/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8565 - loss: 0.3639 - val_accuracy: 0.6782 - val_loss: 1.2178\n",
      "Epoch 993/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8725 - loss: 0.3445 - val_accuracy: 0.6762 - val_loss: 1.2926\n",
      "Epoch 994/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8761 - loss: 0.3249 - val_accuracy: 0.6701 - val_loss: 1.2581\n",
      "Epoch 995/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8652 - loss: 0.3304 - val_accuracy: 0.6701 - val_loss: 1.2132\n",
      "Epoch 996/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8767 - loss: 0.3523 - val_accuracy: 0.6823 - val_loss: 1.2428\n",
      "Epoch 997/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8734 - loss: 0.3704 - val_accuracy: 0.6538 - val_loss: 1.3318\n",
      "Epoch 998/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8516 - loss: 0.4003 - val_accuracy: 0.6782 - val_loss: 1.1927\n",
      "Epoch 999/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8921 - loss: 0.3076 - val_accuracy: 0.6741 - val_loss: 1.2324\n",
      "Epoch 1000/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8662 - loss: 0.3523 - val_accuracy: 0.6884 - val_loss: 1.2877\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6567 - loss: 1.4236\n",
      "Test accuracy: 0.6883910298347473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert to categorical\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_cat = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_cat = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps=1, features)\n",
    "x_train_reshaped = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test_reshaped = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(1, x_train.shape[1])))  # (timesteps, features)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_reshaped, y_train_cat, epochs=1000, batch_size=32, validation_data=(x_test_reshaped, y_test_cat))\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(x_test_reshaped, y_test_cat)\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d68ca660-a4d6-4ab2-99fc-f7f304c31af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6567 - loss: 1.4236\n",
      "Test accuracy: 0.6883910298347473\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test_reshaped, y_test_cat)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474e12c-9169-4472-ba1c-749a05f90e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f6359-a2f8-4239-b622-3e7b5389d0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98803778-aa81-4600-b0ac-17816b3d2721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.80      0.79      0.79        76\n",
      "        calm       0.65      0.86      0.74        59\n",
      "     disgust       0.61      0.61      0.61        44\n",
      "     fearful       0.64      0.68      0.66        68\n",
      "       happy       0.78      0.72      0.75        81\n",
      "     neutral       0.72      0.61      0.66        38\n",
      "         sad       0.70      0.57      0.63        83\n",
      "   surprised       0.54      0.62      0.58        42\n",
      "\n",
      "    accuracy                           0.69       491\n",
      "   macro avg       0.68      0.68      0.68       491\n",
      "weighted avg       0.69      0.69      0.69       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict class probabilities and convert to class indices\n",
    "y_pred_probs = model.predict(x_test_reshaped)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Use y_test_encoded (integer labels) or y_true as shown above\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4cfdd30-f1a6-4397-91bf-9c88273cdeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for file in glob.glob('C:/Users/Dell/Downloads/emotion_det/song/Actor_*/*.wav'):\n",
    "    c = c+1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49499ebf-e9d6-41e4-8b78-a9a4aa1de970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for file in glob.glob('C:/Users/Dell/Downloads/emotion_det/speech/Actor_*/*.wav'):\n",
    "    c = c+1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db83d232-6bed-451c-af7e-ccb1a08118ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da858e13-5f40-4a3e-897b-afcacc67c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# pattern = 'speech'  # or 'song', etc.\n",
    "pattern = 'speech'\n",
    "src_folder = f'C:/Users/Dell/Downloads/emotion_det/{pattern}/Actor_*/*.wav'\n",
    "dst_folder = 'C:/Users/Dell/Downloads/emotion_det/common/'\n",
    "\n",
    "\n",
    "for file in glob.glob(src_folder):\n",
    "    file_name = os.path.basename(file)\n",
    "    dst_file = os.path.join(dst_folder, file_name)\n",
    "    shutil.copyfile(file, dst_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb205f-2951-44f7-8187-3f115e1a169d",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a62878-1460-4e0f-9b03-dbdb07e7c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfa09bf-3938-4d96-ae8d-d595c4a4808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
    "    stft = np.abs(librosa.stft(X)) if chroma or mel else None  # Compute STFT once if needed\n",
    "    result = np.array([])\n",
    "    \n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "        \n",
    "    if chroma:\n",
    "        chroma_feat = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, chroma_feat))\n",
    "        \n",
    "    if mel:\n",
    "        # Fixed: Added y= parameter for melspectrogram\n",
    "        mel_feat = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, mel_feat))\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88af60ab-6336-4a3a-9670-ad283e35a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Automatically derive observed emotions from the dictionary\n",
    "observed_emotions = list(emotions.values())  # Now includes all emotions\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    x, y = [], []\n",
    "    # Process both speech and song files\n",
    "    for pattern in ['speech', 'song']:\n",
    "        for file in glob.glob(f'C:/Users/Dell/Downloads/emotion_det/{pattern}/Actor_*/*.wav'):\n",
    "            file_name = os.path.basename(file)\n",
    "            emotion_code = file_name.split(\"-\")[2]\n",
    "            \n",
    "            # Safely get emotion, skip if code is invalid\n",
    "            emotion = emotions.get(emotion_code)\n",
    "            if emotion not in observed_emotions:\n",
    "                continue\n",
    "            \n",
    "            # Feature extraction\n",
    "            feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "            x.append(feature)\n",
    "            y.append(emotion)\n",
    "    \n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995a06af-0913-47a4-a2a0-49f247f144e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208f9e35-6a61-41c8-8cfe-e5a118132a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "                                              0.0/8.1 MB ? eta -:--:--\n",
      "                                              0.0/8.1 MB 1.4 MB/s eta 0:00:06\n",
      "                                              0.1/8.1 MB 1.3 MB/s eta 0:00:07\n",
      "     -                                        0.2/8.1 MB 1.7 MB/s eta 0:00:05\n",
      "     -                                        0.3/8.1 MB 1.5 MB/s eta 0:00:06\n",
      "     --                                       0.5/8.1 MB 2.3 MB/s eta 0:00:04\n",
      "     ---                                      0.7/8.1 MB 2.3 MB/s eta 0:00:04\n",
      "     ----                                     0.9/8.1 MB 2.8 MB/s eta 0:00:03\n",
      "     -----                                    1.1/8.1 MB 3.2 MB/s eta 0:00:03\n",
      "     ------                                   1.4/8.1 MB 3.2 MB/s eta 0:00:03\n",
      "     -------                                  1.5/8.1 MB 3.4 MB/s eta 0:00:02\n",
      "     --------                                 1.7/8.1 MB 3.3 MB/s eta 0:00:02\n",
      "     ---------                                2.0/8.1 MB 3.6 MB/s eta 0:00:02\n",
      "     -----------                              2.2/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "     -----------                              2.4/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------                             2.5/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "     -------------                            2.8/8.1 MB 3.8 MB/s eta 0:00:02\n",
      "     --------------                           3.0/8.1 MB 3.8 MB/s eta 0:00:02\n",
      "     ---------------                          3.2/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------                         3.4/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------                        3.5/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------                        3.5/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------                        3.5/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------                        3.5/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------                        3.5/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------                   4.5/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     ----------------------                   4.5/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     -----------------------                  4.8/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------                 5.0/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------                5.2/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "     --------------------------               5.3/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------              5.5/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------             5.7/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     -----------------------------            6.0/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------           6.1/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------          6.3/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     --------------------------------         6.5/8.1 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.8/8.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ----------------------------------       7.0/8.1 MB 4.0 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.2/8.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.4/8.1 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.7/8.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.9/8.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.1/8.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.1/8.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.1/8.1 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl (222 kB)\n",
      "                                              0.0/222.0 kB ? eta -:--:--\n",
      "     ------------------------------------   215.0/222.0 kB 6.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 222.0/222.0 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "                                              0.0/2.2 MB ? eta -:--:--\n",
      "     ----                                     0.3/2.2 MB 5.2 MB/s eta 0:00:01\n",
      "     --------                                 0.5/2.2 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------                            0.7/2.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------                       1.0/2.2 MB 5.4 MB/s eta 0:00:01\n",
      "     -----------------------                  1.3/2.2 MB 5.5 MB/s eta 0:00:01\n",
      "     ----------------------------             1.6/2.2 MB 5.6 MB/s eta 0:00:01\n",
      "     --------------------------------         1.8/2.2 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     2.1/2.2 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.2/2.2 MB 4.1 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "                                              0.0/72.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 72.0/72.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "                                              0.0/2.7 MB ? eta -:--:--\n",
      "     ---                                      0.2/2.7 MB 6.9 MB/s eta 0:00:01\n",
      "     ------                                   0.5/2.7 MB 4.7 MB/s eta 0:00:01\n",
      "     ----------                               0.7/2.7 MB 5.5 MB/s eta 0:00:01\n",
      "     --------------                           0.9/2.7 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------                       1.2/2.7 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------                    1.5/2.7 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------                1.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------------             1.9/2.7 MB 5.2 MB/s eta 0:00:01\n",
      "     --------------------------------         2.2/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     -----------------------------------      2.4/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "                                              0.0/111.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 111.1/111.1 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e11251e-4a8c-4a63-9949-5d763a107bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from optree->keras) (4.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd7a1c3-b2fd-4de2-9a80-68f0fc808fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b7e7361-2266-48cb-831f-0ea4210bd54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Downloads\\emotion_det\\emotion\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Flatten, \n",
    "    Dropout, \n",
    "    Activation, \n",
    "    Conv1D, \n",
    "    MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Your model code remains the same\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, 5, padding='same', input_shape=(180, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=8))\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))  # 8 emotion classes\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1118c-9dcb-460d-b8d6-2efa6faeef4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36a37bb-3b96-4a3a-b67e-21b8f55f98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Convert to categorical\n",
    "y_train_cat = to_categorical(y_train_encoded)\n",
    "y_test_cat = to_categorical(y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c39a76-e4cb-4289-a7b8-c2a4d675ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshaped = np.expand_dims(x_train, axis=2)  # Shape: (1839, 180, 1)\n",
    "x_test_reshaped = np.expand_dims(x_test, axis=2)    # Shape: (613, 180, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da980136-37bd-481a-9594-7d00569aaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "opt = RMSprop(learning_rate=0.00005, rho=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86006f8-6104-432e-b1df-41eceae81bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.6148 - loss: 1.0756 - val_accuracy: 0.5438 - val_loss: 1.1813\n",
      "Epoch 2/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6268 - loss: 1.0733 - val_accuracy: 0.5458 - val_loss: 1.1611\n",
      "Epoch 3/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6469 - loss: 1.0366 - val_accuracy: 0.5662 - val_loss: 1.1737\n",
      "Epoch 4/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5983 - loss: 1.0897 - val_accuracy: 0.5540 - val_loss: 1.1394\n",
      "Epoch 5/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6338 - loss: 1.0274 - val_accuracy: 0.5397 - val_loss: 1.1580\n",
      "Epoch 6/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.6146 - loss: 1.0614 - val_accuracy: 0.5519 - val_loss: 1.1613\n",
      "Epoch 7/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6006 - loss: 1.0606 - val_accuracy: 0.5377 - val_loss: 1.2058\n",
      "Epoch 8/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6287 - loss: 1.0397 - val_accuracy: 0.5723 - val_loss: 1.1272\n",
      "Epoch 9/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6269 - loss: 1.0342 - val_accuracy: 0.5784 - val_loss: 1.1376\n",
      "Epoch 10/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6225 - loss: 1.0296 - val_accuracy: 0.5621 - val_loss: 1.1422\n",
      "Epoch 11/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6453 - loss: 1.0160 - val_accuracy: 0.5642 - val_loss: 1.1337\n",
      "Epoch 12/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6309 - loss: 1.0049 - val_accuracy: 0.5723 - val_loss: 1.1246\n",
      "Epoch 13/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6290 - loss: 1.0163 - val_accuracy: 0.5682 - val_loss: 1.1302\n",
      "Epoch 14/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6409 - loss: 1.0015 - val_accuracy: 0.5804 - val_loss: 1.1201\n",
      "Epoch 15/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6207 - loss: 1.0006 - val_accuracy: 0.5621 - val_loss: 1.1535\n",
      "Epoch 16/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6266 - loss: 1.0259 - val_accuracy: 0.5642 - val_loss: 1.1186\n",
      "Epoch 17/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6459 - loss: 0.9824 - val_accuracy: 0.5743 - val_loss: 1.1288\n",
      "Epoch 18/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6345 - loss: 0.9905 - val_accuracy: 0.5845 - val_loss: 1.1165\n",
      "Epoch 19/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6402 - loss: 0.9852 - val_accuracy: 0.6008 - val_loss: 1.1187\n",
      "Epoch 20/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6239 - loss: 1.0215 - val_accuracy: 0.5825 - val_loss: 1.1214\n",
      "Epoch 21/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6447 - loss: 1.0089 - val_accuracy: 0.5682 - val_loss: 1.1206\n",
      "Epoch 22/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6328 - loss: 1.0076 - val_accuracy: 0.5825 - val_loss: 1.1451\n",
      "Epoch 23/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6483 - loss: 0.9799 - val_accuracy: 0.5988 - val_loss: 1.1286\n",
      "Epoch 24/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6275 - loss: 0.9957 - val_accuracy: 0.5845 - val_loss: 1.1213\n",
      "Epoch 25/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6501 - loss: 0.9711 - val_accuracy: 0.5927 - val_loss: 1.0940\n",
      "Epoch 26/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6533 - loss: 0.9643 - val_accuracy: 0.5886 - val_loss: 1.0961\n",
      "Epoch 27/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6234 - loss: 0.9907 - val_accuracy: 0.5621 - val_loss: 1.1303\n",
      "Epoch 28/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6330 - loss: 1.0150 - val_accuracy: 0.5866 - val_loss: 1.1117\n",
      "Epoch 29/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6449 - loss: 0.9724 - val_accuracy: 0.6008 - val_loss: 1.0901\n",
      "Epoch 30/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6522 - loss: 0.9660 - val_accuracy: 0.6029 - val_loss: 1.0909\n",
      "Epoch 31/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6455 - loss: 0.9823 - val_accuracy: 0.5967 - val_loss: 1.0859\n",
      "Epoch 32/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6393 - loss: 0.9883 - val_accuracy: 0.5825 - val_loss: 1.0969\n",
      "Epoch 33/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6632 - loss: 0.9403 - val_accuracy: 0.5845 - val_loss: 1.0981\n",
      "Epoch 34/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6650 - loss: 0.9388 - val_accuracy: 0.6110 - val_loss: 1.0952\n",
      "Epoch 35/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6541 - loss: 0.9680 - val_accuracy: 0.5886 - val_loss: 1.0822\n",
      "Epoch 36/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6465 - loss: 0.9628 - val_accuracy: 0.6008 - val_loss: 1.0774\n",
      "Epoch 37/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6353 - loss: 0.9642 - val_accuracy: 0.5764 - val_loss: 1.0949\n",
      "Epoch 38/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6800 - loss: 0.9025 - val_accuracy: 0.5886 - val_loss: 1.0979\n",
      "Epoch 39/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6468 - loss: 0.9951 - val_accuracy: 0.6029 - val_loss: 1.0777\n",
      "Epoch 40/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6682 - loss: 0.9160 - val_accuracy: 0.6090 - val_loss: 1.0731\n",
      "Epoch 41/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6583 - loss: 0.9481 - val_accuracy: 0.6130 - val_loss: 1.0699\n",
      "Epoch 42/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6570 - loss: 0.9571 - val_accuracy: 0.5580 - val_loss: 1.0906\n",
      "Epoch 43/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6614 - loss: 0.9467 - val_accuracy: 0.6069 - val_loss: 1.0686\n",
      "Epoch 44/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6417 - loss: 0.9350 - val_accuracy: 0.5804 - val_loss: 1.0703\n",
      "Epoch 45/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6401 - loss: 0.9442 - val_accuracy: 0.5988 - val_loss: 1.0640\n",
      "Epoch 46/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6703 - loss: 0.9158 - val_accuracy: 0.5967 - val_loss: 1.0683\n",
      "Epoch 47/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6615 - loss: 0.9152 - val_accuracy: 0.5947 - val_loss: 1.0525\n",
      "Epoch 48/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6830 - loss: 0.9011 - val_accuracy: 0.5947 - val_loss: 1.0727\n",
      "Epoch 49/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6578 - loss: 0.9158 - val_accuracy: 0.5906 - val_loss: 1.0765\n",
      "Epoch 50/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6784 - loss: 0.9294 - val_accuracy: 0.6029 - val_loss: 1.0645\n",
      "Epoch 51/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6553 - loss: 0.9259 - val_accuracy: 0.6130 - val_loss: 1.0614\n",
      "Epoch 52/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6543 - loss: 0.9367 - val_accuracy: 0.6090 - val_loss: 1.0477\n",
      "Epoch 53/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6737 - loss: 0.9047 - val_accuracy: 0.6130 - val_loss: 1.0484\n",
      "Epoch 54/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6682 - loss: 0.9099 - val_accuracy: 0.6130 - val_loss: 1.0514\n",
      "Epoch 55/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6969 - loss: 0.8607 - val_accuracy: 0.6049 - val_loss: 1.0477\n",
      "Epoch 56/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6523 - loss: 0.9312 - val_accuracy: 0.5845 - val_loss: 1.0536\n",
      "Epoch 57/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6701 - loss: 0.9064 - val_accuracy: 0.6049 - val_loss: 1.0462\n",
      "Epoch 58/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6837 - loss: 0.8723 - val_accuracy: 0.6049 - val_loss: 1.0837\n",
      "Epoch 59/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6940 - loss: 0.8762 - val_accuracy: 0.5988 - val_loss: 1.0648\n",
      "Epoch 60/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6909 - loss: 0.8738 - val_accuracy: 0.5947 - val_loss: 1.0598\n",
      "Epoch 61/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6842 - loss: 0.8780 - val_accuracy: 0.6029 - val_loss: 1.0574\n",
      "Epoch 62/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6846 - loss: 0.8822 - val_accuracy: 0.6191 - val_loss: 1.0511\n",
      "Epoch 63/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6904 - loss: 0.8965 - val_accuracy: 0.5947 - val_loss: 1.0666\n",
      "Epoch 64/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6916 - loss: 0.8701 - val_accuracy: 0.5988 - val_loss: 1.0383\n",
      "Epoch 65/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6918 - loss: 0.8447 - val_accuracy: 0.5927 - val_loss: 1.0710\n",
      "Epoch 66/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6754 - loss: 0.8709 - val_accuracy: 0.5988 - val_loss: 1.0517\n",
      "Epoch 67/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6716 - loss: 0.9010 - val_accuracy: 0.5764 - val_loss: 1.0498\n",
      "Epoch 68/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6812 - loss: 0.8938 - val_accuracy: 0.5988 - val_loss: 1.0502\n",
      "Epoch 69/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6723 - loss: 0.8782 - val_accuracy: 0.5967 - val_loss: 1.0434\n",
      "Epoch 70/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6833 - loss: 0.8749 - val_accuracy: 0.6049 - val_loss: 1.0468\n",
      "Epoch 71/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6834 - loss: 0.8754 - val_accuracy: 0.6191 - val_loss: 1.0193\n",
      "Epoch 72/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7042 - loss: 0.8473 - val_accuracy: 0.6110 - val_loss: 1.0296\n",
      "Epoch 73/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6957 - loss: 0.8716 - val_accuracy: 0.6151 - val_loss: 1.0266\n",
      "Epoch 74/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6972 - loss: 0.8603 - val_accuracy: 0.6008 - val_loss: 1.0364\n",
      "Epoch 75/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6623 - loss: 0.8919 - val_accuracy: 0.6191 - val_loss: 1.0305\n",
      "Epoch 76/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6691 - loss: 0.8894 - val_accuracy: 0.6232 - val_loss: 1.0251\n",
      "Epoch 77/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6859 - loss: 0.8609 - val_accuracy: 0.6212 - val_loss: 1.0335\n",
      "Epoch 78/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6906 - loss: 0.8487 - val_accuracy: 0.6130 - val_loss: 1.0286\n",
      "Epoch 79/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6847 - loss: 0.8649 - val_accuracy: 0.6151 - val_loss: 1.0226\n",
      "Epoch 80/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6906 - loss: 0.8503 - val_accuracy: 0.6191 - val_loss: 1.0485\n",
      "Epoch 81/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6739 - loss: 0.8492 - val_accuracy: 0.6171 - val_loss: 1.0350\n",
      "Epoch 82/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7013 - loss: 0.8280 - val_accuracy: 0.6110 - val_loss: 1.0209\n",
      "Epoch 83/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6917 - loss: 0.8545 - val_accuracy: 0.6069 - val_loss: 1.0607\n",
      "Epoch 84/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6923 - loss: 0.8563 - val_accuracy: 0.6354 - val_loss: 1.0216\n",
      "Epoch 85/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6907 - loss: 0.8400 - val_accuracy: 0.6232 - val_loss: 1.0270\n",
      "Epoch 86/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6894 - loss: 0.8504 - val_accuracy: 0.6253 - val_loss: 1.0095\n",
      "Epoch 87/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6889 - loss: 0.8363 - val_accuracy: 0.5988 - val_loss: 1.0439\n",
      "Epoch 88/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6929 - loss: 0.8260 - val_accuracy: 0.6293 - val_loss: 1.0137\n",
      "Epoch 89/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6798 - loss: 0.8534 - val_accuracy: 0.6130 - val_loss: 1.0171\n",
      "Epoch 90/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7025 - loss: 0.8389 - val_accuracy: 0.6069 - val_loss: 1.0245\n",
      "Epoch 91/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7059 - loss: 0.8035 - val_accuracy: 0.6293 - val_loss: 1.0272\n",
      "Epoch 92/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7117 - loss: 0.8079 - val_accuracy: 0.6171 - val_loss: 1.0139\n",
      "Epoch 93/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7132 - loss: 0.8066 - val_accuracy: 0.6253 - val_loss: 0.9983\n",
      "Epoch 94/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7105 - loss: 0.8014 - val_accuracy: 0.6110 - val_loss: 1.0193\n",
      "Epoch 95/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7122 - loss: 0.8046 - val_accuracy: 0.5967 - val_loss: 1.0382\n",
      "Epoch 96/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7047 - loss: 0.8082 - val_accuracy: 0.6090 - val_loss: 1.0157\n",
      "Epoch 97/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6996 - loss: 0.8238 - val_accuracy: 0.6191 - val_loss: 1.0263\n",
      "Epoch 98/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6948 - loss: 0.8267 - val_accuracy: 0.6069 - val_loss: 1.0113\n",
      "Epoch 99/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7044 - loss: 0.8062 - val_accuracy: 0.6354 - val_loss: 1.0058\n",
      "Epoch 100/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6921 - loss: 0.7983 - val_accuracy: 0.6171 - val_loss: 1.0103\n",
      "Epoch 101/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7125 - loss: 0.7892 - val_accuracy: 0.5906 - val_loss: 1.0432\n",
      "Epoch 102/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7181 - loss: 0.7717 - val_accuracy: 0.6253 - val_loss: 0.9923\n",
      "Epoch 103/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7343 - loss: 0.7569 - val_accuracy: 0.5988 - val_loss: 1.0141\n",
      "Epoch 104/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7038 - loss: 0.8146 - val_accuracy: 0.6293 - val_loss: 0.9883\n",
      "Epoch 105/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7130 - loss: 0.7992 - val_accuracy: 0.6334 - val_loss: 1.0038\n",
      "Epoch 106/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6938 - loss: 0.8138 - val_accuracy: 0.6354 - val_loss: 0.9908\n",
      "Epoch 107/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7219 - loss: 0.7828 - val_accuracy: 0.6212 - val_loss: 0.9984\n",
      "Epoch 108/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6976 - loss: 0.8197 - val_accuracy: 0.6334 - val_loss: 1.0101\n",
      "Epoch 109/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7180 - loss: 0.8010 - val_accuracy: 0.6171 - val_loss: 1.0176\n",
      "Epoch 110/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6990 - loss: 0.8087 - val_accuracy: 0.6456 - val_loss: 0.9918\n",
      "Epoch 111/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7132 - loss: 0.7571 - val_accuracy: 0.5967 - val_loss: 0.9992\n",
      "Epoch 112/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7195 - loss: 0.7759 - val_accuracy: 0.6354 - val_loss: 1.0027\n",
      "Epoch 113/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7052 - loss: 0.8074 - val_accuracy: 0.6273 - val_loss: 1.0011\n",
      "Epoch 114/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7257 - loss: 0.7711 - val_accuracy: 0.6273 - val_loss: 0.9834\n",
      "Epoch 115/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7278 - loss: 0.7611 - val_accuracy: 0.6273 - val_loss: 1.0109\n",
      "Epoch 116/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7070 - loss: 0.8004 - val_accuracy: 0.6415 - val_loss: 0.9923\n",
      "Epoch 117/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7327 - loss: 0.7700 - val_accuracy: 0.6334 - val_loss: 0.9862\n",
      "Epoch 118/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7063 - loss: 0.7968 - val_accuracy: 0.6375 - val_loss: 0.9979\n",
      "Epoch 119/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7000 - loss: 0.7869 - val_accuracy: 0.6334 - val_loss: 0.9832\n",
      "Epoch 120/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7155 - loss: 0.7965 - val_accuracy: 0.6212 - val_loss: 1.0412\n",
      "Epoch 121/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7434 - loss: 0.7382 - val_accuracy: 0.6497 - val_loss: 0.9830\n",
      "Epoch 122/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7252 - loss: 0.7490 - val_accuracy: 0.6314 - val_loss: 0.9851\n",
      "Epoch 123/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7304 - loss: 0.7763 - val_accuracy: 0.6436 - val_loss: 0.9934\n",
      "Epoch 124/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7003 - loss: 0.7932 - val_accuracy: 0.6334 - val_loss: 0.9949\n",
      "Epoch 125/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7245 - loss: 0.7656 - val_accuracy: 0.6456 - val_loss: 0.9811\n",
      "Epoch 126/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7416 - loss: 0.7332 - val_accuracy: 0.6314 - val_loss: 0.9864\n",
      "Epoch 127/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7247 - loss: 0.7556 - val_accuracy: 0.6273 - val_loss: 0.9843\n",
      "Epoch 128/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7478 - loss: 0.7358 - val_accuracy: 0.6253 - val_loss: 0.9881\n",
      "Epoch 129/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7331 - loss: 0.7517 - val_accuracy: 0.6212 - val_loss: 0.9934\n",
      "Epoch 130/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7411 - loss: 0.7134 - val_accuracy: 0.6354 - val_loss: 0.9950\n",
      "Epoch 131/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7268 - loss: 0.7655 - val_accuracy: 0.6191 - val_loss: 1.0136\n",
      "Epoch 132/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7356 - loss: 0.7002 - val_accuracy: 0.6151 - val_loss: 0.9723\n",
      "Epoch 133/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7303 - loss: 0.7646 - val_accuracy: 0.6354 - val_loss: 0.9849\n",
      "Epoch 134/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7210 - loss: 0.7490 - val_accuracy: 0.6253 - val_loss: 0.9779\n",
      "Epoch 135/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7139 - loss: 0.7487 - val_accuracy: 0.6477 - val_loss: 0.9672\n",
      "Epoch 136/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7341 - loss: 0.7328 - val_accuracy: 0.6293 - val_loss: 0.9732\n",
      "Epoch 137/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7339 - loss: 0.7495 - val_accuracy: 0.6395 - val_loss: 0.9888\n",
      "Epoch 138/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7377 - loss: 0.7188 - val_accuracy: 0.6130 - val_loss: 0.9970\n",
      "Epoch 139/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7515 - loss: 0.7146 - val_accuracy: 0.6293 - val_loss: 0.9674\n",
      "Epoch 140/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7176 - loss: 0.7501 - val_accuracy: 0.6415 - val_loss: 0.9654\n",
      "Epoch 141/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7447 - loss: 0.7255 - val_accuracy: 0.6273 - val_loss: 0.9771\n",
      "Epoch 142/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7281 - loss: 0.7592 - val_accuracy: 0.6334 - val_loss: 0.9917\n",
      "Epoch 143/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7265 - loss: 0.7493 - val_accuracy: 0.6334 - val_loss: 0.9603\n",
      "Epoch 144/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7648 - loss: 0.7079 - val_accuracy: 0.6538 - val_loss: 0.9641\n",
      "Epoch 145/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7480 - loss: 0.7111 - val_accuracy: 0.6090 - val_loss: 0.9698\n",
      "Epoch 146/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7337 - loss: 0.7376 - val_accuracy: 0.6436 - val_loss: 0.9765\n",
      "Epoch 147/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7406 - loss: 0.6881 - val_accuracy: 0.6253 - val_loss: 0.9834\n",
      "Epoch 148/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7242 - loss: 0.7332 - val_accuracy: 0.6497 - val_loss: 0.9583\n",
      "Epoch 149/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7386 - loss: 0.7313 - val_accuracy: 0.6049 - val_loss: 0.9671\n",
      "Epoch 150/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7549 - loss: 0.7014 - val_accuracy: 0.6395 - val_loss: 0.9664\n",
      "Epoch 151/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7314 - loss: 0.7244 - val_accuracy: 0.6273 - val_loss: 0.9690\n",
      "Epoch 152/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7425 - loss: 0.6863 - val_accuracy: 0.6314 - val_loss: 0.9564\n",
      "Epoch 153/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7133 - loss: 0.7452 - val_accuracy: 0.6354 - val_loss: 0.9625\n",
      "Epoch 154/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7243 - loss: 0.7654 - val_accuracy: 0.6171 - val_loss: 0.9712\n",
      "Epoch 155/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7536 - loss: 0.7130 - val_accuracy: 0.6395 - val_loss: 0.9618\n",
      "Epoch 156/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7487 - loss: 0.6975 - val_accuracy: 0.6354 - val_loss: 0.9721\n",
      "Epoch 157/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7370 - loss: 0.7316 - val_accuracy: 0.6619 - val_loss: 0.9542\n",
      "Epoch 158/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7615 - loss: 0.6891 - val_accuracy: 0.6253 - val_loss: 0.9676\n",
      "Epoch 159/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7251 - loss: 0.7218 - val_accuracy: 0.6293 - val_loss: 0.9685\n",
      "Epoch 160/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7564 - loss: 0.6696 - val_accuracy: 0.6395 - val_loss: 0.9739\n",
      "Epoch 161/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7668 - loss: 0.6752 - val_accuracy: 0.6558 - val_loss: 0.9443\n",
      "Epoch 162/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7474 - loss: 0.6928 - val_accuracy: 0.6334 - val_loss: 0.9551\n",
      "Epoch 163/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7559 - loss: 0.6847 - val_accuracy: 0.6436 - val_loss: 0.9520\n",
      "Epoch 164/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7605 - loss: 0.6840 - val_accuracy: 0.6517 - val_loss: 0.9540\n",
      "Epoch 165/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7410 - loss: 0.7060 - val_accuracy: 0.6415 - val_loss: 0.9474\n",
      "Epoch 166/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7515 - loss: 0.6890 - val_accuracy: 0.6436 - val_loss: 0.9682\n",
      "Epoch 167/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7353 - loss: 0.7124 - val_accuracy: 0.6293 - val_loss: 0.9626\n",
      "Epoch 168/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7504 - loss: 0.6928 - val_accuracy: 0.6497 - val_loss: 0.9815\n",
      "Epoch 169/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7418 - loss: 0.7225 - val_accuracy: 0.6517 - val_loss: 0.9611\n",
      "Epoch 170/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7544 - loss: 0.6753 - val_accuracy: 0.6558 - val_loss: 0.9504\n",
      "Epoch 171/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7744 - loss: 0.6499 - val_accuracy: 0.6497 - val_loss: 0.9396\n",
      "Epoch 172/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7595 - loss: 0.6797 - val_accuracy: 0.6456 - val_loss: 0.9367\n",
      "Epoch 173/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7446 - loss: 0.6813 - val_accuracy: 0.6415 - val_loss: 0.9620\n",
      "Epoch 174/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7586 - loss: 0.6709 - val_accuracy: 0.6395 - val_loss: 0.9554\n",
      "Epoch 175/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7515 - loss: 0.6847 - val_accuracy: 0.6456 - val_loss: 0.9743\n",
      "Epoch 176/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7685 - loss: 0.6648 - val_accuracy: 0.6497 - val_loss: 0.9710\n",
      "Epoch 177/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7654 - loss: 0.6576 - val_accuracy: 0.6599 - val_loss: 0.9513\n",
      "Epoch 178/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7613 - loss: 0.6663 - val_accuracy: 0.6436 - val_loss: 0.9488\n",
      "Epoch 179/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7440 - loss: 0.6978 - val_accuracy: 0.6477 - val_loss: 0.9334\n",
      "Epoch 180/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7510 - loss: 0.7173 - val_accuracy: 0.6558 - val_loss: 0.9438\n",
      "Epoch 181/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7655 - loss: 0.6571 - val_accuracy: 0.6517 - val_loss: 0.9740\n",
      "Epoch 182/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7571 - loss: 0.6642 - val_accuracy: 0.6375 - val_loss: 0.9464\n",
      "Epoch 183/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7517 - loss: 0.7003 - val_accuracy: 0.6497 - val_loss: 0.9390\n",
      "Epoch 184/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7441 - loss: 0.6904 - val_accuracy: 0.6415 - val_loss: 0.9380\n",
      "Epoch 185/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7696 - loss: 0.6544 - val_accuracy: 0.6436 - val_loss: 0.9625\n",
      "Epoch 186/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7572 - loss: 0.6521 - val_accuracy: 0.6375 - val_loss: 0.9426\n",
      "Epoch 187/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7584 - loss: 0.6971 - val_accuracy: 0.6415 - val_loss: 0.9280\n",
      "Epoch 188/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7748 - loss: 0.6461 - val_accuracy: 0.6456 - val_loss: 0.9585\n",
      "Epoch 189/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7768 - loss: 0.6537 - val_accuracy: 0.6578 - val_loss: 0.9325\n",
      "Epoch 190/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7603 - loss: 0.6631 - val_accuracy: 0.6558 - val_loss: 0.9437\n",
      "Epoch 191/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7610 - loss: 0.6665 - val_accuracy: 0.6558 - val_loss: 0.9697\n",
      "Epoch 192/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7590 - loss: 0.6682 - val_accuracy: 0.6395 - val_loss: 0.9643\n",
      "Epoch 193/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7746 - loss: 0.6373 - val_accuracy: 0.6578 - val_loss: 0.9393\n",
      "Epoch 194/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7507 - loss: 0.6730 - val_accuracy: 0.6558 - val_loss: 0.9504\n",
      "Epoch 195/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7613 - loss: 0.6586 - val_accuracy: 0.6497 - val_loss: 0.9366\n",
      "Epoch 196/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7872 - loss: 0.6104 - val_accuracy: 0.6415 - val_loss: 0.9483\n",
      "Epoch 197/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7604 - loss: 0.6630 - val_accuracy: 0.6354 - val_loss: 0.9509\n",
      "Epoch 198/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7588 - loss: 0.6727 - val_accuracy: 0.6415 - val_loss: 0.9557\n",
      "Epoch 199/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7640 - loss: 0.6477 - val_accuracy: 0.6354 - val_loss: 0.9545\n",
      "Epoch 200/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7761 - loss: 0.6393 - val_accuracy: 0.6578 - val_loss: 0.9377\n",
      "Epoch 201/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7687 - loss: 0.6747 - val_accuracy: 0.6436 - val_loss: 0.9448\n",
      "Epoch 202/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7711 - loss: 0.6658 - val_accuracy: 0.6456 - val_loss: 0.9285\n",
      "Epoch 203/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7739 - loss: 0.6474 - val_accuracy: 0.6538 - val_loss: 0.9381\n",
      "Epoch 204/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7718 - loss: 0.6188 - val_accuracy: 0.6477 - val_loss: 0.9425\n",
      "Epoch 205/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7693 - loss: 0.6516 - val_accuracy: 0.6517 - val_loss: 0.9547\n",
      "Epoch 206/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7767 - loss: 0.6170 - val_accuracy: 0.6599 - val_loss: 0.9645\n",
      "Epoch 207/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7661 - loss: 0.6502 - val_accuracy: 0.6477 - val_loss: 0.9566\n",
      "Epoch 208/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7645 - loss: 0.6424 - val_accuracy: 0.6517 - val_loss: 0.9173\n",
      "Epoch 209/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7577 - loss: 0.6410 - val_accuracy: 0.6517 - val_loss: 0.9370\n",
      "Epoch 210/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7789 - loss: 0.6169 - val_accuracy: 0.6538 - val_loss: 0.9486\n",
      "Epoch 211/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7714 - loss: 0.6206 - val_accuracy: 0.6497 - val_loss: 0.9329\n",
      "Epoch 212/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7683 - loss: 0.6483 - val_accuracy: 0.6680 - val_loss: 0.9408\n",
      "Epoch 213/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7958 - loss: 0.6033 - val_accuracy: 0.6456 - val_loss: 0.9352\n",
      "Epoch 214/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 0.6184 - val_accuracy: 0.6497 - val_loss: 0.9353\n",
      "Epoch 215/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7728 - loss: 0.6323 - val_accuracy: 0.6497 - val_loss: 0.9455\n",
      "Epoch 216/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7743 - loss: 0.6292 - val_accuracy: 0.6599 - val_loss: 0.9386\n",
      "Epoch 217/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7778 - loss: 0.6091 - val_accuracy: 0.6538 - val_loss: 0.9165\n",
      "Epoch 218/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7663 - loss: 0.6472 - val_accuracy: 0.6538 - val_loss: 0.9388\n",
      "Epoch 219/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7781 - loss: 0.6382 - val_accuracy: 0.6538 - val_loss: 0.9132\n",
      "Epoch 220/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7711 - loss: 0.6245 - val_accuracy: 0.6477 - val_loss: 0.9277\n",
      "Epoch 221/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7899 - loss: 0.6170 - val_accuracy: 0.6375 - val_loss: 0.9488\n",
      "Epoch 222/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7793 - loss: 0.6102 - val_accuracy: 0.6578 - val_loss: 0.9296\n",
      "Epoch 223/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8063 - loss: 0.5759 - val_accuracy: 0.6517 - val_loss: 0.9660\n",
      "Epoch 224/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7704 - loss: 0.6073 - val_accuracy: 0.6558 - val_loss: 0.9362\n",
      "Epoch 225/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7890 - loss: 0.6161 - val_accuracy: 0.6497 - val_loss: 0.9178\n",
      "Epoch 226/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7888 - loss: 0.5916 - val_accuracy: 0.6660 - val_loss: 0.9128\n",
      "Epoch 227/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7821 - loss: 0.6024 - val_accuracy: 0.6558 - val_loss: 0.9492\n",
      "Epoch 228/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7922 - loss: 0.6039 - val_accuracy: 0.6619 - val_loss: 0.9226\n",
      "Epoch 229/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7537 - loss: 0.6435 - val_accuracy: 0.6558 - val_loss: 0.9196\n",
      "Epoch 230/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7717 - loss: 0.6132 - val_accuracy: 0.6599 - val_loss: 0.9012\n",
      "Epoch 231/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7660 - loss: 0.6311 - val_accuracy: 0.6456 - val_loss: 0.9515\n",
      "Epoch 232/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7889 - loss: 0.6050 - val_accuracy: 0.6599 - val_loss: 0.9252\n",
      "Epoch 233/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7881 - loss: 0.6094 - val_accuracy: 0.6599 - val_loss: 0.9261\n",
      "Epoch 234/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7987 - loss: 0.6016 - val_accuracy: 0.6558 - val_loss: 0.9140\n",
      "Epoch 235/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7883 - loss: 0.5930 - val_accuracy: 0.6660 - val_loss: 0.9309\n",
      "Epoch 236/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8006 - loss: 0.6035 - val_accuracy: 0.6680 - val_loss: 0.9332\n",
      "Epoch 237/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7643 - loss: 0.6180 - val_accuracy: 0.6578 - val_loss: 0.9265\n",
      "Epoch 238/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7984 - loss: 0.5962 - val_accuracy: 0.6558 - val_loss: 0.9173\n",
      "Epoch 239/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7887 - loss: 0.5827 - val_accuracy: 0.6599 - val_loss: 0.9258\n",
      "Epoch 240/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7917 - loss: 0.5801 - val_accuracy: 0.6701 - val_loss: 0.9086\n",
      "Epoch 241/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8103 - loss: 0.5673 - val_accuracy: 0.6538 - val_loss: 0.9369\n",
      "Epoch 242/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7840 - loss: 0.5990 - val_accuracy: 0.6578 - val_loss: 0.9216\n",
      "Epoch 243/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7821 - loss: 0.6172 - val_accuracy: 0.6721 - val_loss: 0.9142\n",
      "Epoch 244/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7830 - loss: 0.5917 - val_accuracy: 0.6558 - val_loss: 0.9103\n",
      "Epoch 245/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7921 - loss: 0.6072 - val_accuracy: 0.6680 - val_loss: 0.9141\n",
      "Epoch 246/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7832 - loss: 0.5611 - val_accuracy: 0.6517 - val_loss: 0.9194\n",
      "Epoch 247/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7887 - loss: 0.5824 - val_accuracy: 0.6578 - val_loss: 0.9321\n",
      "Epoch 248/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8042 - loss: 0.5846 - val_accuracy: 0.6497 - val_loss: 0.9481\n",
      "Epoch 249/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7733 - loss: 0.6078 - val_accuracy: 0.6680 - val_loss: 0.9062\n",
      "Epoch 250/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7884 - loss: 0.6013 - val_accuracy: 0.6721 - val_loss: 0.9079\n",
      "Epoch 251/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8102 - loss: 0.5641 - val_accuracy: 0.6660 - val_loss: 0.9276\n",
      "Epoch 252/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7823 - loss: 0.5676 - val_accuracy: 0.6660 - val_loss: 0.9302\n",
      "Epoch 253/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7922 - loss: 0.6002 - val_accuracy: 0.6701 - val_loss: 0.9153\n",
      "Epoch 254/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7918 - loss: 0.5697 - val_accuracy: 0.6558 - val_loss: 0.9373\n",
      "Epoch 255/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7941 - loss: 0.5703 - val_accuracy: 0.6538 - val_loss: 0.9262\n",
      "Epoch 256/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7938 - loss: 0.5770 - val_accuracy: 0.6619 - val_loss: 0.9371\n",
      "Epoch 257/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7797 - loss: 0.6092 - val_accuracy: 0.6436 - val_loss: 0.9399\n",
      "Epoch 258/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7880 - loss: 0.5987 - val_accuracy: 0.6762 - val_loss: 0.9195\n",
      "Epoch 259/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8006 - loss: 0.5608 - val_accuracy: 0.6619 - val_loss: 0.9202\n",
      "Epoch 260/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7947 - loss: 0.5869 - val_accuracy: 0.6802 - val_loss: 0.9244\n",
      "Epoch 261/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8029 - loss: 0.5773 - val_accuracy: 0.6517 - val_loss: 0.9363\n",
      "Epoch 262/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7902 - loss: 0.5678 - val_accuracy: 0.6782 - val_loss: 0.9258\n",
      "Epoch 263/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8075 - loss: 0.5612 - val_accuracy: 0.6660 - val_loss: 0.9109\n",
      "Epoch 264/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7915 - loss: 0.5939 - val_accuracy: 0.6660 - val_loss: 0.8983\n",
      "Epoch 265/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7873 - loss: 0.5809 - val_accuracy: 0.6599 - val_loss: 0.9002\n",
      "Epoch 266/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7808 - loss: 0.5774 - val_accuracy: 0.6680 - val_loss: 0.9042\n",
      "Epoch 267/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7982 - loss: 0.5794 - val_accuracy: 0.6782 - val_loss: 0.8956\n",
      "Epoch 268/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8202 - loss: 0.5325 - val_accuracy: 0.6599 - val_loss: 0.8965\n",
      "Epoch 269/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8125 - loss: 0.5316 - val_accuracy: 0.6741 - val_loss: 0.9108\n",
      "Epoch 270/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8110 - loss: 0.5651 - val_accuracy: 0.6660 - val_loss: 0.9144\n",
      "Epoch 271/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8217 - loss: 0.5325 - val_accuracy: 0.6640 - val_loss: 0.9137\n",
      "Epoch 272/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8058 - loss: 0.5526 - val_accuracy: 0.6741 - val_loss: 0.9196\n",
      "Epoch 273/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8087 - loss: 0.5754 - val_accuracy: 0.6578 - val_loss: 0.9075\n",
      "Epoch 274/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8053 - loss: 0.5368 - val_accuracy: 0.6599 - val_loss: 0.9106\n",
      "Epoch 275/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7992 - loss: 0.5685 - val_accuracy: 0.6660 - val_loss: 0.9210\n",
      "Epoch 276/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8211 - loss: 0.5425 - val_accuracy: 0.6578 - val_loss: 0.9078\n",
      "Epoch 277/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7994 - loss: 0.5613 - val_accuracy: 0.6578 - val_loss: 0.9066\n",
      "Epoch 278/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8133 - loss: 0.5376 - val_accuracy: 0.6456 - val_loss: 0.9277\n",
      "Epoch 279/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7938 - loss: 0.5850 - val_accuracy: 0.6660 - val_loss: 0.9046\n",
      "Epoch 280/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8106 - loss: 0.5431 - val_accuracy: 0.6517 - val_loss: 0.9192\n",
      "Epoch 281/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7887 - loss: 0.5467 - val_accuracy: 0.6578 - val_loss: 0.9102\n",
      "Epoch 282/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8036 - loss: 0.5534 - val_accuracy: 0.6762 - val_loss: 0.9122\n",
      "Epoch 283/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7877 - loss: 0.5610 - val_accuracy: 0.6599 - val_loss: 0.9369\n",
      "Epoch 284/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7884 - loss: 0.5580 - val_accuracy: 0.6680 - val_loss: 0.9176\n",
      "Epoch 285/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8135 - loss: 0.5392 - val_accuracy: 0.6721 - val_loss: 0.8992\n",
      "Epoch 286/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7953 - loss: 0.5646 - val_accuracy: 0.6640 - val_loss: 0.9249\n",
      "Epoch 287/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8092 - loss: 0.5311 - val_accuracy: 0.6578 - val_loss: 0.9158\n",
      "Epoch 288/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8164 - loss: 0.5305 - val_accuracy: 0.6599 - val_loss: 0.9126\n",
      "Epoch 289/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7960 - loss: 0.5529 - val_accuracy: 0.6701 - val_loss: 0.8927\n",
      "Epoch 290/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8284 - loss: 0.4880 - val_accuracy: 0.6477 - val_loss: 0.9248\n",
      "Epoch 291/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8038 - loss: 0.5592 - val_accuracy: 0.6762 - val_loss: 0.8976\n",
      "Epoch 292/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8124 - loss: 0.5282 - val_accuracy: 0.6782 - val_loss: 0.9229\n",
      "Epoch 293/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8183 - loss: 0.5301 - val_accuracy: 0.6802 - val_loss: 0.9043\n",
      "Epoch 294/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8005 - loss: 0.5479 - val_accuracy: 0.6680 - val_loss: 0.8972\n",
      "Epoch 295/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8150 - loss: 0.5338 - val_accuracy: 0.6660 - val_loss: 0.9133\n",
      "Epoch 296/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8167 - loss: 0.5448 - val_accuracy: 0.6701 - val_loss: 0.9254\n",
      "Epoch 297/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8118 - loss: 0.5265 - val_accuracy: 0.6640 - val_loss: 0.8991\n",
      "Epoch 298/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8280 - loss: 0.5007 - val_accuracy: 0.6619 - val_loss: 0.9010\n",
      "Epoch 299/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8111 - loss: 0.5304 - val_accuracy: 0.6782 - val_loss: 0.8926\n",
      "Epoch 300/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8260 - loss: 0.5109 - val_accuracy: 0.6619 - val_loss: 0.9060\n",
      "Epoch 301/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8232 - loss: 0.5015 - val_accuracy: 0.6640 - val_loss: 0.9247\n",
      "Epoch 302/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8191 - loss: 0.5265 - val_accuracy: 0.6701 - val_loss: 0.8960\n",
      "Epoch 303/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8274 - loss: 0.5040 - val_accuracy: 0.6945 - val_loss: 0.8912\n",
      "Epoch 304/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7948 - loss: 0.5394 - val_accuracy: 0.6578 - val_loss: 0.9072\n",
      "Epoch 305/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8185 - loss: 0.5288 - val_accuracy: 0.6721 - val_loss: 0.9068\n",
      "Epoch 306/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8153 - loss: 0.5451 - val_accuracy: 0.6578 - val_loss: 0.9434\n",
      "Epoch 307/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8114 - loss: 0.5286 - val_accuracy: 0.6741 - val_loss: 0.9030\n",
      "Epoch 308/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8081 - loss: 0.5285 - val_accuracy: 0.6599 - val_loss: 0.9417\n",
      "Epoch 309/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.5465 - val_accuracy: 0.6721 - val_loss: 0.8951\n",
      "Epoch 310/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8279 - loss: 0.4966 - val_accuracy: 0.6680 - val_loss: 0.9030\n",
      "Epoch 311/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8304 - loss: 0.5054 - val_accuracy: 0.6721 - val_loss: 0.8895\n",
      "Epoch 312/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8128 - loss: 0.5210 - val_accuracy: 0.6823 - val_loss: 0.8927\n",
      "Epoch 313/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8226 - loss: 0.5112 - val_accuracy: 0.6721 - val_loss: 0.9012\n",
      "Epoch 314/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8379 - loss: 0.4882 - val_accuracy: 0.6599 - val_loss: 0.9051\n",
      "Epoch 315/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8192 - loss: 0.5160 - val_accuracy: 0.6558 - val_loss: 0.9138\n",
      "Epoch 316/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8317 - loss: 0.5082 - val_accuracy: 0.6823 - val_loss: 0.8985\n",
      "Epoch 317/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.5168 - val_accuracy: 0.6599 - val_loss: 0.9199\n",
      "Epoch 318/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.5011 - val_accuracy: 0.6640 - val_loss: 0.9296\n",
      "Epoch 319/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8110 - loss: 0.5228 - val_accuracy: 0.6721 - val_loss: 0.9002\n",
      "Epoch 320/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8188 - loss: 0.5160 - val_accuracy: 0.6802 - val_loss: 0.9019\n",
      "Epoch 321/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8279 - loss: 0.5041 - val_accuracy: 0.6802 - val_loss: 0.8853\n",
      "Epoch 322/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8298 - loss: 0.5013 - val_accuracy: 0.6741 - val_loss: 0.8936\n",
      "Epoch 323/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8136 - loss: 0.5148 - val_accuracy: 0.6660 - val_loss: 0.8992\n",
      "Epoch 324/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8120 - loss: 0.5162 - val_accuracy: 0.6721 - val_loss: 0.8828\n",
      "Epoch 325/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8435 - loss: 0.4733 - val_accuracy: 0.6701 - val_loss: 0.9003\n",
      "Epoch 326/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8369 - loss: 0.4680 - val_accuracy: 0.6864 - val_loss: 0.8994\n",
      "Epoch 327/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8203 - loss: 0.4980 - val_accuracy: 0.6640 - val_loss: 0.9262\n",
      "Epoch 328/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8288 - loss: 0.5022 - val_accuracy: 0.6660 - val_loss: 0.9105\n",
      "Epoch 329/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8265 - loss: 0.5040 - val_accuracy: 0.6802 - val_loss: 0.8862\n",
      "Epoch 330/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8282 - loss: 0.4879 - val_accuracy: 0.6599 - val_loss: 0.9106\n",
      "Epoch 331/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8178 - loss: 0.5168 - val_accuracy: 0.6660 - val_loss: 0.9112\n",
      "Epoch 332/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8366 - loss: 0.4873 - val_accuracy: 0.6741 - val_loss: 0.9119\n",
      "Epoch 333/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8178 - loss: 0.4905 - val_accuracy: 0.6640 - val_loss: 0.8918\n",
      "Epoch 334/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8262 - loss: 0.5094 - val_accuracy: 0.6762 - val_loss: 0.8976\n",
      "Epoch 335/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8279 - loss: 0.4708 - val_accuracy: 0.6741 - val_loss: 0.9053\n",
      "Epoch 336/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8335 - loss: 0.4772 - val_accuracy: 0.6965 - val_loss: 0.8915\n",
      "Epoch 337/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8177 - loss: 0.4892 - val_accuracy: 0.6721 - val_loss: 0.9008\n",
      "Epoch 338/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8255 - loss: 0.4747 - val_accuracy: 0.6802 - val_loss: 0.8882\n",
      "Epoch 339/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8319 - loss: 0.4655 - val_accuracy: 0.6741 - val_loss: 0.8984\n",
      "Epoch 340/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8339 - loss: 0.4813 - val_accuracy: 0.6721 - val_loss: 0.9168\n",
      "Epoch 341/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8356 - loss: 0.4740 - val_accuracy: 0.6741 - val_loss: 0.8912\n",
      "Epoch 342/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8096 - loss: 0.5067 - val_accuracy: 0.6843 - val_loss: 0.8698\n",
      "Epoch 343/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8482 - loss: 0.4806 - val_accuracy: 0.6802 - val_loss: 0.9089\n",
      "Epoch 344/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8396 - loss: 0.4701 - val_accuracy: 0.6619 - val_loss: 0.9060\n",
      "Epoch 345/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8346 - loss: 0.4904 - val_accuracy: 0.6741 - val_loss: 0.8952\n",
      "Epoch 346/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8186 - loss: 0.4945 - val_accuracy: 0.6741 - val_loss: 0.8942\n",
      "Epoch 347/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8257 - loss: 0.4779 - val_accuracy: 0.6599 - val_loss: 0.9093\n",
      "Epoch 348/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8204 - loss: 0.5026 - val_accuracy: 0.6701 - val_loss: 0.9062\n",
      "Epoch 349/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8379 - loss: 0.4667 - val_accuracy: 0.6884 - val_loss: 0.8802\n",
      "Epoch 350/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8311 - loss: 0.4879 - val_accuracy: 0.6741 - val_loss: 0.9009\n",
      "Epoch 351/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8411 - loss: 0.4743 - val_accuracy: 0.6864 - val_loss: 0.8979\n",
      "Epoch 352/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8557 - loss: 0.4380 - val_accuracy: 0.6701 - val_loss: 0.9033\n",
      "Epoch 353/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8415 - loss: 0.4632 - val_accuracy: 0.6762 - val_loss: 0.8808\n",
      "Epoch 354/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8422 - loss: 0.4634 - val_accuracy: 0.6701 - val_loss: 0.8881\n",
      "Epoch 355/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8447 - loss: 0.4491 - val_accuracy: 0.6640 - val_loss: 0.8981\n",
      "Epoch 356/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8368 - loss: 0.4708 - val_accuracy: 0.6701 - val_loss: 0.8865\n",
      "Epoch 357/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8287 - loss: 0.4922 - val_accuracy: 0.6660 - val_loss: 0.8845\n",
      "Epoch 358/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8394 - loss: 0.4354 - val_accuracy: 0.6782 - val_loss: 0.9026\n",
      "Epoch 359/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8289 - loss: 0.4690 - val_accuracy: 0.6721 - val_loss: 0.9277\n",
      "Epoch 360/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8271 - loss: 0.4716 - val_accuracy: 0.6701 - val_loss: 0.8884\n",
      "Epoch 361/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8423 - loss: 0.4920 - val_accuracy: 0.6680 - val_loss: 0.8891\n",
      "Epoch 362/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8461 - loss: 0.4407 - val_accuracy: 0.6619 - val_loss: 0.9261\n",
      "Epoch 363/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8265 - loss: 0.4757 - val_accuracy: 0.6599 - val_loss: 0.8919\n",
      "Epoch 364/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8283 - loss: 0.4563 - val_accuracy: 0.6945 - val_loss: 0.8787\n",
      "Epoch 365/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8388 - loss: 0.4653 - val_accuracy: 0.6864 - val_loss: 0.8702\n",
      "Epoch 366/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8423 - loss: 0.4524 - val_accuracy: 0.6762 - val_loss: 0.8792\n",
      "Epoch 367/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8537 - loss: 0.4322 - val_accuracy: 0.6904 - val_loss: 0.8872\n",
      "Epoch 368/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8512 - loss: 0.4334 - val_accuracy: 0.6904 - val_loss: 0.8584\n",
      "Epoch 369/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8320 - loss: 0.4480 - val_accuracy: 0.6884 - val_loss: 0.8768\n",
      "Epoch 370/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8526 - loss: 0.4361 - val_accuracy: 0.6640 - val_loss: 0.8815\n",
      "Epoch 371/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8202 - loss: 0.4715 - val_accuracy: 0.6680 - val_loss: 0.8811\n",
      "Epoch 372/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8422 - loss: 0.4435 - val_accuracy: 0.6701 - val_loss: 0.9017\n",
      "Epoch 373/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8348 - loss: 0.4729 - val_accuracy: 0.6802 - val_loss: 0.8632\n",
      "Epoch 374/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8427 - loss: 0.4484 - val_accuracy: 0.6823 - val_loss: 0.9086\n",
      "Epoch 375/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8300 - loss: 0.4731 - val_accuracy: 0.6802 - val_loss: 0.8676\n",
      "Epoch 376/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8312 - loss: 0.4663 - val_accuracy: 0.6721 - val_loss: 0.8957\n",
      "Epoch 377/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8442 - loss: 0.4494 - val_accuracy: 0.6741 - val_loss: 0.9094\n",
      "Epoch 378/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8355 - loss: 0.4711 - val_accuracy: 0.6884 - val_loss: 0.8846\n",
      "Epoch 379/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8446 - loss: 0.4526 - val_accuracy: 0.6701 - val_loss: 0.8864\n",
      "Epoch 380/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8350 - loss: 0.4522 - val_accuracy: 0.6599 - val_loss: 0.9001\n",
      "Epoch 381/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8452 - loss: 0.4319 - val_accuracy: 0.6721 - val_loss: 0.8580\n",
      "Epoch 382/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8474 - loss: 0.4452 - val_accuracy: 0.6538 - val_loss: 0.9018\n",
      "Epoch 383/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8263 - loss: 0.4740 - val_accuracy: 0.6823 - val_loss: 0.8852\n",
      "Epoch 384/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8483 - loss: 0.4426 - val_accuracy: 0.6904 - val_loss: 0.8742\n",
      "Epoch 385/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8532 - loss: 0.4246 - val_accuracy: 0.6701 - val_loss: 0.8851\n",
      "Epoch 386/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8432 - loss: 0.4685 - val_accuracy: 0.7006 - val_loss: 0.8840\n",
      "Epoch 387/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8352 - loss: 0.4568 - val_accuracy: 0.6741 - val_loss: 0.8733\n",
      "Epoch 388/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8453 - loss: 0.4417 - val_accuracy: 0.6782 - val_loss: 0.8684\n",
      "Epoch 389/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8631 - loss: 0.4256 - val_accuracy: 0.6782 - val_loss: 0.8778\n",
      "Epoch 390/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8584 - loss: 0.4316 - val_accuracy: 0.6721 - val_loss: 0.8715\n",
      "Epoch 391/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8588 - loss: 0.3916 - val_accuracy: 0.6762 - val_loss: 0.8793\n",
      "Epoch 392/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8415 - loss: 0.4354 - val_accuracy: 0.6782 - val_loss: 0.8934\n",
      "Epoch 393/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8510 - loss: 0.4399 - val_accuracy: 0.6762 - val_loss: 0.8831\n",
      "Epoch 394/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8234 - loss: 0.4894 - val_accuracy: 0.6843 - val_loss: 0.8679\n",
      "Epoch 395/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8534 - loss: 0.4111 - val_accuracy: 0.6721 - val_loss: 0.8769\n",
      "Epoch 396/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8319 - loss: 0.4655 - val_accuracy: 0.6864 - val_loss: 0.8680\n",
      "Epoch 397/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8632 - loss: 0.4146 - val_accuracy: 0.6741 - val_loss: 0.9027\n",
      "Epoch 398/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8361 - loss: 0.4269 - val_accuracy: 0.6843 - val_loss: 0.8778\n",
      "Epoch 399/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8523 - loss: 0.4133 - val_accuracy: 0.6823 - val_loss: 0.8745\n",
      "Epoch 400/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8367 - loss: 0.4557 - val_accuracy: 0.6965 - val_loss: 0.8687\n",
      "Epoch 401/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8595 - loss: 0.4036 - val_accuracy: 0.6721 - val_loss: 0.8765\n",
      "Epoch 402/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8521 - loss: 0.4022 - val_accuracy: 0.6904 - val_loss: 0.8690\n",
      "Epoch 403/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8404 - loss: 0.4420 - val_accuracy: 0.6904 - val_loss: 0.8733\n",
      "Epoch 404/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8606 - loss: 0.4094 - val_accuracy: 0.6823 - val_loss: 0.8882\n",
      "Epoch 405/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8618 - loss: 0.3947 - val_accuracy: 0.6721 - val_loss: 0.8759\n",
      "Epoch 406/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8537 - loss: 0.4324 - val_accuracy: 0.6823 - val_loss: 0.8639\n",
      "Epoch 407/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8668 - loss: 0.4125 - val_accuracy: 0.6864 - val_loss: 0.8856\n",
      "Epoch 408/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8645 - loss: 0.4237 - val_accuracy: 0.6864 - val_loss: 0.8839\n",
      "Epoch 409/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8444 - loss: 0.4301 - val_accuracy: 0.6884 - val_loss: 0.8964\n",
      "Epoch 410/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8554 - loss: 0.4373 - val_accuracy: 0.6762 - val_loss: 0.8703\n",
      "Epoch 411/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8488 - loss: 0.4250 - val_accuracy: 0.6802 - val_loss: 0.9031\n",
      "Epoch 412/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8592 - loss: 0.3937 - val_accuracy: 0.6802 - val_loss: 0.8681\n",
      "Epoch 413/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8638 - loss: 0.4142 - val_accuracy: 0.6904 - val_loss: 0.8975\n",
      "Epoch 414/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8527 - loss: 0.4088 - val_accuracy: 0.6721 - val_loss: 0.8962\n",
      "Epoch 415/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8664 - loss: 0.4023 - val_accuracy: 0.6741 - val_loss: 0.8818\n",
      "Epoch 416/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8581 - loss: 0.4071 - val_accuracy: 0.6823 - val_loss: 0.8933\n",
      "Epoch 417/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8694 - loss: 0.4086 - val_accuracy: 0.6660 - val_loss: 0.8909\n",
      "Epoch 418/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8545 - loss: 0.3977 - val_accuracy: 0.6680 - val_loss: 0.9094\n",
      "Epoch 419/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8605 - loss: 0.4229 - val_accuracy: 0.6904 - val_loss: 0.8718\n",
      "Epoch 420/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8547 - loss: 0.4118 - val_accuracy: 0.6904 - val_loss: 0.8816\n",
      "Epoch 421/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8542 - loss: 0.4077 - val_accuracy: 0.6660 - val_loss: 0.9080\n",
      "Epoch 422/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8448 - loss: 0.4102 - val_accuracy: 0.6782 - val_loss: 0.8633\n",
      "Epoch 423/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8495 - loss: 0.4327 - val_accuracy: 0.6864 - val_loss: 0.8657\n",
      "Epoch 424/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8576 - loss: 0.4151 - val_accuracy: 0.6904 - val_loss: 0.8625\n",
      "Epoch 425/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8537 - loss: 0.4173 - val_accuracy: 0.6721 - val_loss: 0.8920\n",
      "Epoch 426/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8673 - loss: 0.3918 - val_accuracy: 0.6762 - val_loss: 0.8757\n",
      "Epoch 427/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8628 - loss: 0.4147 - val_accuracy: 0.6843 - val_loss: 0.8763\n",
      "Epoch 428/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8667 - loss: 0.3994 - val_accuracy: 0.6965 - val_loss: 0.8857\n",
      "Epoch 429/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8548 - loss: 0.4083 - val_accuracy: 0.6701 - val_loss: 0.8946\n",
      "Epoch 430/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8623 - loss: 0.3817 - val_accuracy: 0.6782 - val_loss: 0.8705\n",
      "Epoch 431/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8536 - loss: 0.4186 - val_accuracy: 0.6802 - val_loss: 0.8863\n",
      "Epoch 432/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8710 - loss: 0.3619 - val_accuracy: 0.6864 - val_loss: 0.8840\n",
      "Epoch 433/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8556 - loss: 0.4080 - val_accuracy: 0.6802 - val_loss: 0.9026\n",
      "Epoch 434/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8730 - loss: 0.3794 - val_accuracy: 0.6721 - val_loss: 0.8727\n",
      "Epoch 435/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8595 - loss: 0.4057 - val_accuracy: 0.6660 - val_loss: 0.8837\n",
      "Epoch 436/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8710 - loss: 0.3913 - val_accuracy: 0.6884 - val_loss: 0.8875\n",
      "Epoch 437/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8616 - loss: 0.3828 - val_accuracy: 0.6680 - val_loss: 0.9066\n",
      "Epoch 438/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8701 - loss: 0.3691 - val_accuracy: 0.6802 - val_loss: 0.8714\n",
      "Epoch 439/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8545 - loss: 0.4065 - val_accuracy: 0.6864 - val_loss: 0.8744\n",
      "Epoch 440/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8702 - loss: 0.3872 - val_accuracy: 0.6904 - val_loss: 0.8823\n",
      "Epoch 441/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8791 - loss: 0.3670 - val_accuracy: 0.6864 - val_loss: 0.8778\n",
      "Epoch 442/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8743 - loss: 0.3769 - val_accuracy: 0.6762 - val_loss: 0.8998\n",
      "Epoch 443/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8807 - loss: 0.3733 - val_accuracy: 0.6823 - val_loss: 0.8681\n",
      "Epoch 444/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8571 - loss: 0.3957 - val_accuracy: 0.6782 - val_loss: 0.8747\n",
      "Epoch 445/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8698 - loss: 0.3893 - val_accuracy: 0.6660 - val_loss: 0.8862\n",
      "Epoch 446/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8566 - loss: 0.3887 - val_accuracy: 0.6782 - val_loss: 0.8863\n",
      "Epoch 447/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8621 - loss: 0.3881 - val_accuracy: 0.6843 - val_loss: 0.8765\n",
      "Epoch 448/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8685 - loss: 0.3924 - val_accuracy: 0.6864 - val_loss: 0.8798\n",
      "Epoch 449/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8725 - loss: 0.3790 - val_accuracy: 0.6721 - val_loss: 0.9100\n",
      "Epoch 450/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8654 - loss: 0.3819 - val_accuracy: 0.6741 - val_loss: 0.8851\n",
      "Epoch 451/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8554 - loss: 0.3966 - val_accuracy: 0.6741 - val_loss: 0.8803\n",
      "Epoch 452/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8698 - loss: 0.3848 - val_accuracy: 0.6884 - val_loss: 0.8710\n",
      "Epoch 453/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8609 - loss: 0.3849 - val_accuracy: 0.6864 - val_loss: 0.8797\n",
      "Epoch 454/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8675 - loss: 0.3691 - val_accuracy: 0.6782 - val_loss: 0.8695\n",
      "Epoch 455/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8796 - loss: 0.3688 - val_accuracy: 0.6843 - val_loss: 0.8574\n",
      "Epoch 456/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8787 - loss: 0.3721 - val_accuracy: 0.6762 - val_loss: 0.8705\n",
      "Epoch 457/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8691 - loss: 0.3652 - val_accuracy: 0.6762 - val_loss: 0.8666\n",
      "Epoch 458/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8844 - loss: 0.3564 - val_accuracy: 0.6986 - val_loss: 0.8652\n",
      "Epoch 459/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8606 - loss: 0.3819 - val_accuracy: 0.6904 - val_loss: 0.8634\n",
      "Epoch 460/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8595 - loss: 0.3768 - val_accuracy: 0.6884 - val_loss: 0.8871\n",
      "Epoch 461/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8535 - loss: 0.4000 - val_accuracy: 0.6782 - val_loss: 0.8718\n",
      "Epoch 462/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8653 - loss: 0.3814 - val_accuracy: 0.6823 - val_loss: 0.8892\n",
      "Epoch 463/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8658 - loss: 0.3791 - val_accuracy: 0.6925 - val_loss: 0.8645\n",
      "Epoch 464/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8802 - loss: 0.3422 - val_accuracy: 0.6904 - val_loss: 0.8604\n",
      "Epoch 465/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8696 - loss: 0.3769 - val_accuracy: 0.6925 - val_loss: 0.8606\n",
      "Epoch 466/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8623 - loss: 0.3872 - val_accuracy: 0.6680 - val_loss: 0.9086\n",
      "Epoch 467/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8651 - loss: 0.4009 - val_accuracy: 0.6925 - val_loss: 0.8600\n",
      "Epoch 468/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8805 - loss: 0.3595 - val_accuracy: 0.6904 - val_loss: 0.8514\n",
      "Epoch 469/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8766 - loss: 0.3642 - val_accuracy: 0.6904 - val_loss: 0.8659\n",
      "Epoch 470/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8730 - loss: 0.3644 - val_accuracy: 0.6904 - val_loss: 0.8649\n",
      "Epoch 471/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8721 - loss: 0.3792 - val_accuracy: 0.6965 - val_loss: 0.8910\n",
      "Epoch 472/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8695 - loss: 0.3689 - val_accuracy: 0.6904 - val_loss: 0.8983\n",
      "Epoch 473/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8696 - loss: 0.3696 - val_accuracy: 0.6884 - val_loss: 0.9144\n",
      "Epoch 474/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8761 - loss: 0.3626 - val_accuracy: 0.6965 - val_loss: 0.8671\n",
      "Epoch 475/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8814 - loss: 0.3594 - val_accuracy: 0.6986 - val_loss: 0.8826\n",
      "Epoch 476/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8770 - loss: 0.3684 - val_accuracy: 0.6864 - val_loss: 0.8649\n",
      "Epoch 477/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8770 - loss: 0.3717 - val_accuracy: 0.6965 - val_loss: 0.8530\n",
      "Epoch 478/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8770 - loss: 0.3720 - val_accuracy: 0.6843 - val_loss: 0.8917\n",
      "Epoch 479/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8693 - loss: 0.3800 - val_accuracy: 0.6925 - val_loss: 0.8710\n",
      "Epoch 480/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8685 - loss: 0.3767 - val_accuracy: 0.6762 - val_loss: 0.8842\n",
      "Epoch 481/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8773 - loss: 0.3536 - val_accuracy: 0.7088 - val_loss: 0.8656\n",
      "Epoch 482/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8737 - loss: 0.3535 - val_accuracy: 0.6945 - val_loss: 0.8718\n",
      "Epoch 483/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8839 - loss: 0.3533 - val_accuracy: 0.6925 - val_loss: 0.8631\n",
      "Epoch 484/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8731 - loss: 0.3811 - val_accuracy: 0.6884 - val_loss: 0.8568\n",
      "Epoch 485/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8756 - loss: 0.3466 - val_accuracy: 0.6823 - val_loss: 0.8871\n",
      "Epoch 486/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8859 - loss: 0.3386 - val_accuracy: 0.6660 - val_loss: 0.9080\n",
      "Epoch 487/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8691 - loss: 0.3641 - val_accuracy: 0.6782 - val_loss: 0.8837\n",
      "Epoch 488/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8709 - loss: 0.3644 - val_accuracy: 0.6823 - val_loss: 0.8864\n",
      "Epoch 489/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8757 - loss: 0.3651 - val_accuracy: 0.6864 - val_loss: 0.8759\n",
      "Epoch 490/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8688 - loss: 0.3631 - val_accuracy: 0.6925 - val_loss: 0.8652\n",
      "Epoch 491/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8674 - loss: 0.3555 - val_accuracy: 0.6884 - val_loss: 0.8775\n",
      "Epoch 492/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8787 - loss: 0.3486 - val_accuracy: 0.6843 - val_loss: 0.8653\n",
      "Epoch 493/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8735 - loss: 0.3568 - val_accuracy: 0.6660 - val_loss: 0.9036\n",
      "Epoch 494/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8683 - loss: 0.3777 - val_accuracy: 0.6823 - val_loss: 0.8786\n",
      "Epoch 495/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8666 - loss: 0.3759 - val_accuracy: 0.6701 - val_loss: 0.9026\n",
      "Epoch 496/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8766 - loss: 0.3572 - val_accuracy: 0.6782 - val_loss: 0.8889\n",
      "Epoch 497/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8863 - loss: 0.3367 - val_accuracy: 0.6762 - val_loss: 0.8882\n",
      "Epoch 498/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8655 - loss: 0.3581 - val_accuracy: 0.6884 - val_loss: 0.8625\n",
      "Epoch 499/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8760 - loss: 0.3485 - val_accuracy: 0.6843 - val_loss: 0.8821\n",
      "Epoch 500/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8844 - loss: 0.3433 - val_accuracy: 0.6802 - val_loss: 0.8810\n",
      "Epoch 501/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8781 - loss: 0.3595 - val_accuracy: 0.6843 - val_loss: 0.8785\n",
      "Epoch 502/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8812 - loss: 0.3407 - val_accuracy: 0.6802 - val_loss: 0.8783\n",
      "Epoch 503/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8863 - loss: 0.3409 - val_accuracy: 0.6823 - val_loss: 0.8652\n",
      "Epoch 504/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8853 - loss: 0.3324 - val_accuracy: 0.6965 - val_loss: 0.8762\n",
      "Epoch 505/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8807 - loss: 0.3563 - val_accuracy: 0.6843 - val_loss: 0.8660\n",
      "Epoch 506/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.3123 - val_accuracy: 0.6864 - val_loss: 0.9015\n",
      "Epoch 507/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8837 - loss: 0.3336 - val_accuracy: 0.6986 - val_loss: 0.8883\n",
      "Epoch 508/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8726 - loss: 0.3548 - val_accuracy: 0.6782 - val_loss: 0.8850\n",
      "Epoch 509/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8746 - loss: 0.3666 - val_accuracy: 0.6782 - val_loss: 0.8735\n",
      "Epoch 510/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8776 - loss: 0.3517 - val_accuracy: 0.6904 - val_loss: 0.8769\n",
      "Epoch 511/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8976 - loss: 0.3312 - val_accuracy: 0.6823 - val_loss: 0.8922\n",
      "Epoch 512/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8796 - loss: 0.3472 - val_accuracy: 0.6741 - val_loss: 0.8769\n",
      "Epoch 513/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8840 - loss: 0.3441 - val_accuracy: 0.6721 - val_loss: 0.9027\n",
      "Epoch 514/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8542 - loss: 0.3753 - val_accuracy: 0.6721 - val_loss: 0.8978\n",
      "Epoch 515/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8803 - loss: 0.3563 - val_accuracy: 0.6884 - val_loss: 0.8536\n",
      "Epoch 516/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8706 - loss: 0.3599 - val_accuracy: 0.6904 - val_loss: 0.8774\n",
      "Epoch 517/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8810 - loss: 0.3487 - val_accuracy: 0.6904 - val_loss: 0.8557\n",
      "Epoch 518/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8780 - loss: 0.3498 - val_accuracy: 0.6802 - val_loss: 0.8815\n",
      "Epoch 519/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9031 - loss: 0.3155 - val_accuracy: 0.6741 - val_loss: 0.8772\n",
      "Epoch 520/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8846 - loss: 0.3330 - val_accuracy: 0.7006 - val_loss: 0.8893\n",
      "Epoch 521/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9256 - loss: 0.2233 - val_accuracy: 0.7047 - val_loss: 0.9266\n",
      "Epoch 738/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9360 - loss: 0.2188 - val_accuracy: 0.7047 - val_loss: 0.8992\n",
      "Epoch 739/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9329 - loss: 0.2058 - val_accuracy: 0.7067 - val_loss: 0.9242\n",
      "Epoch 740/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9327 - loss: 0.1942 - val_accuracy: 0.7149 - val_loss: 0.8807\n",
      "Epoch 741/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9240 - loss: 0.2247 - val_accuracy: 0.6965 - val_loss: 0.9268\n",
      "Epoch 742/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9380 - loss: 0.1976 - val_accuracy: 0.6986 - val_loss: 0.9147\n",
      "Epoch 743/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9309 - loss: 0.2139 - val_accuracy: 0.7047 - val_loss: 0.9100\n",
      "Epoch 744/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9215 - loss: 0.2193 - val_accuracy: 0.7047 - val_loss: 0.9503\n",
      "Epoch 745/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9255 - loss: 0.2193 - val_accuracy: 0.7108 - val_loss: 0.8926\n",
      "Epoch 746/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9393 - loss: 0.2034 - val_accuracy: 0.7088 - val_loss: 0.8934\n",
      "Epoch 747/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9293 - loss: 0.2111 - val_accuracy: 0.6904 - val_loss: 0.9417\n",
      "Epoch 748/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9326 - loss: 0.2081 - val_accuracy: 0.7128 - val_loss: 0.8974\n",
      "Epoch 749/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9194 - loss: 0.2314 - val_accuracy: 0.7128 - val_loss: 0.8870\n",
      "Epoch 750/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9228 - loss: 0.2274 - val_accuracy: 0.6925 - val_loss: 0.9201\n",
      "Epoch 751/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9307 - loss: 0.2083 - val_accuracy: 0.7067 - val_loss: 0.9345\n",
      "Epoch 752/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9231 - loss: 0.2292 - val_accuracy: 0.7149 - val_loss: 0.8945\n",
      "Epoch 753/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9228 - loss: 0.2154 - val_accuracy: 0.7149 - val_loss: 0.9019\n",
      "Epoch 754/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.2050 - val_accuracy: 0.7047 - val_loss: 0.9270\n",
      "Epoch 755/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9370 - loss: 0.2055 - val_accuracy: 0.7230 - val_loss: 0.9262\n",
      "Epoch 756/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9245 - loss: 0.2295 - val_accuracy: 0.6965 - val_loss: 0.9468\n",
      "Epoch 757/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9257 - loss: 0.2246 - val_accuracy: 0.6945 - val_loss: 0.9445\n",
      "Epoch 758/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9322 - loss: 0.1936 - val_accuracy: 0.7108 - val_loss: 0.8969\n",
      "Epoch 759/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9239 - loss: 0.2315 - val_accuracy: 0.6904 - val_loss: 0.9348\n",
      "Epoch 760/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9398 - loss: 0.1915 - val_accuracy: 0.6925 - val_loss: 0.9551\n",
      "Epoch 761/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9208 - loss: 0.2207 - val_accuracy: 0.6945 - val_loss: 0.9408\n",
      "Epoch 762/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9283 - loss: 0.2149 - val_accuracy: 0.6965 - val_loss: 0.9133\n",
      "Epoch 763/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9333 - loss: 0.2126 - val_accuracy: 0.7067 - val_loss: 0.9357\n",
      "Epoch 764/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9217 - loss: 0.2349 - val_accuracy: 0.7067 - val_loss: 0.9214\n",
      "Epoch 765/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9285 - loss: 0.1929 - val_accuracy: 0.6884 - val_loss: 0.9271\n",
      "Epoch 766/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9344 - loss: 0.2051 - val_accuracy: 0.7026 - val_loss: 0.9038\n",
      "Epoch 767/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9344 - loss: 0.1889 - val_accuracy: 0.7067 - val_loss: 0.9045\n",
      "Epoch 768/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9372 - loss: 0.1922 - val_accuracy: 0.7128 - val_loss: 0.9127\n",
      "Epoch 769/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9319 - loss: 0.2084 - val_accuracy: 0.6884 - val_loss: 0.9379\n",
      "Epoch 770/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9273 - loss: 0.2175 - val_accuracy: 0.7026 - val_loss: 0.9172\n",
      "Epoch 771/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9251 - loss: 0.2156 - val_accuracy: 0.7128 - val_loss: 0.9391\n",
      "Epoch 772/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9395 - loss: 0.1938 - val_accuracy: 0.7088 - val_loss: 0.9135\n",
      "Epoch 773/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9478 - loss: 0.1794 - val_accuracy: 0.7006 - val_loss: 0.9439\n",
      "Epoch 774/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9372 - loss: 0.2130 - val_accuracy: 0.7006 - val_loss: 0.9427\n",
      "Epoch 775/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9442 - loss: 0.1850 - val_accuracy: 0.7026 - val_loss: 0.9446\n",
      "Epoch 776/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9426 - loss: 0.1946 - val_accuracy: 0.6945 - val_loss: 0.9859\n",
      "Epoch 777/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9181 - loss: 0.2355 - val_accuracy: 0.6884 - val_loss: 0.9157\n",
      "Epoch 778/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9428 - loss: 0.1845 - val_accuracy: 0.7047 - val_loss: 0.9190\n",
      "Epoch 779/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9392 - loss: 0.1915 - val_accuracy: 0.7026 - val_loss: 0.9410\n",
      "Epoch 780/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9356 - loss: 0.2063 - val_accuracy: 0.7108 - val_loss: 0.8892\n",
      "Epoch 781/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9294 - loss: 0.2174 - val_accuracy: 0.7006 - val_loss: 0.9464\n",
      "Epoch 782/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9373 - loss: 0.2021 - val_accuracy: 0.7169 - val_loss: 0.9234\n",
      "Epoch 783/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9479 - loss: 0.1868 - val_accuracy: 0.6945 - val_loss: 0.9543\n",
      "Epoch 784/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9272 - loss: 0.2075 - val_accuracy: 0.7026 - val_loss: 0.9793\n",
      "Epoch 785/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9513 - loss: 0.1874 - val_accuracy: 0.7047 - val_loss: 0.8985\n",
      "Epoch 786/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9318 - loss: 0.2035 - val_accuracy: 0.7026 - val_loss: 0.9311\n",
      "Epoch 787/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9455 - loss: 0.1885 - val_accuracy: 0.7026 - val_loss: 0.9455\n",
      "Epoch 788/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9356 - loss: 0.1985 - val_accuracy: 0.6925 - val_loss: 0.9214\n",
      "Epoch 789/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9273 - loss: 0.2024 - val_accuracy: 0.6965 - val_loss: 0.9245\n",
      "Epoch 790/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9418 - loss: 0.1880 - val_accuracy: 0.7128 - val_loss: 0.9369\n",
      "Epoch 791/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9416 - loss: 0.1901 - val_accuracy: 0.7026 - val_loss: 0.9178\n",
      "Epoch 792/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9353 - loss: 0.1982 - val_accuracy: 0.7047 - val_loss: 0.9147\n",
      "Epoch 793/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9355 - loss: 0.1907 - val_accuracy: 0.7026 - val_loss: 0.9327\n",
      "Epoch 794/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9463 - loss: 0.1799 - val_accuracy: 0.7067 - val_loss: 0.9212\n",
      "Epoch 795/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9541 - loss: 0.1690 - val_accuracy: 0.7067 - val_loss: 0.9136\n",
      "Epoch 796/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9467 - loss: 0.1729 - val_accuracy: 0.7006 - val_loss: 0.9297\n",
      "Epoch 797/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9266 - loss: 0.2183 - val_accuracy: 0.7047 - val_loss: 0.9356\n",
      "Epoch 798/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9359 - loss: 0.1986 - val_accuracy: 0.7047 - val_loss: 0.9344\n",
      "Epoch 799/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.2058 - val_accuracy: 0.6823 - val_loss: 0.9435\n",
      "Epoch 800/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9525 - loss: 0.1549 - val_accuracy: 0.7108 - val_loss: 0.9626\n",
      "Epoch 873/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9468 - loss: 0.1639 - val_accuracy: 0.7210 - val_loss: 0.9574\n",
      "Epoch 874/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9322 - loss: 0.1849 - val_accuracy: 0.7128 - val_loss: 0.9547\n",
      "Epoch 875/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9510 - loss: 0.1494 - val_accuracy: 0.7088 - val_loss: 0.9505\n",
      "Epoch 876/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9311 - loss: 0.1897 - val_accuracy: 0.7108 - val_loss: 0.9279\n",
      "Epoch 877/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9424 - loss: 0.1784 - val_accuracy: 0.7169 - val_loss: 0.9359\n",
      "Epoch 878/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9540 - loss: 0.1546 - val_accuracy: 0.6965 - val_loss: 0.9499\n",
      "Epoch 879/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9390 - loss: 0.1641 - val_accuracy: 0.7067 - val_loss: 0.9410\n",
      "Epoch 880/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9395 - loss: 0.1857 - val_accuracy: 0.7067 - val_loss: 0.9291\n",
      "Epoch 881/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9511 - loss: 0.1614 - val_accuracy: 0.7026 - val_loss: 0.9394\n",
      "Epoch 882/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9474 - loss: 0.1797 - val_accuracy: 0.7210 - val_loss: 0.9132\n",
      "Epoch 883/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9561 - loss: 0.1560 - val_accuracy: 0.7128 - val_loss: 0.9368\n",
      "Epoch 884/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9463 - loss: 0.1616 - val_accuracy: 0.7189 - val_loss: 0.9355\n",
      "Epoch 885/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9573 - loss: 0.1691 - val_accuracy: 0.7230 - val_loss: 0.9620\n",
      "Epoch 886/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9401 - loss: 0.1705 - val_accuracy: 0.7026 - val_loss: 0.9608\n",
      "Epoch 887/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9482 - loss: 0.1588 - val_accuracy: 0.7189 - val_loss: 0.9356\n",
      "Epoch 888/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9441 - loss: 0.1765 - val_accuracy: 0.7210 - val_loss: 0.9343\n",
      "Epoch 889/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9412 - loss: 0.1698 - val_accuracy: 0.7128 - val_loss: 0.9878\n",
      "Epoch 890/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9466 - loss: 0.1668 - val_accuracy: 0.7169 - val_loss: 0.9520\n",
      "Epoch 891/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9425 - loss: 0.1655 - val_accuracy: 0.7128 - val_loss: 0.9662\n",
      "Epoch 892/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9557 - loss: 0.1531 - val_accuracy: 0.6904 - val_loss: 0.9839\n",
      "Epoch 893/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9499 - loss: 0.1604 - val_accuracy: 0.7067 - val_loss: 0.9484\n",
      "Epoch 894/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9463 - loss: 0.1684 - val_accuracy: 0.7067 - val_loss: 0.9526\n",
      "Epoch 895/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9420 - loss: 0.1807 - val_accuracy: 0.7108 - val_loss: 0.9550\n",
      "Epoch 896/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9517 - loss: 0.1605 - val_accuracy: 0.7088 - val_loss: 0.9582\n",
      "Epoch 897/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9470 - loss: 0.1530 - val_accuracy: 0.7108 - val_loss: 0.9894\n",
      "Epoch 898/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9566 - loss: 0.1575 - val_accuracy: 0.7047 - val_loss: 0.9879\n",
      "Epoch 899/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9547 - loss: 0.1519 - val_accuracy: 0.7108 - val_loss: 0.9468\n",
      "Epoch 900/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9504 - loss: 0.1541 - val_accuracy: 0.6945 - val_loss: 1.0020\n",
      "Epoch 901/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9516 - loss: 0.1622 - val_accuracy: 0.6945 - val_loss: 0.9692\n",
      "Epoch 902/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9576 - loss: 0.1329 - val_accuracy: 0.6965 - val_loss: 1.0204\n",
      "Epoch 903/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9573 - loss: 0.1455 - val_accuracy: 0.7189 - val_loss: 0.9396\n",
      "Epoch 904/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9441 - loss: 0.1645 - val_accuracy: 0.7006 - val_loss: 0.9640\n",
      "Epoch 905/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9515 - loss: 0.1484 - val_accuracy: 0.7210 - val_loss: 0.9421\n",
      "Epoch 906/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9518 - loss: 0.1526 - val_accuracy: 0.7189 - val_loss: 0.9442\n",
      "Epoch 907/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9627 - loss: 0.1315 - val_accuracy: 0.7128 - val_loss: 0.9305\n",
      "Epoch 908/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9453 - loss: 0.1580 - val_accuracy: 0.6945 - val_loss: 0.9524\n",
      "Epoch 909/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9640 - loss: 0.1430 - val_accuracy: 0.7149 - val_loss: 0.9203\n",
      "Epoch 910/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9578 - loss: 0.1537 - val_accuracy: 0.7047 - val_loss: 0.9510\n",
      "Epoch 911/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9374 - loss: 0.1669 - val_accuracy: 0.7210 - val_loss: 0.9195\n",
      "Epoch 912/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9529 - loss: 0.1602 - val_accuracy: 0.6965 - val_loss: 0.9989\n",
      "Epoch 913/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9492 - loss: 0.1628 - val_accuracy: 0.7108 - val_loss: 0.9634\n",
      "Epoch 914/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9592 - loss: 0.1449 - val_accuracy: 0.7189 - val_loss: 0.9498\n",
      "Epoch 915/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9468 - loss: 0.1570 - val_accuracy: 0.7149 - val_loss: 0.9480\n",
      "Epoch 916/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9544 - loss: 0.1475 - val_accuracy: 0.7128 - val_loss: 0.9439\n",
      "Epoch 917/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9362 - loss: 0.1755 - val_accuracy: 0.7128 - val_loss: 0.9472\n",
      "Epoch 918/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9575 - loss: 0.1462 - val_accuracy: 0.7128 - val_loss: 0.9571\n",
      "Epoch 919/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9526 - loss: 0.1612 - val_accuracy: 0.7189 - val_loss: 0.9714\n",
      "Epoch 920/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9482 - loss: 0.1536 - val_accuracy: 0.7149 - val_loss: 0.9596\n",
      "Epoch 921/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9458 - loss: 0.1621 - val_accuracy: 0.7169 - val_loss: 0.9436\n",
      "Epoch 922/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9529 - loss: 0.1494 - val_accuracy: 0.7088 - val_loss: 0.9760\n",
      "Epoch 923/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9497 - loss: 0.1490 - val_accuracy: 0.7067 - val_loss: 0.9469\n",
      "Epoch 924/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9463 - loss: 0.1652 - val_accuracy: 0.7108 - val_loss: 0.9624\n",
      "Epoch 925/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9563 - loss: 0.1398 - val_accuracy: 0.7006 - val_loss: 0.9698\n",
      "Epoch 926/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9621 - loss: 0.1492 - val_accuracy: 0.7108 - val_loss: 0.9525\n",
      "Epoch 927/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9490 - loss: 0.1661 - val_accuracy: 0.7128 - val_loss: 0.9573\n",
      "Epoch 928/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9401 - loss: 0.1649 - val_accuracy: 0.7067 - val_loss: 0.9426\n",
      "Epoch 929/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9434 - loss: 0.1549 - val_accuracy: 0.7067 - val_loss: 0.9584\n",
      "Epoch 930/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9456 - loss: 0.1619 - val_accuracy: 0.6945 - val_loss: 0.9915\n",
      "Epoch 931/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9571 - loss: 0.1372 - val_accuracy: 0.7189 - val_loss: 0.9401\n",
      "Epoch 932/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9561 - loss: 0.1532 - val_accuracy: 0.7047 - val_loss: 0.9977\n",
      "Epoch 933/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9443 - loss: 0.1735 - val_accuracy: 0.7149 - val_loss: 0.9496\n",
      "Epoch 934/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9433 - loss: 0.1507 - val_accuracy: 0.7189 - val_loss: 0.9574\n",
      "Epoch 935/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9556 - loss: 0.1603 - val_accuracy: 0.7047 - val_loss: 0.9940\n",
      "Epoch 936/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9473 - loss: 0.1590 - val_accuracy: 0.7108 - val_loss: 0.9725\n",
      "Epoch 937/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9449 - loss: 0.1738 - val_accuracy: 0.7291 - val_loss: 0.9503\n",
      "Epoch 938/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9488 - loss: 0.1509 - val_accuracy: 0.7108 - val_loss: 0.9463\n",
      "Epoch 939/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9566 - loss: 0.1500 - val_accuracy: 0.6986 - val_loss: 0.9565\n",
      "Epoch 940/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9593 - loss: 0.1306 - val_accuracy: 0.7169 - val_loss: 0.9596\n",
      "Epoch 941/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9412 - loss: 0.1561 - val_accuracy: 0.7169 - val_loss: 0.9619\n",
      "Epoch 942/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9549 - loss: 0.1463 - val_accuracy: 0.7088 - val_loss: 0.9406\n",
      "Epoch 943/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9604 - loss: 0.1366 - val_accuracy: 0.7088 - val_loss: 0.9841\n",
      "Epoch 944/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9453 - loss: 0.1762 - val_accuracy: 0.7128 - val_loss: 0.9281\n",
      "Epoch 945/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9597 - loss: 0.1431 - val_accuracy: 0.7047 - val_loss: 0.9481\n",
      "Epoch 946/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9512 - loss: 0.1515 - val_accuracy: 0.7067 - val_loss: 0.9660\n",
      "Epoch 947/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9566 - loss: 0.1365 - val_accuracy: 0.7108 - val_loss: 0.9877\n",
      "Epoch 948/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9477 - loss: 0.1491 - val_accuracy: 0.7210 - val_loss: 0.9410\n",
      "Epoch 949/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9566 - loss: 0.1340 - val_accuracy: 0.7088 - val_loss: 0.9720\n",
      "Epoch 950/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9536 - loss: 0.1459 - val_accuracy: 0.7047 - val_loss: 0.9750\n",
      "Epoch 951/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9556 - loss: 0.1415 - val_accuracy: 0.7271 - val_loss: 0.9573\n",
      "Epoch 952/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9548 - loss: 0.1442 - val_accuracy: 0.6965 - val_loss: 1.0307\n",
      "Epoch 953/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9429 - loss: 0.1572 - val_accuracy: 0.7251 - val_loss: 0.9267\n",
      "Epoch 954/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9535 - loss: 0.1514 - val_accuracy: 0.7189 - val_loss: 0.9709\n",
      "Epoch 955/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9655 - loss: 0.1236 - val_accuracy: 0.6945 - val_loss: 0.9866\n",
      "Epoch 956/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9617 - loss: 0.1288 - val_accuracy: 0.7189 - val_loss: 0.9473\n",
      "Epoch 957/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9525 - loss: 0.1530 - val_accuracy: 0.7189 - val_loss: 0.9690\n",
      "Epoch 958/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9494 - loss: 0.1470 - val_accuracy: 0.6965 - val_loss: 1.0093\n",
      "Epoch 959/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9558 - loss: 0.1406 - val_accuracy: 0.7067 - val_loss: 0.9706\n",
      "Epoch 960/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9596 - loss: 0.1370 - val_accuracy: 0.7128 - val_loss: 0.9665\n",
      "Epoch 961/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9501 - loss: 0.1556 - val_accuracy: 0.7088 - val_loss: 0.9596\n",
      "Epoch 962/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9483 - loss: 0.1523 - val_accuracy: 0.7169 - val_loss: 0.9553\n",
      "Epoch 963/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9578 - loss: 0.1450 - val_accuracy: 0.7149 - val_loss: 0.9639\n",
      "Epoch 964/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9547 - loss: 0.1403 - val_accuracy: 0.7128 - val_loss: 0.9824\n",
      "Epoch 965/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9522 - loss: 0.1467 - val_accuracy: 0.7149 - val_loss: 1.0014\n",
      "Epoch 966/1000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9563 - loss: 0.1470 - val_accuracy: 0.7149 - val_loss: 0.9693\n",
      "Epoch 967/1000\n",
      "\u001b[1m35/62\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9583 - loss: 0.1255"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_reshaped, y_train_cat,\n",
    "                    batch_size=32,\n",
    "                    epochs=1000,\n",
    "                    validation_data=(x_test_reshaped, y_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8781f7e5-660b-4153-a07d-28d14a2fa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 0.9546149969100952\n",
      "Final Validation Accuracy: 0.7148675918579102\n"
     ]
    }
   ],
   "source": [
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "print(\"Final Training Accuracy:\", final_train_acc)\n",
    "print(\"Final Validation Accuracy:\", final_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96da7f10-ab18-488f-bae1-e0b38bfb6f50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnnhistory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.plot(\u001b[43mcnnhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m plt.plot(cnnhistory.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mmodel loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cnnhistory' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c82c8-ae9a-45a5-8a80-8e9658690a34",
   "metadata": {},
   "source": [
    "## another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00175c44-e92a-4b4b-a1a0-6e5fbd041c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow\n",
    "import resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ad6a5d-710f-418c-9e98-fb7722c8f960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8d85c6-e874-417f-a7e7-211e06637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6b96ea-7098-4b27-b87f-c40025cb3a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'voice-gender-classifier'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/JaesungHuh/voice-gender-classifier.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915b1e48-bf18-4522-b571-ccae657ab3d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Downloads\\emotion_det\\voice-gender-classifier\n",
      "Requirement already satisfied: torch in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from -r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from -r requirements.txt (line 2)) (2.7.1)\n",
      "Requirement already satisfied: pysoundfile in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from -r requirements.txt (line 3)) (0.9.0.post1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from -r requirements.txt (line 4)) (0.33.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from -r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.5.1)\n",
      "Requirement already satisfied: cffi>=0.6 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from pysoundfile->-r requirements.txt (line 3)) (1.17.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from cffi>=0.6->pysoundfile->-r requirements.txt (line 3)) (2.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests->huggingface_hub->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests->huggingface_hub->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests->huggingface_hub->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\downloads\\emotion_det\\emotion\\lib\\site-packages (from requests->huggingface_hub->-r requirements.txt (line 4)) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%cd voice-gender-classifier\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea273cbf-c32a-485d-8353-0eef39defa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from model import ECAPA_gender\n",
    "\n",
    "# You could directly download the model from the huggingface model hub\n",
    "model = ECAPA_gender.from_pretrained(\"JaesungHuh/voice-gender-classifier\")\n",
    "model.eval()\n",
    "\n",
    "# If you are using gpu ....\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the audio file and use predict function to directly get the output\n",
    "def get_gender(example_file):\n",
    "    with torch.no_grad():\n",
    "        output = model.predict(example_file, device=device)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b570f76a-b6fd-4dcb-bdc4-17ac8d22af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def featureExtraction(path):\n",
    "    X, sample_rate = librosa.load(path)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T, axis=0)\n",
    "    # Concatenate all features into a single vector\n",
    "    return np.hstack([mfccs, chroma, mel, contrast, tonnetz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2483a9-b077-48ea-8476-d5bc9163a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "observed_emotions = list(emotions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de9e732-286b-4b63-a281-f67495feb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(x_fem, y_fem, x_male, y_male):\n",
    "    for file in glob.glob('C:/Users/Dell/Downloads/emotion_det/common/*.wav'):\n",
    "        file_name = os.path.basename(file)\n",
    "        parts = file_name.split(\"-\")\n",
    "\n",
    "        # Ensure valid filename format\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "\n",
    "        emotion_code = parts[2]\n",
    "        emotion = emotions.get(emotion_code)\n",
    "\n",
    "        # Skip if emotion not recognized\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "\n",
    "        # Extract features\n",
    "        feature = featureExtraction(file)\n",
    "\n",
    "        # Get gender and append to correct list\n",
    "        gender = get_gender(file)\n",
    "        if gender == 'female':\n",
    "            x_fem.append(feature)\n",
    "            y_fem.append(emotion)\n",
    "        elif gender == 'male':\n",
    "            x_male.append(feature)\n",
    "            y_male.append(emotion)\n",
    "\n",
    "    return x_fem, y_fem, x_male, y_male\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991c4405-2061-4ac8-b3ac-cd1071a87a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Downloads\\emotion_det\\emotion\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1012\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "x_fem, y_fem, x_male, y_male = [], [], [], []\n",
    "x_fem, y_fem, x_male, y_male = load_data(x_fem, y_fem, x_male, y_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ffb7d-3e13-4846-83c8-95c0b309a577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb2a364-13bc-4d72-9970-d1602e1ea202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow GPU Devices: []\n",
      "Torch CUDA Available: False\n",
      "Torch is using CPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# TensorFlow GPU check\n",
    "print(\"TensorFlow GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Safe PyTorch GPU info\n",
    "print(\"Torch CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "    print(\"Torch GPU Device:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"Torch is using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e4d24b-3a78-4507-b2b7-812b64bcb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42ccd256-4bb4-47ff-ae7e-17163b09c460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion distribution:\n",
      "happy        0.156046\n",
      "calm         0.155229\n",
      "fearful      0.153595\n",
      "sad          0.151144\n",
      "angry        0.150327\n",
      "disgust      0.079248\n",
      "surprised    0.078431\n",
      "neutral      0.075980\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Downloads\\emotion_det\\emotion\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">99,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │          \u001b[38;5;34m99,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │           \u001b[38;5;34m1,032\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,168</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m268,168\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,376</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,376\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.1331 - loss: 2.8082 - val_accuracy: 0.1707 - val_loss: 2.0406 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1653 - loss: 2.7685 - val_accuracy: 0.2358 - val_loss: 1.9606 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1974 - loss: 2.5658 - val_accuracy: 0.2520 - val_loss: 1.8977 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2056 - loss: 2.4864 - val_accuracy: 0.2846 - val_loss: 1.8458 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2384 - loss: 2.3344 - val_accuracy: 0.3171 - val_loss: 1.8002 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2664 - loss: 2.2477 - val_accuracy: 0.3821 - val_loss: 1.7483 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2676 - loss: 2.1947 - val_accuracy: 0.4228 - val_loss: 1.6986 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2726 - loss: 2.1008 - val_accuracy: 0.4309 - val_loss: 1.6516 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2918 - loss: 2.0966 - val_accuracy: 0.4553 - val_loss: 1.6037 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3071 - loss: 1.9836 - val_accuracy: 0.5041 - val_loss: 1.5582 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3572 - loss: 1.9055 - val_accuracy: 0.5285 - val_loss: 1.5106 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3485 - loss: 1.8585 - val_accuracy: 0.5285 - val_loss: 1.4761 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.3542 - loss: 1.9114 - val_accuracy: 0.5366 - val_loss: 1.4428 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3473 - loss: 1.9111 - val_accuracy: 0.5366 - val_loss: 1.4110 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.3720 - loss: 1.8074 - val_accuracy: 0.5447 - val_loss: 1.3815 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.3748 - loss: 1.8458 - val_accuracy: 0.5528 - val_loss: 1.3539 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.3969 - loss: 1.7200 - val_accuracy: 0.5528 - val_loss: 1.3225 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4205 - loss: 1.6689 - val_accuracy: 0.5610 - val_loss: 1.3008 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.4152 - loss: 1.6503 - val_accuracy: 0.5610 - val_loss: 1.2830 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.3788 - loss: 1.7348 - val_accuracy: 0.5772 - val_loss: 1.2617 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3917 - loss: 1.6894 - val_accuracy: 0.5854 - val_loss: 1.2362 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.4280 - loss: 1.5942 - val_accuracy: 0.5854 - val_loss: 1.2119 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.4232 - loss: 1.6332 - val_accuracy: 0.5935 - val_loss: 1.1916 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.4361 - loss: 1.5783 - val_accuracy: 0.6098 - val_loss: 1.1778 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.4686 - loss: 1.4995 - val_accuracy: 0.6179 - val_loss: 1.1617 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.4519 - loss: 1.5485 - val_accuracy: 0.6016 - val_loss: 1.1468 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.4612 - loss: 1.5047 - val_accuracy: 0.6016 - val_loss: 1.1339 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4570 - loss: 1.5279 - val_accuracy: 0.6098 - val_loss: 1.1196 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.4668 - loss: 1.4763 - val_accuracy: 0.6179 - val_loss: 1.1073 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4887 - loss: 1.4738 - val_accuracy: 0.6341 - val_loss: 1.0974 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.4715 - loss: 1.5258 - val_accuracy: 0.6260 - val_loss: 1.0892 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.4683 - loss: 1.4619 - val_accuracy: 0.6260 - val_loss: 1.0771 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.4661 - loss: 1.5070 - val_accuracy: 0.6341 - val_loss: 1.0705 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.4791 - loss: 1.4602 - val_accuracy: 0.6179 - val_loss: 1.0658 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5051 - loss: 1.4289 - val_accuracy: 0.6016 - val_loss: 1.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.4993 - loss: 1.3783 - val_accuracy: 0.6098 - val_loss: 1.0496 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.4987 - loss: 1.3669 - val_accuracy: 0.6098 - val_loss: 1.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.5116 - loss: 1.3586 - val_accuracy: 0.6179 - val_loss: 1.0351 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5247 - loss: 1.3332 - val_accuracy: 0.6098 - val_loss: 1.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5249 - loss: 1.3225 - val_accuracy: 0.6098 - val_loss: 1.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5223 - loss: 1.3007 - val_accuracy: 0.6098 - val_loss: 1.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5301 - loss: 1.2939 - val_accuracy: 0.6098 - val_loss: 1.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5418 - loss: 1.2011 - val_accuracy: 0.6504 - val_loss: 0.9942 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5637 - loss: 1.2555 - val_accuracy: 0.6423 - val_loss: 0.9872 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5519 - loss: 1.2370 - val_accuracy: 0.6504 - val_loss: 0.9798 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5481 - loss: 1.2743 - val_accuracy: 0.6423 - val_loss: 0.9715 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5464 - loss: 1.2608 - val_accuracy: 0.6260 - val_loss: 0.9620 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5556 - loss: 1.2002 - val_accuracy: 0.6260 - val_loss: 0.9538 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5656 - loss: 1.2252 - val_accuracy: 0.6260 - val_loss: 0.9479 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5780 - loss: 1.1748 - val_accuracy: 0.6341 - val_loss: 0.9400 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.5531 - loss: 1.1559 - val_accuracy: 0.6423 - val_loss: 0.9366 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5641 - loss: 1.2493 - val_accuracy: 0.6667 - val_loss: 0.9352 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5706 - loss: 1.2065 - val_accuracy: 0.6667 - val_loss: 0.9304 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5869 - loss: 1.1307 - val_accuracy: 0.6748 - val_loss: 0.9260 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5837 - loss: 1.1784 - val_accuracy: 0.6585 - val_loss: 0.9178 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5728 - loss: 1.1393 - val_accuracy: 0.6667 - val_loss: 0.9110 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5955 - loss: 1.1016 - val_accuracy: 0.6585 - val_loss: 0.9033 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5934 - loss: 1.1246 - val_accuracy: 0.6667 - val_loss: 0.8990 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5967 - loss: 1.1542 - val_accuracy: 0.6504 - val_loss: 0.8991 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5738 - loss: 1.1453 - val_accuracy: 0.6504 - val_loss: 0.8982 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6031 - loss: 1.0637 - val_accuracy: 0.6504 - val_loss: 0.8922 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6033 - loss: 1.0963 - val_accuracy: 0.6504 - val_loss: 0.8886 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.6108 - loss: 1.0601 - val_accuracy: 0.6748 - val_loss: 0.8825 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5879 - loss: 1.0989 - val_accuracy: 0.6829 - val_loss: 0.8803 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6219 - loss: 1.0626 - val_accuracy: 0.6748 - val_loss: 0.8757 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5940 - loss: 1.1161 - val_accuracy: 0.6829 - val_loss: 0.8704 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6299 - loss: 1.0121 - val_accuracy: 0.6829 - val_loss: 0.8651 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5836 - loss: 1.1146 - val_accuracy: 0.6829 - val_loss: 0.8581 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6115 - loss: 1.0549 - val_accuracy: 0.6748 - val_loss: 0.8530 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6035 - loss: 1.1092 - val_accuracy: 0.6911 - val_loss: 0.8469 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6298 - loss: 1.0594 - val_accuracy: 0.6992 - val_loss: 0.8429 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6124 - loss: 1.0474 - val_accuracy: 0.6992 - val_loss: 0.8422 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6154 - loss: 1.0178 - val_accuracy: 0.6911 - val_loss: 0.8376 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6061 - loss: 1.0866 - val_accuracy: 0.6911 - val_loss: 0.8343 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6233 - loss: 1.0274 - val_accuracy: 0.6911 - val_loss: 0.8291 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6443 - loss: 1.0150 - val_accuracy: 0.6911 - val_loss: 0.8251 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6190 - loss: 1.0242 - val_accuracy: 0.6911 - val_loss: 0.8184 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6167 - loss: 1.0374 - val_accuracy: 0.6911 - val_loss: 0.8177 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.6259 - loss: 1.0048 - val_accuracy: 0.7073 - val_loss: 0.8146 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6407 - loss: 0.9456 - val_accuracy: 0.7073 - val_loss: 0.8100 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6740 - loss: 0.8871 - val_accuracy: 0.6992 - val_loss: 0.8100 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6264 - loss: 0.9908 - val_accuracy: 0.6992 - val_loss: 0.8028 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6453 - loss: 0.9599 - val_accuracy: 0.7154 - val_loss: 0.7976 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6625 - loss: 0.9156 - val_accuracy: 0.7236 - val_loss: 0.7980 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6342 - loss: 0.9530 - val_accuracy: 0.7154 - val_loss: 0.7944 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6587 - loss: 0.9475 - val_accuracy: 0.7398 - val_loss: 0.7931 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6632 - loss: 0.9669 - val_accuracy: 0.7480 - val_loss: 0.7912 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6676 - loss: 0.9329 - val_accuracy: 0.7317 - val_loss: 0.7910 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6614 - loss: 0.8797 - val_accuracy: 0.7236 - val_loss: 0.7841 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6683 - loss: 0.8870 - val_accuracy: 0.7236 - val_loss: 0.7787 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6483 - loss: 0.9721 - val_accuracy: 0.7317 - val_loss: 0.7724 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6771 - loss: 0.8886 - val_accuracy: 0.7236 - val_loss: 0.7702 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6611 - loss: 0.8967 - val_accuracy: 0.7236 - val_loss: 0.7716 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7015 - loss: 0.8213 - val_accuracy: 0.7398 - val_loss: 0.7697 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6754 - loss: 0.8510 - val_accuracy: 0.7317 - val_loss: 0.7652 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6705 - loss: 0.9293 - val_accuracy: 0.7480 - val_loss: 0.7648 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6826 - loss: 0.9064 - val_accuracy: 0.7561 - val_loss: 0.7644 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6544 - loss: 0.8756 - val_accuracy: 0.7642 - val_loss: 0.7642 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7031 - loss: 0.8399 - val_accuracy: 0.7480 - val_loss: 0.7584 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6731 - loss: 0.8904 - val_accuracy: 0.7561 - val_loss: 0.7532 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6805 - loss: 0.8892 - val_accuracy: 0.7642 - val_loss: 0.7477 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6888 - loss: 0.8306 - val_accuracy: 0.7724 - val_loss: 0.7415 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6721 - loss: 0.8934 - val_accuracy: 0.7642 - val_loss: 0.7320 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7178 - loss: 0.8162 - val_accuracy: 0.7561 - val_loss: 0.7251 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6966 - loss: 0.8542 - val_accuracy: 0.7724 - val_loss: 0.7219 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6980 - loss: 0.8367 - val_accuracy: 0.7642 - val_loss: 0.7192 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7192 - loss: 0.7883 - val_accuracy: 0.7642 - val_loss: 0.7157 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7129 - loss: 0.8171 - val_accuracy: 0.7642 - val_loss: 0.7143 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7143 - loss: 0.8029 - val_accuracy: 0.7724 - val_loss: 0.7147 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6828 - loss: 0.8629 - val_accuracy: 0.7724 - val_loss: 0.7079 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7063 - loss: 0.8164 - val_accuracy: 0.7724 - val_loss: 0.7060 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6938 - loss: 0.8169 - val_accuracy: 0.7642 - val_loss: 0.7048 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7225 - loss: 0.7704 - val_accuracy: 0.7724 - val_loss: 0.7002 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7026 - loss: 0.8117 - val_accuracy: 0.7642 - val_loss: 0.6935 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7149 - loss: 0.7714 - val_accuracy: 0.7724 - val_loss: 0.6910 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7097 - loss: 0.8146 - val_accuracy: 0.7642 - val_loss: 0.6875 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7129 - loss: 0.8018 - val_accuracy: 0.7724 - val_loss: 0.6852 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7094 - loss: 0.7749 - val_accuracy: 0.7642 - val_loss: 0.6861 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7402 - loss: 0.7518 - val_accuracy: 0.7805 - val_loss: 0.6840 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7062 - loss: 0.7787 - val_accuracy: 0.7805 - val_loss: 0.6811 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7160 - loss: 0.7905 - val_accuracy: 0.7805 - val_loss: 0.6748 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7308 - loss: 0.7022 - val_accuracy: 0.8049 - val_loss: 0.6700 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7242 - loss: 0.7465 - val_accuracy: 0.7886 - val_loss: 0.6711 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7341 - loss: 0.7103 - val_accuracy: 0.7805 - val_loss: 0.6675 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7167 - loss: 0.7204 - val_accuracy: 0.7967 - val_loss: 0.6717 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7452 - loss: 0.7158 - val_accuracy: 0.7886 - val_loss: 0.6676 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7475 - loss: 0.7384 - val_accuracy: 0.7967 - val_loss: 0.6654 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7512 - loss: 0.7143 - val_accuracy: 0.7886 - val_loss: 0.6637 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7583 - loss: 0.6792 - val_accuracy: 0.7805 - val_loss: 0.6620 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7399 - loss: 0.6719 - val_accuracy: 0.7967 - val_loss: 0.6605 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7418 - loss: 0.7131 - val_accuracy: 0.7967 - val_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7279 - loss: 0.7061 - val_accuracy: 0.7886 - val_loss: 0.6581 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7322 - loss: 0.7226 - val_accuracy: 0.7805 - val_loss: 0.6566 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7527 - loss: 0.6455 - val_accuracy: 0.7724 - val_loss: 0.6576 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7632 - loss: 0.6459 - val_accuracy: 0.7724 - val_loss: 0.6558 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7566 - loss: 0.7056 - val_accuracy: 0.7886 - val_loss: 0.6477 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7634 - loss: 0.6862 - val_accuracy: 0.7805 - val_loss: 0.6527 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7626 - loss: 0.6792 - val_accuracy: 0.7805 - val_loss: 0.6616 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7656 - loss: 0.6651 - val_accuracy: 0.7561 - val_loss: 0.6648 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7562 - loss: 0.6955 - val_accuracy: 0.7724 - val_loss: 0.6576 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7484 - loss: 0.6830 - val_accuracy: 0.7642 - val_loss: 0.6513 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7448 - loss: 0.6827 - val_accuracy: 0.7724 - val_loss: 0.6473 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7498 - loss: 0.6714 - val_accuracy: 0.7724 - val_loss: 0.6476 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7575 - loss: 0.6757 - val_accuracy: 0.7805 - val_loss: 0.6451 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7468 - loss: 0.6877 - val_accuracy: 0.7724 - val_loss: 0.6424 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7504 - loss: 0.6987 - val_accuracy: 0.7805 - val_loss: 0.6396 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7614 - loss: 0.6829 - val_accuracy: 0.7724 - val_loss: 0.6378 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7753 - loss: 0.6149 - val_accuracy: 0.7886 - val_loss: 0.6358 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.7821 - loss: 0.6067 - val_accuracy: 0.7805 - val_loss: 0.6379 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7673 - loss: 0.6449 - val_accuracy: 0.7724 - val_loss: 0.6387 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7395 - loss: 0.6806 - val_accuracy: 0.7724 - val_loss: 0.6392 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7727 - loss: 0.6165 - val_accuracy: 0.7724 - val_loss: 0.6394 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7804 - loss: 0.6391 - val_accuracy: 0.7886 - val_loss: 0.6391 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7675 - loss: 0.6458 - val_accuracy: 0.7805 - val_loss: 0.6363 - learning_rate: 2.5000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7554 - loss: 0.6548 - val_accuracy: 0.7886 - val_loss: 0.6333 - learning_rate: 2.5000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7531 - loss: 0.6685 - val_accuracy: 0.7886 - val_loss: 0.6322 - learning_rate: 2.5000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7738 - loss: 0.6147 - val_accuracy: 0.7967 - val_loss: 0.6305 - learning_rate: 2.5000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7556 - loss: 0.6624 - val_accuracy: 0.7967 - val_loss: 0.6308 - learning_rate: 2.5000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7756 - loss: 0.6374 - val_accuracy: 0.7967 - val_loss: 0.6304 - learning_rate: 2.5000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7821 - loss: 0.6036 - val_accuracy: 0.7967 - val_loss: 0.6301 - learning_rate: 2.5000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7639 - loss: 0.6438 - val_accuracy: 0.7967 - val_loss: 0.6298 - learning_rate: 2.5000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7609 - loss: 0.6580 - val_accuracy: 0.7967 - val_loss: 0.6324 - learning_rate: 2.5000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7706 - loss: 0.6063 - val_accuracy: 0.7886 - val_loss: 0.6323 - learning_rate: 2.5000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7831 - loss: 0.6015 - val_accuracy: 0.7886 - val_loss: 0.6310 - learning_rate: 2.5000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7798 - loss: 0.5900 - val_accuracy: 0.7886 - val_loss: 0.6306 - learning_rate: 2.5000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7593 - loss: 0.6487 - val_accuracy: 0.7886 - val_loss: 0.6304 - learning_rate: 2.5000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.7728 - loss: 0.6083 - val_accuracy: 0.7967 - val_loss: 0.6306 - learning_rate: 1.2500e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7862 - loss: 0.5991 - val_accuracy: 0.7886 - val_loss: 0.6316 - learning_rate: 1.2500e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7495 - loss: 0.6519 - val_accuracy: 0.7967 - val_loss: 0.6301 - learning_rate: 1.2500e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7774 - loss: 0.6516 - val_accuracy: 0.7967 - val_loss: 0.6313 - learning_rate: 1.2500e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7709 - loss: 0.6261 - val_accuracy: 0.7967 - val_loss: 0.6301 - learning_rate: 1.2500e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7694 - loss: 0.6644 - val_accuracy: 0.7967 - val_loss: 0.6300 - learning_rate: 6.2500e-06\n",
      "Epoch 173/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7667 - loss: 0.6674 - val_accuracy: 0.7967 - val_loss: 0.6290 - learning_rate: 6.2500e-06\n",
      "Epoch 174/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7799 - loss: 0.6071 - val_accuracy: 0.7886 - val_loss: 0.6298 - learning_rate: 6.2500e-06\n",
      "Epoch 175/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7603 - loss: 0.7163 - val_accuracy: 0.7886 - val_loss: 0.6300 - learning_rate: 6.2500e-06\n",
      "Epoch 176/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7701 - loss: 0.6514 - val_accuracy: 0.7886 - val_loss: 0.6292 - learning_rate: 6.2500e-06\n",
      "Epoch 177/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7860 - loss: 0.6092 - val_accuracy: 0.7967 - val_loss: 0.6283 - learning_rate: 6.2500e-06\n",
      "Epoch 178/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8027 - loss: 0.5790 - val_accuracy: 0.7886 - val_loss: 0.6283 - learning_rate: 6.2500e-06\n",
      "Epoch 179/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7475 - loss: 0.6601 - val_accuracy: 0.7967 - val_loss: 0.6273 - learning_rate: 6.2500e-06\n",
      "Epoch 180/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8006 - loss: 0.5719 - val_accuracy: 0.7967 - val_loss: 0.6259 - learning_rate: 6.2500e-06\n",
      "Epoch 181/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7556 - loss: 0.6579 - val_accuracy: 0.7967 - val_loss: 0.6254 - learning_rate: 6.2500e-06\n",
      "Epoch 182/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7540 - loss: 0.6683 - val_accuracy: 0.7967 - val_loss: 0.6259 - learning_rate: 6.2500e-06\n",
      "Epoch 183/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.7687 - loss: 0.6142 - val_accuracy: 0.7886 - val_loss: 0.6261 - learning_rate: 6.2500e-06\n",
      "Epoch 184/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.7706 - loss: 0.6392 - val_accuracy: 0.7886 - val_loss: 0.6266 - learning_rate: 6.2500e-06\n",
      "Epoch 185/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8002 - loss: 0.5982 - val_accuracy: 0.7967 - val_loss: 0.6251 - learning_rate: 6.2500e-06\n",
      "Epoch 186/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7721 - loss: 0.6047 - val_accuracy: 0.7967 - val_loss: 0.6254 - learning_rate: 6.2500e-06\n",
      "Epoch 187/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8041 - loss: 0.5389 - val_accuracy: 0.7967 - val_loss: 0.6260 - learning_rate: 6.2500e-06\n",
      "Epoch 188/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7747 - loss: 0.6372 - val_accuracy: 0.7967 - val_loss: 0.6248 - learning_rate: 6.2500e-06\n",
      "Epoch 189/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7665 - loss: 0.6306 - val_accuracy: 0.7967 - val_loss: 0.6245 - learning_rate: 6.2500e-06\n",
      "Epoch 190/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7875 - loss: 0.6223 - val_accuracy: 0.7886 - val_loss: 0.6244 - learning_rate: 6.2500e-06\n",
      "Epoch 191/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.7599 - loss: 0.6345 - val_accuracy: 0.7886 - val_loss: 0.6236 - learning_rate: 6.2500e-06\n",
      "Epoch 192/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7861 - loss: 0.6273 - val_accuracy: 0.7967 - val_loss: 0.6240 - learning_rate: 6.2500e-06\n",
      "Epoch 193/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7768 - loss: 0.6309 - val_accuracy: 0.7967 - val_loss: 0.6236 - learning_rate: 6.2500e-06\n",
      "Epoch 194/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7678 - loss: 0.5976 - val_accuracy: 0.7967 - val_loss: 0.6233 - learning_rate: 6.2500e-06\n",
      "Epoch 195/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7552 - loss: 0.6577 - val_accuracy: 0.7886 - val_loss: 0.6235 - learning_rate: 6.2500e-06\n",
      "Epoch 196/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7760 - loss: 0.6387 - val_accuracy: 0.7886 - val_loss: 0.6242 - learning_rate: 6.2500e-06\n",
      "Epoch 197/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7706 - loss: 0.6129 - val_accuracy: 0.7886 - val_loss: 0.6251 - learning_rate: 6.2500e-06\n",
      "Epoch 198/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7920 - loss: 0.6106 - val_accuracy: 0.7967 - val_loss: 0.6239 - learning_rate: 6.2500e-06\n",
      "Epoch 199/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7627 - loss: 0.6491 - val_accuracy: 0.7967 - val_loss: 0.6235 - learning_rate: 6.2500e-06\n",
      "Epoch 200/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7657 - loss: 0.6297 - val_accuracy: 0.7886 - val_loss: 0.6249 - learning_rate: 3.1250e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7749 - loss: 0.6215\n",
      "Test Accuracy: 0.7967\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Verify class distribution\n",
    "print(\"Emotion distribution:\")\n",
    "print(pd.Series(y_fem).value_counts(normalize=True))\n",
    "\n",
    "# 2. Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_fem)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# 3. Prepare features\n",
    "X = np.array(x_fem)\n",
    "\n",
    "# 4. Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.1, random_state=9\n",
    ")\n",
    "\n",
    "# 5. Feature scaling (CRITICAL)\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 6. Build enhanced model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(x_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Lower LR\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# 7. Train with callbacks\n",
    "history = model.fit(\n",
    "    x_train_scaled, y_train,\n",
    "    epochs=200,  # More epochs\n",
    "    batch_size=64,\n",
    "    validation_data=(x_test_scaled, y_test),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 8. Evaluate and visualize\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21056336-3724-48ac-b889-57409e447d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb753a-0054-4bd0-8e3b-18ecc80ecc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a930e-bc6e-4dbf-a0cf-a4830adfcb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a750be-e302-46f1-9959-2e3fff21dbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6383e5-2116-4a6b-857e-013b1b44e443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b3c18-1627-4e78-b322-959fd615ae01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0c1b569-091c-4876-989f-6c453908e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Verify class distribution\n",
    "print(\"Emotion distribution:\")\n",
    "print(pd.Series(y_fem).value_counts(normalize=True))\n",
    "\n",
    "# 2. Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_fem)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# 3. Prepare features\n",
    "X = np.array(x_fem)\n",
    "\n",
    "# 4. Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.1, random_state=9  # Use integer labels for sklearn\n",
    ")\n",
    "\n",
    "# 5. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 6. Build base classifiers\n",
    "rf = RandomForestClassifier(n_estimators=200, \n",
    "                           max_depth=10, \n",
    "                           class_weight='balanced',\n",
    "                           random_state=9)\n",
    "\n",
    "svm = SVC(C=1.0, \n",
    "          kernel='rbf', \n",
    "          probability=True, \n",
    "          class_weight='balanced',\n",
    "          random_state=9)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=150,\n",
    "                                learning_rate=0.1,\n",
    "                                max_depth=5,\n",
    "                                random_state=9)\n",
    "\n",
    "# 7. Create ensemble models\n",
    "# Voting Classifier (Hard Voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('svm', svm), ('gb', gb)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('svm', svm), ('gb', gb)],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=9),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 8. Train and evaluate models\n",
    "models = {\n",
    "    'Random Forest': rf,\n",
    "    'SVM': svm,\n",
    "    'Gradient Boosting': gb,\n",
    "    'Voting Classifier': voting_clf,\n",
    "    'Stacking Classifier': stacking_clf\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Confusion matrix for each model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', \n",
    "                xticklabels=le.classes_, \n",
    "                yticklabels=le.classes_)\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# 9. Compare model performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results.keys(), results.values(), color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. Feature importance from Random Forest\n",
    "plt.figure(figsize=(12, 8))\n",
    "importances = rf.feature_importances_\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "plt.bar(range(20), importances[sorted_idx][:20])\n",
    "plt.xticks(range(20), sorted_idx[:20], rotation=90)\n",
    "plt.title('Top 20 Important Features (Random Forest)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a238686-c1ae-430f-a6ad-63bfef717558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Per-Class Accuracy:\n",
      "  angry: 0.9756\n",
      "  calm: 0.9675\n",
      "  disgust: 0.9106\n",
      "  fearful: 0.9350\n",
      "  happy: 0.9512\n",
      "  neutral: 0.9837\n",
      "  sad: 0.9106\n",
      "  surprised: 0.9756\n",
      "\n",
      "SVM Per-Class Accuracy:\n",
      "  angry: 0.9756\n",
      "  calm: 0.9675\n",
      "  disgust: 0.9106\n",
      "  fearful: 0.9350\n",
      "  happy: 0.9512\n",
      "  neutral: 0.9837\n",
      "  sad: 0.9106\n",
      "  surprised: 0.9756\n",
      "\n",
      "Gradient Boosting Per-Class Accuracy:\n",
      "  angry: 0.9756\n",
      "  calm: 0.9675\n",
      "  disgust: 0.9106\n",
      "  fearful: 0.9350\n",
      "  happy: 0.9512\n",
      "  neutral: 0.9837\n",
      "  sad: 0.9106\n",
      "  surprised: 0.9756\n",
      "\n",
      "Voting Classifier Per-Class Accuracy:\n",
      "  angry: 0.9756\n",
      "  calm: 0.9675\n",
      "  disgust: 0.9106\n",
      "  fearful: 0.9350\n",
      "  happy: 0.9512\n",
      "  neutral: 0.9837\n",
      "  sad: 0.9106\n",
      "  surprised: 0.9756\n",
      "\n",
      "Stacking Classifier Per-Class Accuracy:\n",
      "  angry: 0.9756\n",
      "  calm: 0.9675\n",
      "  disgust: 0.9106\n",
      "  fearful: 0.9350\n",
      "  happy: 0.9512\n",
      "  neutral: 0.9837\n",
      "  sad: 0.9106\n",
      "  surprised: 0.9756\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    ...\n",
    "    # Existing code (confusion matrix plot)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # NEW: Compute per-class accuracy\n",
    "    total_samples = cm.sum()\n",
    "    class_acc = {}\n",
    "    for i, cls in enumerate(le.classes_):\n",
    "        tp = cm[i, i]\n",
    "        tn = total_samples - (cm[i,:].sum() + cm[:,i].sum() - tp)\n",
    "        class_acc[cls] = (tp + tn) / total_samples\n",
    "    \n",
    "    print(f\"\\n{name} Per-Class Accuracy:\")\n",
    "    for cls, acc in class_acc.items():\n",
    "        print(f\"  {cls}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557fdcb2-82fa-4bc4-9055-b1027c10cb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4349d-7c42-43bd-8247-255d896955d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d964f9e-7bab-43e4-b3a3-994857ed2b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51085c46-adc2-4bfe-a0a8-2167b24010fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66007a6-6988-4708-a920-cb3882e7697b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Append gender as 1 or 0 to each feature vector\n",
    "# for i in range(len(x_fem)):\n",
    "#     x_fem[i] = np.append(x_fem[i], 1)  # Female = 1\n",
    "\n",
    "# for i in range(len(x_male)):\n",
    "#     x_male[i] = np.append(x_male[i], 0)  # Male = 0\n",
    "\n",
    "# # Combine datasets\n",
    "# X_combined = np.array(x_fem + x_male)\n",
    "# y_combined = np.array(y_fem + y_male)\n",
    "\n",
    "# # 1. Verify class distribution\n",
    "# print(\"Emotion distribution:\")\n",
    "# print(pd.Series(y_combined).value_counts(normalize=True))\n",
    "\n",
    "# # 2. Encode labels\n",
    "# le = LabelEncoder()\n",
    "# y_encoded = le.fit_transform(y_combined)\n",
    "# y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# # 3. Split data\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     X_combined, y_categorical, test_size=0.1, random_state=9\n",
    "# )\n",
    "\n",
    "# # 4. Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 5. Reshape data for CNN-LSTM\n",
    "# x_train_reshaped = x_train_scaled.reshape((x_train_scaled.shape[0], 1, x_train_scaled.shape[1]))\n",
    "# x_test_reshaped = x_test_scaled.reshape((x_test_scaled.shape[0], 1, x_test_scaled.shape[1]))\n",
    "\n",
    "# print(\"Reshaped data dimensions:\")\n",
    "# print(f\"x_train_reshaped: {x_train_reshaped.shape}\")\n",
    "# print(f\"x_test_reshaped: {x_test_reshaped.shape}\")\n",
    "\n",
    "# # 6. Define model parameters\n",
    "# num_classes = y_categorical.shape[1]\n",
    "# max_seq_len = 1\n",
    "# num_features = x_train_scaled.shape[1]\n",
    "\n",
    "# # 7. Build hybrid CNN-LSTM model\n",
    "# model = Sequential([\n",
    "#     Conv1D(128, 5, activation='relu', padding='same', input_shape=(max_seq_len, num_features)),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.3),\n",
    "#     MaxPooling1D(pool_size=1),\n",
    "#     LSTM(128, return_sequences=True),\n",
    "#     Dropout(0.3),\n",
    "#     LSTM(64),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile model\n",
    "# opt = Adam(learning_rate=0.0001)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# # 8. Train with callbacks\n",
    "# history = model.fit(\n",
    "#     x_train_reshaped, y_train,\n",
    "#     epochs=500,\n",
    "#     batch_size=64,\n",
    "#     validation_data=(x_test_reshaped, y_test),\n",
    "#     callbacks=[\n",
    "#         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # 9. Evaluate and visualize\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Train')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Train')\n",
    "# plt.plot(history.history['val_loss'], label='Validation')\n",
    "# plt.title('Model Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Evaluate\n",
    "# test_loss, test_acc = model.evaluate(x_test_reshaped, y_test)\n",
    "# print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# # Confusion matrix\n",
    "# y_pred = model.predict(x_test_reshaped)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# cm = confusion_matrix(y_true, y_pred_classes)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad4fce-dcd6-407a-bcef-e32aab51b19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2dad5-5daa-47fe-8371-b09bc0974843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13bb75-be9b-4691-a925-fe07d18fe6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ec28d-a25c-46f8-830b-7dc9499283a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
